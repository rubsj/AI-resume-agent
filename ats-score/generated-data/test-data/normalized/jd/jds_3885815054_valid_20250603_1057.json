[
    {
        "record_id": 3885815054,
        "domain": "software",
        "input_text": "Job Title: Palantir Developer\n\nLocation: Cleveland, OH\n\nEmployment Type: full-time\n\nListed Skills: Data Modelling , Big Data\n\nDescription:\nWe are seeking a skilled Data Engineer with a strong background in data pipeline creation, data visualization, and analytics. As a key member of our team, you will play a crucial role in designing, developing, and optimizing data solutions to drive actionable insights.\n\nResponsibilities\n\nData Pipeline Creation:\n\noProficiently design, develop, and maintain data pipelines using the Palantir Foundry tool suite, including apps like Slate, Workshop, Contour, Taurus, Ontology Manager, Object View, and Report.\n\noUtilize JavaScript and Python to create robust data pipelines, ensuring efficient data flow and transformation.\n\nData Visualization:\n\noDevelop interactive dashboards using JavaScript, providing stakeholders with clear insights into complex datasets.\n\noLeverage Python for data transformation and visualization, enhancing the user experience.\n\nBig Data Processing:\n\noWork on the Azure platform with Databricks, developing Spark applications using Spark-SQL.\n\noExtract, transform, and aggregate data from various file formats (e.g., txt, avro, parquet, csv) to analyze customer data and derive meaningful insights.\n\nSpark and PySpark:\n\noUtilize Spark and PySpark to streamline data processing tasks, enhance scalability, and optimize performance.\n\noDesign and implement efficient data workflows, ensuring data quality and reliability.\n\nMachine Learning and Deep Learning:\n\noDesigned regression models and employed ensemble techniques to predict life expectancy, achieving a 60% decrease in RMSE compared to the baseline model using gradient boosting regression.\n\noProficient in using Spark APIs, including Spark SQL, Spark DataFrames, and User-Defined Functions (UDFs).\n\noHands-on experience with various functions, transformations, and actions performed on Spark RDDs.\n\nData Modeling and Analysis:\n\noImported data onto the Hadoop Distributed File System using MapReduce.\n\noAnalyzed data using Hive and reported insights using Tableau 2020.1.\n\noWorked with different file formats (Excel, CSV, Parquet, Avro) for Hive querying and processing.\n\nData Visualization Tools:\n\noConducted Exploratory Data Analysis (EDA) using Tableau 2020.1, Matplotlib, Seaborn (Python), and GGPlot ®.\n\noProficiently designed both logical and physical data models, addressing OLTP and OLAP requirements.\n\nVersion Control and Collaboration:\n\noProficiently used Git and GitHub for version control, creating and managing branches.\n\nTableau Expertise: div>\n\noGenerated Tableau visualizations and dashboards using Tableau Desktop.\n\noCreated dashboards with quick filters, parameters, and sets to handle views more efficiently.\n\noCombined visualizations into interactive Tableau dashboards and published them to web portals such as Tableau Public.\n\noExtensively used advanced chart visualizations in Tableau, including dual-axis, box plots, bullet graphs, tree maps, bubble charts, waterfall charts, and funnel charts to assist business users in solving complex problems.\n\nBachelor’s degree in Computer Science, Data Science, or a related field.Proven experience in data engineering, data visualization, and big data processing.Strong analytical skills with meticulous attention to detail.\n\nExcellent communication and collaboration skills.\n\nExperience Level (if available): Entry level",
        "output_json": {
            "jd_id": 3885815054,
            "inferred_domain": "software",
            "title": "Palantir Developer",
            "summary": "Seeking a skilled Data Engineer with expertise in data pipeline creation, visualization, and analytics.",
            "required_experience_years": "",
            "preferred_degrees": [
                "Bachelor’s degree in Computer Science, Data Science, or a related field"
            ],
            "required_skills": [
                "Data Modelling",
                "Big Data",
                "Data Engineering",
                "Data Visualization",
                "Analytics",
                "JavaScript",
                "Python",
                "Palantir Foundry",
                "Databricks",
                "Spark",
                "PySpark",
                "Hive",
                "Tableau",
                "Git",
                "GitHub"
            ],
            "optional_skills": [
                "Machine Learning",
                "Deep Learning",
                "OLTP",
                "OLAP",
                "MapReduce",
                "Hadoop",
                "User-Defined Functions (UDFs)"
            ],
            "tools_and_technologies": [
                "Palantir Foundry",
                "JavaScript",
                "Python",
                "Databricks",
                "Spark",
                "PySpark",
                "Hive",
                "Tableau",
                "Git",
                "GitHub"
            ],
            "certifications": [],
            "soft_skills": [
                "Strong analytical skills",
                "Meticulous attention to detail",
                "Excellent communication",
                "Collaboration"
            ],
            "job_responsibilities": [
                "Design, develop, and maintain data pipelines using Palantir Foundry tools",
                "Create interactive dashboards using JavaScript",
                "Develop Spark applications using Spark-SQL",
                "Process data from various file formats",
                "Design and implement efficient data workflows",
                "Streamline data processing tasks using Spark APIs",
                "Design regression models and ensemble techniques",
                "Use Spark functions, transformations, and actions",
                "Import data onto Hadoop Distributed File System using MapReduce",
                "Analyze data using Hive and Tableau",
                "Work with different file formats for Hive querying",
                "Conduct EDA using Tableau, Matplotlib, Seaborn, and GGPlot",
                "Create logical and physical data models",
                "Use Git and GitHub for version control",
                "Generate Tableau visualizations and dashboards",
                "Create interactive Tableau dashboards",
                "Use advanced chart visualizations in Tableau"
            ],
            "job_location": "Cleveland, OH",
            "remote_option": "",
            "employment_type": "full-time",
            "travel_requirements": "",
            "physical_requirements": "",
            "benefits": [],
            "company_information": "",
            "equal_opportunity_policy": "",
            "other": [
                {
                    "section_name": "Experience Level",
                    "content": "Entry level"
                }
            ]
        }
    }
]