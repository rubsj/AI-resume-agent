{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f630d895",
   "metadata": {},
   "source": [
    "# Global setup and package installation used in most phases"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "969fcea6",
   "metadata": {},
   "source": [
    "## Colab + GPU Detection Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e7cf79fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "def is_running_in_colab():\n",
    "    try:\n",
    "        import google.colab\n",
    "        return True\n",
    "    except ImportError:\n",
    "        return False\n",
    "\n",
    "def get_available_gpu_memory_gb():\n",
    "    try:\n",
    "        output = subprocess.check_output(\n",
    "            [\"nvidia-smi\", \"--query-gpu=memory.free\", \"--format=csv,nounits,noheader\"],\n",
    "            encoding=\"utf-8\"\n",
    "        )\n",
    "        free_mem_mb = int(output.strip().split(\"\\n\")[0])\n",
    "        return free_mem_mb / 1024\n",
    "    except Exception:\n",
    "        return 0.0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66be54d4",
   "metadata": {},
   "source": [
    "## install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "942fba10",
   "metadata": {},
   "outputs": [],
   "source": [
    "if is_running_in_colab():\n",
    "    # Install the required packages\n",
    "    !pip install kagglehub pandas\n",
    "    !pip install -q transformers accelerate bitsandbytes sentencepiece pydantic huggingface_hub xformers\n",
    "    !pip install regex json5\n",
    "    !pip install sentence-transformers scikit-learn\n",
    "    !pip install rapidfuzz unidecode\n",
    "\n",
    "else:\n",
    "    %pip install kagglehub pandas\n",
    "    %pip install -q transformers accelerate sentencepiece pydantic huggingface_hub xformers\n",
    "    #%pip install torch==2.2.2 torchvision==0.17.2 torchaudio==2.2.2 --index-url https://download.pytorch.org/whl/cu121\n",
    "    #%pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121\n",
    "    %pip install --pre torch torchvision torchaudio --index-url https://download.pytorch.org/whl/nightly/cu128\n",
    "    %pip install -U bitsandbytes\n",
    "    %pip install regex json5\n",
    "    %pip install sentence-transformers scikit-learn\n",
    "    %pip install rapidfuzz unidecode\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef4a9f61",
   "metadata": {},
   "source": [
    "## Login to huggingface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1235aef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import login\n",
    "import os\n",
    "\n",
    "# Set your token here securely or prompt for it in Colab\n",
    "# Recommended: store in Colab secrets or environment variable\n",
    "HF_TOKEN = os.getenv(\"HUGGINGFACE_TOKEN\")\n",
    "\n",
    "\n",
    "if not HF_TOKEN:\n",
    "    if is_running_in_colab():\n",
    "        # If running in Colab, use the Colab secrets\n",
    "        try:\n",
    "            from google.colab import userdata\n",
    "            HF_TOKEN = userdata.get('HF_TOKEN')\n",
    "            if not HF_TOKEN:\n",
    "                raise ValueError(\"‚ö†Ô∏è Hugging Face token not found in Colab secrets.\")\n",
    "            print(\"üîë Hugging Face token found in Colab secrets.\")\n",
    "        except ImportError:\n",
    "            print(\"‚ö†Ô∏è Unable to authenticate in Colab. Please set your Hugging Face token manually.\")\n",
    "    else:\n",
    "        # Prompt for token if not set in environment\n",
    "        print(\"üîë Please enter your Hugging Face token:\")\n",
    "        # For Colab or local prompt input\n",
    "        HF_TOKEN = input(\"üîë Enter your Hugging Face token: \").strip()\n",
    "\n",
    "login(token=HF_TOKEN)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b423735e",
   "metadata": {},
   "source": [
    "## Setup Kaggle Credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "409818e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Kaggle credentials already exist at C:\\Users\\rubyj/.kaggle/kaggle.json\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "\n",
    "def setup_kaggle_credentials():\n",
    "    kaggle_path = os.path.expanduser('~/.kaggle/kaggle.json')\n",
    "    if not os.path.exists(kaggle_path):\n",
    "        from google.colab import files\n",
    "        print(\"üìÇ Upload kaggle.json file...\")\n",
    "        uploaded = files.upload()\n",
    "        os.makedirs(os.path.dirname(kaggle_path), exist_ok=True)\n",
    "        for filename in uploaded.keys():\n",
    "            shutil.move(filename, kaggle_path)\n",
    "        os.chmod(kaggle_path, 0o600)\n",
    "        print(f\"‚úÖ Kaggle credentials setup at {kaggle_path}\")\n",
    "    else:\n",
    "        print(f\"‚úÖ Kaggle credentials already exist at {kaggle_path}\")\n",
    "\n",
    "setup_kaggle_credentials()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d384b2f",
   "metadata": {},
   "source": [
    "## Mount Google Drive (Colab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1517ea98",
   "metadata": {},
   "outputs": [],
   "source": [
    "if is_running_in_colab():\n",
    "   from google.colab import drive\n",
    "   drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9964af3",
   "metadata": {},
   "source": [
    "##  Load Qwen-Instruct with Fallback to Quantized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "be6d840d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig, pipeline\n",
    "import torch\n",
    "\n",
    "def load_model_pipeline(model_name: str, hf_token: str):\n",
    "    has_cuda = torch.cuda.is_available()\n",
    "    free_mem = torch.cuda.get_device_properties(0).total_memory / (1024 ** 3) if has_cuda else 0\n",
    "    print(f\"üíª CUDA: {has_cuda} | GPU Memory: {free_mem:.2f} GB\")\n",
    "\n",
    "    device_map = {\"\": 0} if has_cuda else \"cpu\"\n",
    "    use_4bit = has_cuda and free_mem < 24\n",
    "\n",
    "    # Set quantization config\n",
    "    quant_config = BitsAndBytesConfig(\n",
    "        load_in_4bit=True if use_4bit else False,\n",
    "        bnb_4bit_use_double_quant=True,\n",
    "        bnb_4bit_compute_dtype=torch.float16,\n",
    "        bnb_4bit_quant_type=\"nf4\"\n",
    "    ) if use_4bit else None\n",
    "\n",
    "    # Load tokenizer\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name, token=hf_token, trust_remote_code=True)\n",
    "    tokenizer.pad_token = tokenizer.eos_token  # ‚úÖ Fix warning about pad_token\n",
    "\n",
    "    # Load model\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        model_name,\n",
    "        device_map=device_map,\n",
    "        quantization_config=quant_config,\n",
    "        torch_dtype=torch.float16 if not quant_config else None,\n",
    "        trust_remote_code=True,\n",
    "        token=hf_token\n",
    "    )\n",
    "\n",
    "    print(f\"‚úÖ Model loaded on {next(model.parameters()).device}\")\n",
    "    return pipeline(\"text-generation\", model=model, tokenizer=tokenizer, batch_size=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5f811301",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üíª CUDA: True | GPU Memory: 15.92 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sliding Window Attention is enabled but not implemented for `sdpa`; unexpected results may be encountered.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96c80345f32d43f9ada6a5036dd31d28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Model loaded on cuda:0\n"
     ]
    }
   ],
   "source": [
    "llm_pipeline = load_model_pipeline(\n",
    "    model_name=\"Qwen/Qwen2-7B-Instruct\",\n",
    "    hf_token=HF_TOKEN\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "739b4783",
   "metadata": {},
   "source": [
    "# Global utilities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63df9fc3",
   "metadata": {},
   "source": [
    "### Utility to save json to a folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "727b44eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "# üì¶ Save JSON Output with Safety\n",
    "def save_json_output(data, output_path: str, indent: int = 4, overwrite: bool = True):\n",
    "    output_dir = os.path.dirname(output_path)\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    if os.path.exists(output_path):\n",
    "        if overwrite:\n",
    "            os.remove(output_path)\n",
    "        else:\n",
    "            raise FileExistsError(f\"File {output_path} already exists and overwrite=False.\")\n",
    "\n",
    "    with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(data, f, indent=indent, ensure_ascii=False)\n",
    "\n",
    "    print(f\"‚úÖ Saved output to {output_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc498258",
   "metadata": {},
   "source": [
    "### Utility to load file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dcf31583",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any\n",
    "import json\n",
    "\n",
    "# üìÇ Load normalized JSON data\n",
    "def load_json_file(file_path: str) -> Any:\n",
    "    if not os.path.isfile(file_path):\n",
    "        raise FileNotFoundError(f\"File not found: {file_path}\")\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        return json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dc3308e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from typing import List, Dict\n",
    "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "# Utility: Load structured JSON records from one or more files\n",
    "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "def load_json_records(paths: List[Path]) -> List[Dict]:\n",
    "    records = []\n",
    "    for path in paths:\n",
    "        with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "            data = json.load(f)\n",
    "            if isinstance(data, list):\n",
    "                records.extend(data)\n",
    "            else:\n",
    "                records.append(data)\n",
    "    return records"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b329b93",
   "metadata": {},
   "source": [
    "### Configurations  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4308e95a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================\n",
    "# üõ† CONFIGURATION\n",
    "# ==============================\n",
    "\n",
    "class Config:\n",
    "    JSON_OUTPUT_DIR = \"json_outputs_all_data\"\n",
    "    JSON_OUTPUT_NORMALIZED_DIR = \"json_outputs_all_data/normalized\"\n",
    "    JSON_OUTPUT_NORMALIZED_JD = \"json_outputs_all_data/normalized/jd\"\n",
    "    JSON_OUTPUT_NORMALIZED_RESUME = \"json_outputs_all_data/normalized/resume\"\n",
    "    JSON_OUTPUT_SCORING_DIR = \"json_outputs_all_data/scoring\"\n",
    "    JSON_OUTPUT_SCORING_SPLIT_DIR = \"json_outputs_all_data/scoring/split\"\n",
    "  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c7b2072",
   "metadata": {},
   "source": [
    "# Pre Phase3 Embedding-Based Resume-JD Relevance Generator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d210e8c3",
   "metadata": {},
   "source": [
    "## Generate Sementic relevance file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e2862ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "from typing import Tuple\n",
    "\n",
    "# Load embedding model once (lightweight)\n",
    "domain_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "def compute_domain_similarity(domain1: str, domain2: str, threshold: float = 0.5) -> Tuple[float, bool]:\n",
    "    \"\"\"\n",
    "    Compute cosine similarity between two domain strings using sentence embeddings.\n",
    "\n",
    "    Returns:\n",
    "        (similarity_score, is_similar) where:\n",
    "            - similarity_score is a float between 0 and 1\n",
    "            - is_similar is True if similarity >= threshold\n",
    "    \"\"\"\n",
    "    if not domain1 or not domain2:\n",
    "        return 1.0, True  # Treat empty/missing domain as matching\n",
    "\n",
    "    embeddings = domain_model.encode([domain1, domain2], convert_to_tensor=True)\n",
    "    similarity = util.cos_sim(embeddings[0], embeddings[1]).item()\n",
    "    return round(similarity, 4), similarity >= threshold\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a86afb58",
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_score, is_similar = compute_domain_similarity(\"healthcare analytics\", \"medical data science\")\n",
    "print(f\"Similarity: {sim_score}, Match: {is_similar}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "509dc162",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Dict\n",
    "from pathlib import Path\n",
    "import json\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "\n",
    "def generate_relevance_map(\n",
    "    resume_files: List[Path],\n",
    "    jd_files: List[Path],\n",
    "    model_name: str = \"all-MiniLM-L6-v2\",\n",
    "    min_score: float = 0.2\n",
    ") -> Dict[str, List[Dict]]:\n",
    "    model = SentenceTransformer(model_name)\n",
    "\n",
    "    resumes = load_json_records(resume_files)\n",
    "    jds = load_json_records(jd_files)\n",
    "\n",
    "    resumes_df = pd.DataFrame([r for r in resumes if r.get(\"input_text\") and r.get(\"output_json\")])\n",
    "    jds_df = pd.DataFrame([j for j in jds if j.get(\"input_text\") and j.get(\"output_json\")])\n",
    "\n",
    "    resume_embeds = model.encode(resumes_df[\"input_text\"].tolist(), convert_to_tensor=True)\n",
    "    jd_embeds = model.encode(jds_df[\"input_text\"].tolist(), convert_to_tensor=True)\n",
    "    scores = util.cos_sim(resume_embeds, jd_embeds).cpu().numpy()\n",
    "\n",
    "    results = []\n",
    "    for i, r_row in resumes_df.iterrows():\n",
    "        for j, jd_row in jds_df.iterrows():\n",
    "            r_domain = r_row[\"domain\"].strip().lower()\n",
    "            jd_domain = jd_row[\"domain\"].strip().lower()\n",
    "            domain_score, domain_match = compute_domain_similarity(r_domain, jd_domain, threshold=0.5)\n",
    "            if not domain_match:\n",
    "                continue  # Skip this resume‚ÄìJD pair\n",
    "\n",
    "\n",
    "            score = float(scores[i][j])\n",
    "            if score < min_score:\n",
    "                continue\n",
    "\n",
    "            label = (\n",
    "                \"strong\" if score >= 0.65 else\n",
    "                \"medium\" if score >= 0.4 else\n",
    "                \"weak\"\n",
    "            )\n",
    "\n",
    "            # Append result with extended metadata\n",
    "            results.append({\n",
    "                \"resume_id\": r_row[\"record_id\"],\n",
    "                \"jd_id\": jd_row[\"record_id\"],\n",
    "                \"resume_domain\": r_row[\"domain\"],\n",
    "                \"jd_domain\": jd_row[\"domain\"],\n",
    "                \"domain_similarity\": round(domain_score, 3),\n",
    "                \"resume_jd_similarity\": round(score, 3),\n",
    "                \"semantic_match_label\": label\n",
    "            })\n",
    "\n",
    "    print(f\"Generated relevance map with {len(results)} pairs.\")\n",
    "    # print count of weak, medium, strong matches\n",
    "    weak_count = sum(1 for r in results if r[\"semantic_match_label\"] == \"weak\")\n",
    "    medium_count = sum(1 for r in results if r[\"semantic_match_label\"] == \"medium\")\n",
    "    strong_count = sum(1 for r in results if r[\"semantic_match_label\"] == \"strong\")\n",
    "    print(f\"Weak matches: {weak_count}, Medium matches: {medium_count}, Strong matches: {strong_count}\")\n",
    "\n",
    "    top_k = 3  # Change as needed\n",
    "    reverse_map = defaultdict(list)\n",
    "\n",
    "    # Group by resume_id and sort by similarity score\n",
    "    for r in results:\n",
    "        reverse_map[r[\"resume_id\"]].append(r)\n",
    "\n",
    "    # Sort and keep top K\n",
    "    resume_top_matches = {\n",
    "        resume_id: sorted(matches, key=lambda x: x[\"resume_jd_similarity\"], reverse=True)[:top_k]\n",
    "        for resume_id, matches in reverse_map.items()\n",
    "    }\n",
    "\n",
    "\n",
    "    return {\n",
    "    \"semantic_relevance_scores\": results,\n",
    "    \"resume_top_matches\": resume_top_matches\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4a049b60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated relevance map with 2463477 pairs.\n",
      "Weak matches: 1450197, Medium matches: 998172, Strong matches: 15108\n",
      "‚úÖ Saved output to json_outputs_all_data/scoring\\semantic_relevance_scores.json\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "resume_paths = list(Path(Config.JSON_OUTPUT_NORMALIZED_RESUME).glob(\"resumes_*.json\"))\n",
    "jd_paths = list(Path(Config.JSON_OUTPUT_NORMALIZED_JD).glob(\"jds_*.json\"))\n",
    "relevance_data = generate_relevance_map(resume_paths, jd_paths)\n",
    "relevance_map_file = os.path.join(Config.JSON_OUTPUT_SCORING_DIR, 'semantic_relevance_scores.json')\n",
    "save_json_output(relevance_data, relevance_map_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73673dc9",
   "metadata": {},
   "source": [
    "## Generate smaller semantic file for future scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "29e91838",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Dict, Tuple, Set\n",
    "from collections import defaultdict, Counter\n",
    "import random\n",
    "\n",
    "# === 1. FILTERING ===\n",
    "def filter_pairs_by_score(pairs: List[Dict], threshold: float) -> List[Dict]:\n",
    "    return [p for p in pairs if p.get(\"resume_jd_similarity\", 0.0) >= threshold]\n",
    "\n",
    "\n",
    "# === 2. GROUPING ===\n",
    "def group_pairs_by_quality_and_resume(pairs: List[Dict]) -> Tuple[\n",
    "    Dict[str, List[Dict]],\n",
    "    Dict[int, Dict[str, List[Dict]]],\n",
    "    Dict[str, List[Dict]]\n",
    "]:\n",
    "    quality_buckets = defaultdict(list)\n",
    "    resume_to_qualities = defaultdict(lambda: defaultdict(list))\n",
    "    domain_coverage = defaultdict(list)\n",
    "\n",
    "    for p in pairs:\n",
    "        q = p.get(\"semantic_match_label\", \"unknown\").lower()\n",
    "        rid = p[\"resume_id\"]\n",
    "        res_dom = p.get(\"resume_domain\", \"unknown\").lower()\n",
    "        jd_dom = p.get(\"jd_domain\", \"unknown\").lower()\n",
    "\n",
    "        quality_buckets[q].append(p)\n",
    "        resume_to_qualities[rid][q].append(p)\n",
    "        domain_coverage[res_dom].append(p)\n",
    "        domain_coverage[jd_dom].append(p)\n",
    "\n",
    "    return quality_buckets, resume_to_qualities, domain_coverage\n",
    "\n",
    "\n",
    "# === 3. RESUME-BALANCED SAMPLING ===\n",
    "def resume_balanced_sampling(\n",
    "    resume_to_qualities: Dict[int, Dict[str, List[Dict]]],\n",
    "    target_qualities: List[str],\n",
    "    seen_pairs: Set[Tuple[int, int]]\n",
    ") -> Dict[str, List[Dict]]:\n",
    "    selected = defaultdict(list)\n",
    "    resume_count = 0\n",
    "\n",
    "    for resume_id, qmap in resume_to_qualities.items():\n",
    "        used = 0\n",
    "        for q in target_qualities:\n",
    "            if q in qmap:\n",
    "                pair = random.choice(qmap[q])\n",
    "                key = (pair[\"resume_id\"], pair[\"jd_id\"])\n",
    "                if key not in seen_pairs:\n",
    "                    selected[q].append(pair)\n",
    "                    seen_pairs.add(key)\n",
    "                    used += 1\n",
    "        if used > 0:\n",
    "            resume_count += 1\n",
    "\n",
    "    return selected, resume_count\n",
    "\n",
    "\n",
    "# === 4. DOMAIN QUOTA ENFORCEMENT ===\n",
    "def enforce_domain_quota(\n",
    "    quality_buckets: Dict[str, List[Dict]],\n",
    "    seen_pairs: Set[Tuple[int, int]],\n",
    "    target_counts: Dict[str, int],\n",
    "    current_counts: Dict[str, int],\n",
    "    min_per_domain: int\n",
    ") -> Dict[str, List[Dict]]:\n",
    "    selected = defaultdict(list)\n",
    "    domain_pair_cache = defaultdict(list)\n",
    "\n",
    "    for q in quality_buckets:\n",
    "        for p in quality_buckets[q]:\n",
    "            d1 = p.get(\"resume_domain\", \"unknown\").lower()\n",
    "            d2 = p.get(\"jd_domain\", \"unknown\").lower()\n",
    "            domain_pair_cache[(q, d1)].append(p)\n",
    "            domain_pair_cache[(q, d2)].append(p)\n",
    "\n",
    "    for (q, domain), group in domain_pair_cache.items():\n",
    "        if current_counts[q] >= target_counts[q]:\n",
    "            continue  # already filled this quality\n",
    "\n",
    "        candidates = [p for p in group if (p[\"resume_id\"], p[\"jd_id\"]) not in seen_pairs]\n",
    "        room_left = target_counts[q] - current_counts[q]\n",
    "        take_count = min(min_per_domain, len(candidates), room_left)\n",
    "        sampled = random.sample(candidates, take_count)\n",
    "\n",
    "        for p in sampled:\n",
    "            key = (p[\"resume_id\"], p[\"jd_id\"])\n",
    "            if key not in seen_pairs:\n",
    "                selected[q].append(p)\n",
    "                seen_pairs.add(key)\n",
    "                current_counts[q] += 1\n",
    "                if current_counts[q] >= target_counts[q]:\n",
    "                    break  # stop sampling more of this quality\n",
    "\n",
    "    return selected\n",
    "\n",
    "\n",
    "\n",
    "# === 5. FILL REMAINING WITH DIVERSITY ===\n",
    "def fill_remaining_by_diverse_domains(\n",
    "    quality_buckets: Dict[str, List[Dict]],\n",
    "    selected_by_quality: Dict[str, List[Dict]],\n",
    "    target_counts: Dict[str, int],\n",
    "    seen_pairs: Set[Tuple[int, int]]\n",
    ") -> Dict[str, List[Dict]]:\n",
    "    for q in target_counts:\n",
    "        remaining = target_counts[q] - len(selected_by_quality[q])\n",
    "        if remaining <= 0:\n",
    "            continue\n",
    "\n",
    "        available = [\n",
    "            p for p in quality_buckets[q]\n",
    "            if (p[\"resume_id\"], p[\"jd_id\"]) not in seen_pairs\n",
    "        ]\n",
    "\n",
    "        # Bucket by domain\n",
    "        domain_groups = defaultdict(list)\n",
    "        for p in available:\n",
    "            domain_groups[p.get(\"resume_domain\", \"unknown\").lower()].append(p)\n",
    "            domain_groups[p.get(\"jd_domain\", \"unknown\").lower()].append(p)\n",
    "\n",
    "        sampled = []\n",
    "        domain_cycle = list(domain_groups.keys())\n",
    "        random.shuffle(domain_cycle)\n",
    "\n",
    "        while remaining > 0 and domain_cycle:\n",
    "            domain = domain_cycle.pop(0)\n",
    "            group = domain_groups[domain]\n",
    "            group = [p for p in group if (p[\"resume_id\"], p[\"jd_id\"]) not in seen_pairs]\n",
    "            if not group:\n",
    "                continue\n",
    "            chosen = random.choice(group)\n",
    "            sampled.append(chosen)\n",
    "            seen_pairs.add((chosen[\"resume_id\"], chosen[\"jd_id\"]))\n",
    "            domain_groups[domain].remove(chosen)\n",
    "            domain_cycle.append(domain)\n",
    "            remaining -= 1\n",
    "\n",
    "        selected_by_quality[q].extend(sampled)\n",
    "\n",
    "    return selected_by_quality\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aaa25eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 6. MAIN WRAPPER ===\n",
    "def generate_balanced_sample(\n",
    "    all_pairs: List[Dict],\n",
    "    target_counts: Dict[str, int],\n",
    "    score_threshold: float = 0.1,\n",
    "    min_per_domain: int = 50\n",
    ") -> List[Dict]:\n",
    "    print(f\"üîç Total pairs in input: {len(all_pairs)}\")\n",
    "    filtered = filter_pairs_by_score(all_pairs, score_threshold)\n",
    "    print(f\"‚úÖ After score ‚â• {score_threshold}: {len(filtered)}\")\n",
    "\n",
    "    quality_buckets, resume_to_qualities, domain_coverage = group_pairs_by_quality_and_resume(filtered)\n",
    "    print(\"üìä Match quality counts:\")\n",
    "    for q in target_counts:\n",
    "        print(f\"  {q.upper():<7}: {len(quality_buckets[q])}\")\n",
    "    print(f\"üë• Unique resumes: {len(resume_to_qualities)}\")\n",
    "\n",
    "    seen_pairs = set()\n",
    "\n",
    "    # Resume-balanced\n",
    "    selected_by_quality, resume_count = resume_balanced_sampling(resume_to_qualities, list(target_counts.keys()), seen_pairs)\n",
    "    print(f\"üë§ Resume-balanced resumes: {resume_count}\")\n",
    "\n",
    "    # Domain quotas\n",
    "    current_counts = {q: len(selected_by_quality[q]) for q in target_counts}\n",
    "    domain_quota_selected = enforce_domain_quota(\n",
    "        quality_buckets,\n",
    "        seen_pairs,\n",
    "        target_counts,\n",
    "        current_counts,\n",
    "        min_per_domain\n",
    "    )\n",
    "\n",
    "    for q in target_counts:\n",
    "        selected_by_quality[q].extend(domain_quota_selected.get(q, []))\n",
    "\n",
    "    # Fill remaining\n",
    "    selected_by_quality = fill_remaining_by_diverse_domains(quality_buckets, selected_by_quality, target_counts, seen_pairs)\n",
    "\n",
    "    # Final merge\n",
    "    final_sample = []\n",
    "    print(\"\\nüì¶ Final sampled count:\")\n",
    "    for q in target_counts:\n",
    "        group = selected_by_quality[q]\n",
    "        print(f\"  {q.upper():<7}: {len(group)}\")\n",
    "        final_sample.extend(group)\n",
    "\n",
    "    print(f\"\\nüéØ Total selected: {len(final_sample)}\")\n",
    "\n",
    "    # Domain coverage\n",
    "    resume_domains = [p.get(\"resume_domain\", \"unknown\").lower() for p in final_sample]\n",
    "    jd_domains = [p.get(\"jd_domain\", \"unknown\").lower() for p in final_sample]\n",
    "    print(\"\\nüìä Resume domain coverage (top 10):\")\n",
    "    for dom, count in Counter(resume_domains).most_common(10):\n",
    "        print(f\"  {dom:<30} {count}\")\n",
    "\n",
    "    print(\"\\nüìä JD domain coverage (top 10):\")\n",
    "    for dom, count in Counter(jd_domains).most_common(10):\n",
    "        print(f\"  {dom:<30} {count}\")\n",
    "\n",
    "    return final_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7a1629a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Total pairs in input: 2463477\n",
      "‚úÖ After score ‚â• 0.2: 2463477\n",
      "üìä Match quality counts:\n",
      "  STRONG : 15108\n",
      "  MEDIUM : 998172\n",
      "  WEAK   : 1450197\n",
      "üë• Unique resumes: 2079\n",
      "üë§ Resume-balanced resumes: 2079\n",
      "\n",
      "üì¶ Final sampled count:\n",
      "  STRONG : 14993\n",
      "  MEDIUM : 25000\n",
      "  WEAK   : 15000\n",
      "\n",
      "üéØ Total selected: 54993\n",
      "\n",
      "üìä Resume domain coverage (top 10):\n",
      "  chef                           5950\n",
      "  accountant                     5836\n",
      "  sales                          5530\n",
      "  engineering                    5375\n",
      "  finance                        4738\n",
      "  construction                   3663\n",
      "  business-development           3308\n",
      "  banking                        2663\n",
      "  information-technology         2487\n",
      "  consultant                     1945\n",
      "\n",
      "üìä JD domain coverage (top 10):\n",
      "  finance                        7041\n",
      "  food_service                   2507\n",
      "  retail                         2105\n",
      "  construction                   1645\n",
      "  manufacturing                  1073\n",
      "  education                      1069\n",
      "  business                       866\n",
      "  sales                          770\n",
      "  engineering                    766\n",
      "  information technology         708\n",
      "‚úÖ Saved output to json_outputs_all_data/scoring\\relevant_pairs.json\n"
     ]
    }
   ],
   "source": [
    "# üéØ Define how many samples per match type\n",
    "target_counts = {\n",
    "    \"strong\": 20000,\n",
    "    \"medium\": 25000,\n",
    "    \"weak\": 15000\n",
    "}\n",
    "\n",
    "# üì• Load the filtered list only\n",
    "input_path = os.path.join(Config.JSON_OUTPUT_SCORING_DIR, 'semantic_relevance_scores.json')\n",
    "full_data  = load_json_file(input_path)\n",
    "relevance_data = full_data.get(\"semantic_relevance_scores\", [])\n",
    "\n",
    "# üß† Generate the balanced subset\n",
    "sampled = generate_balanced_sample(\n",
    "    all_pairs=relevance_data,\n",
    "    target_counts=target_counts,\n",
    "    score_threshold=0.2\n",
    ")\n",
    "\n",
    "# Wrap in valid JSON object structure\n",
    "relevance_wrapped = {\n",
    "    \"semantic_relevance_scores\": sampled\n",
    "}\n",
    "\n",
    "# üíæ Save the sampled subset\n",
    "relevance_map_file = os.path.join(Config.JSON_OUTPUT_SCORING_DIR, 'relevant_pairs.json')\n",
    "save_json_output(relevance_wrapped, relevance_map_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e89760a",
   "metadata": {},
   "source": [
    "# Phase 3 Rubric-Based Scoring Engine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0e31b1a",
   "metadata": {},
   "source": [
    "## Rule-Based Scoring Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "61a6b5f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring_config = {\n",
    "    \"matching\": {\n",
    "        # Global fuzzy threshold for fuzzy matching (0‚Äì100)\n",
    "        \"fuzzy_threshold_default\": 85,\n",
    "        \"section_thresholds\": {\n",
    "            \"skills\": 85,\n",
    "            \"tools\": 80,\n",
    "            \"certifications\": 88,\n",
    "            \"responsibilities\": 83,\n",
    "            \"education\": 87\n",
    "        }\n",
    "    },\n",
    "    \"weights\": {\n",
    "        \"skills\": {\n",
    "            \"exact\": 1.0,\n",
    "            \"substring\": 0.8,\n",
    "            \"fuzzy\": 0.5\n",
    "        },\n",
    "        \"tools\": {\n",
    "            \"exact\": 1.0,\n",
    "            \"substring\": 0.7,\n",
    "            \"fuzzy\": 0.4\n",
    "        },\n",
    "        \"certifications\": {\n",
    "            \"exact\": 1.0,\n",
    "            \"substring\": 0.9,\n",
    "            \"fuzzy\": 0.5\n",
    "        },\n",
    "        \"responsibilities\": {\n",
    "            \"exact\": 1.0,\n",
    "            \"substring\": 0.85,\n",
    "            \"fuzzy\": 0.5\n",
    "        },\n",
    "        \"education\": {\n",
    "            \"exact\": 1.0,\n",
    "            \"substring\": 0.75,\n",
    "            \"fuzzy\": 0.5\n",
    "        }\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "53494bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rapidfuzz import fuzz\n",
    "import re\n",
    "from typing import List, Tuple, Dict, Any\n",
    "from unidecode import unidecode\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "62163dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(text: str) -> str:\n",
    "    text = unidecode(text.lower())\n",
    "    text = re.sub(r\"[^\\w\\s]\", \" \", text)\n",
    "    return re.sub(r\"\\s+\", \" \", text).strip()\n",
    "\n",
    "def normalize_score(score: float) -> float:\n",
    "    return max(0.0, min(round(score, 3), 1.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "76af97bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hybrid_match(jd_terms: List[str], resume_text: str, section: str) -> Tuple[Dict[str, int], List[Dict[str, str]]]:\n",
    "    \"\"\"\n",
    "    Classifies JD terms matched in resume_text as 'exact', 'substring', or 'fuzzy'.\n",
    "    Returns match counts and match breakdown list.\n",
    "    \"\"\"\n",
    "    if not jd_terms:\n",
    "        return {\"exact\": 0, \"substring\": 0, \"fuzzy\": 0}, []\n",
    "\n",
    "\n",
    "    fuzzy_threshold = scoring_config[\"matching\"].get(\"section_thresholds\", {}).get(\n",
    "        section,\n",
    "        scoring_config[\"matching\"].get(\"fuzzy_threshold_default\", 85)\n",
    "    )\n",
    "    resume_tokens = set(re.findall(r\"\\b[\\w\\+\\-\\.#]{3,}\\b\", resume_text.lower()))\n",
    "    normalized_text = normalize(resume_text)\n",
    "\n",
    "    counts = {\"exact\": 0, \"substring\": 0, \"fuzzy\": 0}\n",
    "    matched_terms = []\n",
    "\n",
    "    for term in jd_terms:\n",
    "        normalized_term = normalize(term)\n",
    "\n",
    "        if normalized_term in resume_tokens:\n",
    "            counts[\"exact\"] += 1\n",
    "            matched_terms.append({\"term\": term, \"type\": \"exact\"})\n",
    "        elif normalized_term in normalized_text:\n",
    "            counts[\"substring\"] += 1\n",
    "            matched_terms.append({\"term\": term, \"type\": \"substring\"})\n",
    "        elif fuzz.partial_ratio(normalized_term, normalized_text) >= fuzzy_threshold:\n",
    "            counts[\"fuzzy\"] += 1\n",
    "            matched_terms.append({\"term\": term, \"type\": \"fuzzy\"})\n",
    "\n",
    "    return counts, matched_terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "162e5a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_from_match_counts(counts: Dict[str, int], total: int, weights: Dict[str, float]) -> float:\n",
    "    weighted_sum = (\n",
    "        weights.get(\"exact\", 1.0) * counts[\"exact\"] +\n",
    "        weights.get(\"substring\", 0.8) * counts[\"substring\"] +\n",
    "        weights.get(\"fuzzy\", 0.5) * counts[\"fuzzy\"]\n",
    "    )\n",
    "    return normalize_score(weighted_sum / total) if total else 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9621447e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Dict, Any, Union\n",
    "\n",
    "def flatten_field_values(records: List[Dict[str, Any]], field_name: str) -> str:\n",
    "    lines: List[str] = []\n",
    "    for record in records or []:\n",
    "        value = record.get(field_name)\n",
    "        if isinstance(value, list):\n",
    "            lines.extend([str(v) for v in value if isinstance(v, (str, int, float))])\n",
    "        elif isinstance(value, (str, int, float)):\n",
    "            lines.append(str(value))\n",
    "    return \" \".join(lines)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a27e5128",
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_skills_rule(resume_skills, resume_other, jd_required, jd_optional):\n",
    "    resume_text = (\n",
    "        \" \".join(resume_skills or []) + \" \" +\n",
    "        flatten_field_values(resume_other, \"content\")\n",
    "    )\n",
    "\n",
    "    weights = scoring_config[\"weights\"].get(\"skills\", {\"exact\": 1.0, \"substring\": 0.8, \"fuzzy\": 0.5})\n",
    "\n",
    "    r_counts, r_matches = hybrid_match(jd_required, resume_text, section=\"skills\")\n",
    "    o_counts, o_matches = hybrid_match(jd_optional, resume_text, section=\"skills\")\n",
    "\n",
    "    r_score = score_from_match_counts(r_counts, len(jd_required), weights)\n",
    "    o_score = score_from_match_counts(o_counts, len(jd_optional), weights)\n",
    "\n",
    "    final_score = normalize_score(0.8 * r_score + 0.2 * o_score)\n",
    "    reason = (\n",
    "        f\"Required: {r_counts}, Optional: {o_counts}. \"\n",
    "        f\"Matched skills: {[m['term'] + ' (' + m['type'] + ')' for m in r_matches + o_matches]}\"\n",
    "    )\n",
    "    return final_score, reason\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "eb7febd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_certifications_rule(resume_certs, resume_other, jd_certs):\n",
    "    if not jd_certs:\n",
    "        return 1.0, \"No certifications required by JD.\"\n",
    "\n",
    "    cert_text = (\n",
    "        \" \".join(cert.get(\"certification\", \"\") for cert in resume_certs or []) + \" \" +\n",
    "        flatten_field_values(resume_other, \"content\")\n",
    "    )\n",
    "\n",
    "    weights = scoring_config[\"weights\"].get(\"certifications\", {\"exact\": 1.0, \"substring\": 0.9, \"fuzzy\": 0.5})\n",
    "\n",
    "    counts, matches = hybrid_match(jd_certs, cert_text, section=\"certifications\")\n",
    "    score = score_from_match_counts(counts, len(jd_certs), weights)\n",
    "\n",
    "    reason = f\"Certifications matched: {counts}. Matched: {[m['term'] + ' (' + m['type'] + ')' for m in matches]}\"\n",
    "    return score, reason\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c5b22de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_education_rule(resume_education, jd_degrees):\n",
    "    if not jd_degrees:\n",
    "        return 1.0, \"No preferred degrees listed in JD.\"\n",
    "    if not resume_education:\n",
    "        return 0.0, \"No education information found in resume.\"\n",
    "\n",
    "    resume_text = \" \".join((edu.get(\"degree\", \"\") or \"\") for edu in resume_education)\n",
    "\n",
    "    weights = scoring_config[\"weights\"].get(\"education\", {\"exact\": 1.0, \"substring\": 0.75, \"fuzzy\": 0.5})\n",
    "\n",
    "    counts, matches = hybrid_match(jd_degrees, resume_text, section=\"education\")\n",
    "    score = score_from_match_counts(counts, len(jd_degrees), weights)\n",
    "\n",
    "    reason = f\"Degrees matched: {counts}. Matched: {[m['term'] + ' (' + m['type'] + ')' for m in matches]}\"\n",
    "    return score, reason\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b161703a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_experience_rule(resume_years, jd_required_years, cap: float = 40.0):\n",
    "    if not jd_required_years or resume_years is None:\n",
    "        return 0.5, \"Missing required or actual experience data.\"\n",
    "\n",
    "    numbers = re.findall(r'\\d+(?:\\.\\d+)?', jd_required_years)\n",
    "    if not numbers:\n",
    "        return 1.0, \"JD experience string did not specify clear years.\"\n",
    "\n",
    "    required_years = float(min(numbers))\n",
    "    if required_years == 0:\n",
    "        return 1.0, \"JD required years = 0.\"\n",
    "\n",
    "    resume_years_capped = min(resume_years, cap)\n",
    "    score = resume_years_capped / required_years\n",
    "    reason = f\"Resume: {resume_years} yrs (capped to {resume_years_capped}), JD requires: {required_years} yrs.\"\n",
    "    return normalize_score(score), reason"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b3266e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_tools_rule(resume_skills, resume_experience, resume_other, resume_projects, jd_tools):\n",
    "    if not jd_tools:\n",
    "        return 1.0, \"No tools required by JD.\"\n",
    "\n",
    "    resume_text = (\n",
    "        \" \".join(resume_skills or []) + \" \" +\n",
    "        flatten_field_values(resume_experience, \"description\") + \" \" +\n",
    "        flatten_field_values(resume_other, \"content\") +\n",
    "        flatten_field_values(resume_projects, \"description\")\n",
    "    )\n",
    "\n",
    "    weights = scoring_config[\"weights\"].get(\"tools\", {\"exact\": 1.0, \"substring\": 0.7, \"fuzzy\": 0.4})\n",
    "\n",
    "    counts, matches = hybrid_match(jd_tools, resume_text, section =\"tools\")\n",
    "    score = score_from_match_counts(counts, len(jd_tools), weights)\n",
    "\n",
    "    reason = f\"Tools matched: {counts}. Matched: {[m['term'] + ' (' + m['type'] + ')' for m in matches]}\"\n",
    "    return score, reason\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "20dfeb08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_responsibilities_rule(resume_experience, resume_other, resume_projects, jd_responsibilities):\n",
    "    if not jd_responsibilities:\n",
    "        return 1.0, \"No responsibilities listed in JD.\"\n",
    "\n",
    "    resume_text = (\n",
    "        flatten_field_values(resume_experience, \"description\") + \" \" +\n",
    "        flatten_field_values(resume_other, \"content\") + \" \" +\n",
    "        flatten_field_values(resume_projects, \"description\")\n",
    "    )\n",
    "\n",
    "    weights = scoring_config[\"weights\"].get(\"responsibilities\", {\"exact\": 1.0, \"substring\": 0.85, \"fuzzy\": 0.4})\n",
    "\n",
    "    counts, matches = hybrid_match(jd_responsibilities, resume_text, section=\"responsibilities\")\n",
    "    score = score_from_match_counts(counts, len(jd_responsibilities), weights)\n",
    "\n",
    "    reason = f\"Responsibilities matched: {counts}. Matched: {[m['term'] + ' (' + m['type'] + ')' for m in matches]}\"\n",
    "    return score, reason\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3a24b934",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_all_rule_scores(resume_json: Dict[str, Any], jd_json: Dict[str, Any]) -> Dict[str, Dict[str, Any]]:\n",
    "    scores = {}\n",
    "\n",
    "    skills_score, skills_reason = score_skills_rule(\n",
    "        resume_json.get(\"skills\", []),\n",
    "        resume_json.get(\"other\", []),\n",
    "        jd_json.get(\"required_skills\", []),\n",
    "        jd_json.get(\"optional_skills\", [])\n",
    "    )\n",
    "    scores[\"skills\"] = {\"score\": skills_score, \"reason\": skills_reason}\n",
    "\n",
    "    cert_score, cert_reason = score_certifications_rule(\n",
    "        resume_json.get(\"certifications\", []),\n",
    "        resume_json.get(\"other\", []),\n",
    "        jd_json.get(\"certifications\", [])\n",
    "    )\n",
    "    scores[\"certifications\"] = {\"score\": cert_score, \"reason\": cert_reason}\n",
    "\n",
    "    edu_score, edu_reason = score_education_rule(\n",
    "        resume_json.get(\"education\", []),\n",
    "        jd_json.get(\"preferred_degrees\", [])\n",
    "    )\n",
    "    scores[\"education\"] = {\"score\": edu_score, \"reason\": edu_reason}\n",
    "\n",
    "    exp_score, exp_reason = score_experience_rule(\n",
    "        resume_json.get(\"total_experience_years\", 0.0),\n",
    "        jd_json.get(\"required_experience_years\", \"\")\n",
    "    )\n",
    "    scores[\"experience\"] = {\"score\": exp_score, \"reason\": exp_reason}\n",
    "\n",
    "    tools_score, tools_reason = score_tools_rule(\n",
    "        resume_json.get(\"skills\", []),\n",
    "        resume_json.get(\"experience\", []),\n",
    "        resume_json.get(\"other\", []),\n",
    "        resume_json.get(\"projects\", []),\n",
    "        jd_json.get(\"tools_and_technologies\", [])\n",
    "    )\n",
    "    scores[\"tools\"] = {\"score\": tools_score, \"reason\": tools_reason}\n",
    "\n",
    "    resp_score, resp_reason = score_responsibilities_rule(\n",
    "        resume_json.get(\"experience\", []),\n",
    "        resume_json.get(\"other\", []),\n",
    "        resume_json.get(\"projects\", []),\n",
    "        jd_json.get(\"job_responsibilities\", [])\n",
    "    )\n",
    "    scores[\"responsibilities\"] = {\"score\": resp_score, \"reason\": resp_reason}\n",
    "\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b42629c1",
   "metadata": {},
   "source": [
    "### unit test for each scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d10d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== Testing: score_skills_rule ===\")\n",
    "resume_skills = [\"Python\", \"SQL\", \"Excel\"]\n",
    "resume_other = [{\"section_name\": \"Training\", \"content\": \"Completed MongoDB, Tableau, Excel\"}]\n",
    "jd_required_skills = [\"Python\", \"MongoDB\"]\n",
    "jd_optional_skills = [\"Tableau\", \"Java\"]\n",
    "\n",
    "score, reason = score_skills_rule(resume_skills, resume_other, jd_required_skills, jd_optional_skills)\n",
    "print(f\"Score: {score}\\nReason: {reason}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68848f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== Testing: score_certifications_rule ===\")\n",
    "resume_certs = [{\"certification\": \"AWS Certified\"}, {\"certification\": \"Azure\"}]\n",
    "resume_other = [{\"section_name\": \"Achievements\", \"content\": \"Google Cloud certified\"}]\n",
    "jd_certs = [\"AWS Certified\", \"Google Cloud\"]\n",
    "\n",
    "score, reason = score_certifications_rule(resume_certs, resume_other, jd_certs)\n",
    "print(f\"Score: {score}\\nReason: {reason}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bae023ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== Testing: score_education_rule ===\")\n",
    "resume_education = [{\"degree\": \"Bachelor of Computer Science\"}, {\"degree\": \"MBA\"}]\n",
    "jd_degrees = [\"Computer Science\", \"Information Technology\"]\n",
    "\n",
    "score, reason = score_education_rule(resume_education, jd_degrees)\n",
    "print(f\"Score: {score}\\nReason: {reason}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e42095c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== Testing: score_experience_rule ===\")\n",
    "resume_years = 6.0\n",
    "jd_experience = \"3‚Äì5 years\"\n",
    "\n",
    "score, reason = score_experience_rule(resume_years, jd_experience)\n",
    "print(f\"Score: {score}\\nReason: {reason}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fc2aa04",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== Testing: score_tools_rule ===\")\n",
    "resume_skills = [\"Python\", \"Docker\"]\n",
    "resume_experience = [\n",
    "    {\"job_title\": \"DevOps Engineer\", \"description\": [\"Used AWS, Docker, and Jenkins\"]},\n",
    "    {\"job_title\": \"Software Engineer\", \"description\": [\"Built APIs with Flask\"]}\n",
    "]\n",
    "resume_other = [{\"section_name\": \"Misc\", \"content\": \"Worked on Kubernetes and Terraform\"}]\n",
    "resume_projects = [{\"description\": \"Built ML model with Scikit-learn and deployed on AWS\"}]\n",
    "jd_tools = [\"AWS\", \"Docker\", \"Kubernetes\", \"GCP\"]\n",
    "\n",
    "score, reason = score_tools_rule(resume_skills, resume_experience, resume_other, resume_projects, jd_tools)\n",
    "print(f\"Score: {score}\\nReason: {reason}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "042ea423",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== Testing: score_responsibilities_rule ===\")\n",
    "resume_experience = [\n",
    "    {\"job_title\": \"Data Analyst\", \"description\": [\"Created dashboards using Power BI\", \"Cleaned large datasets\"]},\n",
    "]\n",
    "resume_other = [{\"section_name\": \"Leadership\", \"content\": \"Led team of 5 analysts\"}]\n",
    "resume_projects = [{\"description\": \"Automated data pipeline using Python\"}]\n",
    "jd_responsibilities = [\n",
    "    \"Created dashboards using Power BI\",\n",
    "    \"Automated data pipeline using Python\",\n",
    "    \"Built ETL workflows\"\n",
    "]\n",
    "\n",
    "score, reason = score_responsibilities_rule(resume_experience, resume_other, resume_projects, jd_responsibilities)\n",
    "print(f\"Score: {score}\\nReason: {reason}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e67572f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "print(\"=== Testing: compute_all_rule_scores ===\")\n",
    "\n",
    "resume_json = {\n",
    "    \"skills\": [\"Python\", \"Docker\"],\n",
    "    \"certifications\": [{\"certification\": \"AWS Certified\"}, {\"certification\": \"Azure\"}],\n",
    "    \"education\": [{\"degree\": \"Bachelor of Computer Science\"}, {\"degree\": \"MBA\"}],\n",
    "    \"total_experience_years\": 4.5,\n",
    "    \"experience\": [\n",
    "        {\"job_title\": \"DevOps Engineer\", \"description\": [\"Used AWS, Docker, and Jenkins\"]},\n",
    "        {\"job_title\": \"Data Analyst\", \"description\": [\"Created dashboards using Power BI\"]}\n",
    "    ],\n",
    "    \"other\": [\n",
    "        {\"section_name\": \"Leadership\", \"content\": \"Led team of 5 analysts\"},\n",
    "        {\"section_name\": \"Achievements\", \"content\": \"Google Cloud certified\"}\n",
    "    ],\n",
    "    \"projects\": [\n",
    "        {\"description\": \"Built ML model with Scikit-learn and deployed on AWS\"}\n",
    "    ]\n",
    "}\n",
    "\n",
    "jd_json = {\n",
    "    \"required_skills\": [\"Python\", \"MongoDB\"],\n",
    "    \"optional_skills\": [\"Tableau\", \"Java\"],\n",
    "    \"certifications\": [\"AWS Certified\", \"Google Cloud\"],\n",
    "    \"preferred_degrees\": [\"Computer Science\", \"Information Technology\"],\n",
    "    \"required_experience_years\": \"3+ years\",\n",
    "    \"tools_and_technologies\": [\"AWS\", \"Docker\", \"Kubernetes\", \"GCP\"],\n",
    "    \"job_responsibilities\": [\n",
    "        \"Created dashboards using Power BI\",\n",
    "        \"Automated data pipeline using Python\",\n",
    "        \"Built ETL workflows\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "results = compute_all_rule_scores(resume_json, jd_json)\n",
    "\n",
    "\n",
    "pprint(results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b948ff22",
   "metadata": {},
   "source": [
    "## LLM-Based Scoring Functions (Structured Prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c4f8cffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "LLM_SCORING_SCHEMA = \"\"\"{\n",
    "  \"skills\": {\n",
    "    \"score\": float,\n",
    "    \"reason\": str\n",
    "  },\n",
    "  \"certifications\": {\n",
    "    \"score\": float,\n",
    "    \"reason\": str\n",
    "  },\n",
    "  \"education\": {\n",
    "    \"score\": float,\n",
    "    \"reason\": str\n",
    "  },\n",
    "  \"experience\": {\n",
    "    \"score\": float,\n",
    "    \"reason\": str\n",
    "  },\n",
    "  \"tools\": {\n",
    "    \"score\": float,\n",
    "    \"reason\": str\n",
    "  },\n",
    "  \"responsibilities\": {\n",
    "    \"score\": float,\n",
    "    \"reason\": str\n",
    "  },\n",
    "  \"soft_skills\": {\n",
    "    \"score\": float,\n",
    "    \"reason\": str\n",
    "  },\n",
    "  \"transferable_skills\": {\n",
    "    \"score\": float,\n",
    "    \"reason\": str\n",
    "  },\n",
    "  \"leadership\": {\n",
    "    \"score\": float,\n",
    "    \"reason\": str\n",
    "  },\n",
    "  \"grammar_cleanliness\": {\n",
    "    \"score\": float,\n",
    "    \"reason\": str\n",
    "  }\n",
    "}\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "54453faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "LLM_SCORING_PROMPT_TEMPLATE = \"\"\"\n",
    "You are an expert resume evaluator.\n",
    "\n",
    "Your task is to **compare** a candidate's resume and a job description and assign **section-wise ATS scores**. Each section receives:\n",
    "- a score between 0.0 and 1.0\n",
    "- a short reason explaining why\n",
    "\n",
    "You must return a valid JSON object. Do not return the resume. Do not repeat input. Do not include markdown or explanations.\n",
    "\n",
    "RESUME:\n",
    "{resume_json}\n",
    "\n",
    "JOB DESCRIPTION:\n",
    "{jd_json}\n",
    "\n",
    "Output format (STRICTLY FOLLOW THIS STRUCTURE):\n",
    "{schema}\n",
    "\n",
    "Now respond ONLY with a JSON object in this format:\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "381ad05e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import regex\n",
    "import json5\n",
    "from typing import Dict\n",
    "\n",
    "def extract_json_block(text: str) -> Dict:\n",
    "    \"\"\"\n",
    "    Extract the last valid JSON object block from the text using recursive regex and json5.\n",
    "    Handles smart quotes, trailing commas, and prefers LLM's final output JSON.\n",
    "    \"\"\"\n",
    "    # Normalize smart quotes\n",
    "    text = text.replace(\"‚Äú\", \"\\\"\").replace(\"‚Äù\", \"\\\"\").replace(\"‚Äò\", \"'\").replace(\"‚Äô\", \"'\")\n",
    "\n",
    "    # Match all nested JSON-like blocks\n",
    "    matches = regex.findall(r\"\\{(?:[^{}]|(?R))*\\}\", text, flags=regex.DOTALL)\n",
    "\n",
    "    expected_keys = {\"skills\", \"experience\", \"education\", \"certifications\"}\n",
    "\n",
    "    for block in reversed(matches):\n",
    "        try:\n",
    "            parsed = json5.loads(block)\n",
    "            if isinstance(parsed, dict) and expected_keys.intersection(parsed.keys()):\n",
    "                return parsed\n",
    "        except Exception:\n",
    "            continue\n",
    "\n",
    "    print(\"‚ùå No valid JSON block found in LLM output.\")\n",
    "    print(\"üîé Last few lines:\\n\", text[-500:])\n",
    "    raise ValueError(\"No valid JSON block found.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5c2c4afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_with_llm(resume_json: dict, jd_json: dict, resume_id=\"resume\", jd_id=\"jd\") -> dict:\n",
    "    \"\"\"\n",
    "    Use an LLM pipeline to compute ATS scores with reasoning per section.\n",
    "    \"\"\"\n",
    "    prompt = LLM_SCORING_PROMPT_TEMPLATE.format(\n",
    "        schema=LLM_SCORING_SCHEMA,\n",
    "        resume_json=json.dumps(resume_json, indent=2),\n",
    "        jd_json=json.dumps(jd_json, indent=2)\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        outputs = llm_pipeline(\n",
    "            prompt,\n",
    "            max_new_tokens=1024,\n",
    "            do_sample=False,\n",
    "            temperature=None,\n",
    "            top_p=None,\n",
    "            top_k=None,\n",
    "            pad_token_id=llm_pipeline.tokenizer.pad_token_id\n",
    "        )\n",
    "        response_text = outputs[0][\"generated_text\"]\n",
    "        #print(\"üí¨ LLM response preview:\\n\", response_text)  \n",
    "\n",
    "        return extract_json_block(response_text)\n",
    "        \n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå LLM inference failed for {resume_id} x {jd_id}: {str(e)}\")\n",
    "        print(\"üß™ Raw output preview:\\n\", response_text)\n",
    "        return {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8f5d7b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "print(\"=== Testing: score_with_llm ===\")\n",
    "\n",
    "# Sample resume JSON\n",
    "resume_json = {\n",
    "    \"skills\": [\"Python\", \"Docker\"],\n",
    "    \"certifications\": [{\"certification\": \"AWS Certified\"}, {\"certification\": \"Azure\"}],\n",
    "    \"education\": [{\"degree\": \"Bachelor of Computer Science\"}, {\"degree\": \"MBA\"}],\n",
    "    \"total_experience_years\": 4.5,\n",
    "    \"experience\": [\n",
    "        {\"job_title\": \"DevOps Engineer\", \"description\": [\"Used AWS, Docker, and Jenkins\"]},\n",
    "        {\"job_title\": \"Data Analyst\", \"description\": [\"Created dashboards using Power BI\"]}\n",
    "    ],\n",
    "    \"other\": [\n",
    "        {\"section_name\": \"Leadership\", \"content\": \"Led team of 5 analysts\"},\n",
    "        {\"section_name\": \"Achievements\", \"content\": \"Google Cloud certified\"}\n",
    "    ],\n",
    "    \"projects\": [\n",
    "        {\"description\": \"Built ML model with Scikit-learn and deployed on AWS\"}\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Sample job description JSON\n",
    "jd_json = {\n",
    "    \"required_skills\": [\"Python\", \"MongoDB\"],\n",
    "    \"optional_skills\": [\"Tableau\", \"Java\"],\n",
    "    \"certifications\": [\"AWS Certified\", \"Google Cloud\"],\n",
    "    \"preferred_degrees\": [\"Computer Science\", \"Information Technology\"],\n",
    "    \"required_experience_years\": \"3+ years\",\n",
    "    \"tools_and_technologies\": [\"AWS\", \"Docker\", \"Kubernetes\", \"GCP\"],\n",
    "    \"job_responsibilities\": [\n",
    "        \"Created dashboards using Power BI\",\n",
    "        \"Automated data pipeline using Python\",\n",
    "        \"Built ETL workflows\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Run LLM-based scoring\n",
    "llm_scores = score_with_llm(resume_json, jd_json)\n",
    "\n",
    "print(\"=== LLM Scoring Output ===\")\n",
    "pprint(llm_scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4fef8f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "print(\"=== Testing: score_with_llm ===\")\n",
    "\n",
    "# Sample resume JSON\n",
    "resume_json = {\n",
    "            \"resume_id\": 88907739,\n",
    "            \"total_experience_years\": 11.3,\n",
    "            \"summary\": \"High-achieving management professional and effective consultant possessing excellent communication, organizational and analytical capabilities with about 4 years of experience in devising innovative strategies and solutions to resolve complex business challenges.\",\n",
    "            \"education\": [\n",
    "                {\n",
    "                    \"degree\": \"Master of Science\",\n",
    "                    \"field\": \"Software Management\",\n",
    "                    \"institution\": \"Carnegie Mellon University\",\n",
    "                    \"year\": \",\",\n",
    "                    \"gpa\": 3.8\n",
    "                },\n",
    "                {\n",
    "                    \"degree\": \"MBA\",\n",
    "                    \"field\": \"International Business\",\n",
    "                    \"institution\": \"Institute of Technology & Management\",\n",
    "                    \"year\": \",\",\n",
    "                    \"gpa\": 4.0\n",
    "                },\n",
    "                {\n",
    "                    \"degree\": \"MBA\",\n",
    "                    \"field\": \"International Business\",\n",
    "                    \"institution\": \"International Business Institute of Technology and Management India\",\n",
    "                    \"year\": \",\",\n",
    "                    \"gpa\": 4.0\n",
    "                }\n",
    "            ],\n",
    "            \"experience\": [\n",
    "                {\n",
    "                    \"job_title\": \"Consultant\",\n",
    "                    \"company\": \"Company Name\",\n",
    "                    \"start_date\": \"06/2015\",\n",
    "                    \"end_date\": \"Current\",\n",
    "                    \"description\": [\n",
    "                        \"Managed and delivered a project to implement and integrate a new content management platform to create a unified brand experience, support scalability, growth and enhance digital presence for client's business - post acquisition\",\n",
    "                        \"Led cross-functional global teams consisting of technical, business and functional representatives and achieved key milestones on time with quality deliverables\",\n",
    "                        \"Prioritized, escalated and resolved issues with internal and external stakeholders\",\n",
    "                        \"Directly managed 3rd party vendor and offshore teams.\"\n",
    "                    ]\n",
    "                },\n",
    "                {\n",
    "                    \"job_title\": \"Product Strategy Intern\",\n",
    "                    \"company\": \"Company Name\",\n",
    "                    \"start_date\": \"09/2015\",\n",
    "                    \"end_date\": \"12/2015\",\n",
    "                    \"description\": [\n",
    "                        \"Led a practicum team at Carnegie Mellon University to understand IBM Bluemix (PaaS), cloud based solution and use business frameworks to perform market, competitor and customer journey analysis\",\n",
    "                        \"Liaised with cross functional teams to assess opportunities in marketplace, determine synergies and align business unit goals with corporate strategy\",\n",
    "                        \"Worked with senior management and stakeholders to develop strategy for to enhance awareness, increase conversion and explore new market opportunities to scale the client's user base.\"\n",
    "                    ]\n",
    "                },\n",
    "                {\n",
    "                    \"job_title\": \"Assistant Operations Manager\",\n",
    "                    \"company\": \"Company Name\",\n",
    "                    \"start_date\": \"07/2012\",\n",
    "                    \"end_date\": \"10/2013\",\n",
    "                    \"description\": [\n",
    "                        \"Business Strategy & Vendor Management: Automation of Hub, typical model and replication\",\n",
    "                        \"Reported to Chief Operating Officer to recommend company wide automation strategies and vendor selection\",\n",
    "                        \"Conducted gap analysis, market research, competitor and financial analysis to propose short, mid and long term strategies to the Executive team\",\n",
    "                        \"Project Management: RFID Project Member of the core project management team responsible for coordinated of cross-functional teams to achieve project milestones\",\n",
    "                        \"Focused on process improvement and optimization to enhance team productivity\",\n",
    "                        \"Defined the Key Performance Indicator's to evaluate vendors.\"\n",
    "                    ]\n",
    "                }\n",
    "            ],\n",
    "            \"skills\": [\n",
    "                \"Strategy & Operations Process Optimization\",\n",
    "                \"Digital Transformation\",\n",
    "                \"Cross Functional Team Management\",\n",
    "                \"Project/Product Management\",\n",
    "                \"Agile/Lean Methodologies\",\n",
    "                \"Work History\",\n",
    "                \"Client\",\n",
    "                \"Data Analysis\",\n",
    "                \"E-Commerce\",\n",
    "                \"senior management\",\n",
    "                \"Financial\",\n",
    "                \"financial analysis\",\n",
    "                \"functional\",\n",
    "                \"Google Analytics\",\n",
    "                \"Government\",\n",
    "                \"Hub\",\n",
    "                \"IBM\",\n",
    "                \"International Business\",\n",
    "                \"investments\",\n",
    "                \"IP\",\n",
    "                \"Marketing plan\",\n",
    "                \"market research\",\n",
    "                \"Market Strategy\",\n",
    "                \"marketing\",\n",
    "                \"market\",\n",
    "                \"MBA\",\n",
    "                \".NET\",\n",
    "                \"academic\",\n",
    "                \"ADA\",\n",
    "                \"Adobe\",\n",
    "                \"Apple\",\n",
    "                \"approach\",\n",
    "                \"Automation\",\n",
    "                \"business development\",\n",
    "                \"Business Process\",\n",
    "                \"Business Strategy\",\n",
    "                \"Consulting\",\n",
    "                \"content management\",\n",
    "                \"Conversion\",\n",
    "                \"Client\",\n",
    "                \"Data Analysis\",\n",
    "                \"E-Commerce\",\n",
    "                \"senior management\",\n",
    "                \"Financial\",\n",
    "                \"financial analysis\",\n",
    "                \"functional\",\n",
    "                \"Google Analytics\",\n",
    "                \"Government\",\n",
    "                \"Hub\",\n",
    "                \"IBM\",\n",
    "                \"International Business\",\n",
    "                \"investments\",\n",
    "                \"IP\",\n",
    "                \"Marketing plan\",\n",
    "                \"market research\",\n",
    "                \"Market Strategy\",\n",
    "                \"marketing\",\n",
    "                \"market\",\n",
    "                \"MBA\",\n",
    "                \"C#\",\n",
    "                \"Excel\",\n",
    "                \"Microsoft Office Suite\",\n",
    "                \"Power Point\",\n",
    "                \"Word\",\n",
    "                \"Network\",\n",
    "                \"Object Oriented Analysis and Design\",\n",
    "                \"optimization\",\n",
    "                \"policies\",\n",
    "                \"process improvement\",\n",
    "                \"Project Management\",\n",
    "                \"proposals\",\n",
    "                \"quality\",\n",
    "                \"Requirement\",\n",
    "                \"Research\",\n",
    "                \"RFP\",\n",
    "                \"Scrum\",\n",
    "                \"SDLC\",\n",
    "                \"Speech\",\n",
    "                \"MS SQL\",\n",
    "                \"Strategy\",\n",
    "                \"Strategy Development\",\n",
    "                \"Vendor Management\",\n",
    "                \"Management\",\n",
    "                \"Visio\",\n",
    "                \"websites\"\n",
    "            ],\n",
    "            \"certifications\": [],\n",
    "            \"projects\": [\n",
    "                {\n",
    "                    \"project_title\": \"Online E-commerce store\",\n",
    "                    \"description\": \"Conceptualized and launched Online E-commerce store, developed Product Strategy and Roadmap, and produced Engineering, Financial and Marketing plan\",\n",
    "                    \"start_date\": \"08/2014\",\n",
    "                    \"end_date\": \"12/2015\"\n",
    "                },\n",
    "                {\n",
    "                    \"project_title\": \"Commercialization of IP\",\n",
    "                    \"description\": \"Developed Go-to-Market Strategy, Product Roadmap and proposed Business Model to launch CMU's Automatic Speech Recognition Technology and presented to Sand Hill Angel Investors\",\n",
    "                    \"start_date\": \"08/2014\",\n",
    "                    \"end_date\": \"12/2015\"\n",
    "                },\n",
    "                {\n",
    "                    \"project_title\": \"Survivable Social Network on Chip\",\n",
    "                    \"description\": \"Performed Object Oriented Analysis and Design along with the estimation, planning, development, measurement and tracking of the software project using the hybrid development approach\",\n",
    "                    \"start_date\": \"08/2014\",\n",
    "                    \"end_date\": \"12/2015\"\n",
    "                }\n",
    "            ],\n",
    "            \"languages\": [],\n",
    "            \"other\": []\n",
    "        }\n",
    "\n",
    "# Sample job description JSON\n",
    "jd_json = {\n",
    "            \"jd_id\": 3906094741,\n",
    "            \"inferred_domain\": \"consulting\",\n",
    "            \"title\": \"Director, Property Tax\",\n",
    "            \"summary\": \"Director, Property Tax role at Kroll, focusing on tax consulting and valuation projects.\",\n",
    "            \"required_experience_years\": \"7\",\n",
    "            \"preferred_degrees\": [\n",
    "                \"Accounting\",\n",
    "                \"Economics\",\n",
    "                \"Finance\",\n",
    "                \"Management\",\n",
    "                \"Real Estate\"\n",
    "            ],\n",
    "            \"required_skills\": [\n",
    "                \"Management\",\n",
    "                \"Sales\"\n",
    "            ],\n",
    "            \"optional_skills\": [],\n",
    "            \"tools_and_technologies\": [\n",
    "                \"Excel\",\n",
    "                \"Word\",\n",
    "                \"PowerPoint\"\n",
    "            ],\n",
    "            \"certifications\": [\n",
    "                \"ASA\",\n",
    "                \"CPA\",\n",
    "                \"CFA\",\n",
    "                \"MAI\"\n",
    "            ],\n",
    "            \"soft_skills\": [\n",
    "                \"Leadership\",\n",
    "                \"Client Relationship Management\",\n",
    "                \"Analytical Skills\",\n",
    "                \"Independence\",\n",
    "                \"Teamwork\",\n",
    "                \"Communication\",\n",
    "                \"Diversity Awareness\"\n",
    "            ],\n",
    "            \"job_responsibilities\": [\n",
    "                \"Client Research\",\n",
    "                \"Data Analysis\",\n",
    "                \"Presentation Development\",\n",
    "                \"Valuation Techniques\",\n",
    "                \"Tax Hearing Preparation\",\n",
    "                \"Project Reporting\",\n",
    "                \"Tax Projection Scenarios\",\n",
    "                \"Business Solution Implementation\",\n",
    "                \"Junior Staff Development\",\n",
    "                \"Practice Growth\"\n",
    "            ],\n",
    "            \"job_location\": \"Atlanta, GA\",\n",
    "            \"remote_option\": \",\",\n",
    "            \"employment_type\": \"full-time\",\n",
    "            \"travel_requirements\": \"N/A\",\n",
    "            \"physical_requirements\": \"N/A\",\n",
    "            \"benefits\": [],\n",
    "            \"company_information\": \"Kroll is a global firm providing services in governance, risk, and transparency.\",\n",
    "            \"equal_opportunity_policy\": \"Kroll is committed to creating an inclusive work environment and is an equal opportunity employer.\",\n",
    "            \"other\": [\n",
    "                {\n",
    "                    \"section_name\": \"Experience Level\",\n",
    "                    \"content\": \"Director\"\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "\n",
    "# Run LLM-based scoring\n",
    "llm_scores = score_with_llm(resume_json, jd_json)\n",
    "\n",
    "print(\"=== LLM Scoring Output ===\")\n",
    "pprint(llm_scores)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4e71a89",
   "metadata": {},
   "source": [
    "## Combine Section Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0e152afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_weights_config = {\n",
    "    \"skills\": {\"rule\": 0.6, \"llm\": 0.4},\n",
    "    \"certifications\": {\"rule\": 0.5, \"llm\": 0.5},\n",
    "    \"education\": {\"rule\": 0.5, \"llm\": 0.5},\n",
    "    \"experience\": {\"rule\": 0.5, \"llm\": 0.5},\n",
    "    \"tools\": {\"rule\": 0.6, \"llm\": 0.4},\n",
    "    \"responsibilities\": {\"rule\": 0.5, \"llm\": 0.5},\n",
    "    \"soft_skills\": {\"rule\": 0.0, \"llm\": 1.0},\n",
    "    \"transferable_skills\": {\"rule\": 0.0, \"llm\": 1.0},\n",
    "    \"leadership\": {\"rule\": 0.0, \"llm\": 1.0},\n",
    "    \"grammar_cleanliness\": {\"rule\": 0.0, \"llm\": 1.0}\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1830d9f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, Any\n",
    "\n",
    "def merge_scores(rule_scores: Dict[str, Dict[str, Any]],\n",
    "                 llm_scores: Dict[str, Dict[str, Any]],\n",
    "                 weights_config: Dict[str, Dict[str, float]]) -> Dict[str, Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Merges rule-based and LLM-based scores using weighted averages and combines reasons.\n",
    "    Returns final section-wise score dictionary.\n",
    "    \"\"\"\n",
    "    merged = {}\n",
    "    all_sections = set(rule_scores) | set(llm_scores)\n",
    "\n",
    "    for section in sorted(all_sections):\n",
    "        rule = rule_scores.get(section, {})\n",
    "        llm = llm_scores.get(section, {})\n",
    "\n",
    "        rule_score = rule.get(\"score\", 0.0)\n",
    "        llm_score = llm.get(\"score\", 0.0)\n",
    "        rule_reason = rule.get(\"reason\", \"\")\n",
    "        llm_reason = llm.get(\"reason\", \"\")\n",
    "\n",
    "        weights = weights_config.get(section, {\"rule\": 0.5, \"llm\": 0.5})\n",
    "        final_score = (rule_score * weights[\"rule\"]) + (llm_score * weights[\"llm\"])\n",
    "\n",
    "        merged_reason = f\"(Rule {weights['rule']:.1f}): {rule_reason} | (LLM {weights['llm']:.1f}): {llm_reason}\"\n",
    "\n",
    "        merged[section] = {\n",
    "            \"score\": round(final_score, 3),\n",
    "            \"reason\": merged_reason\n",
    "        }\n",
    "\n",
    "    return merged\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8bf44863",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_total_ats_score(merged_scores: Dict[str, Dict[str, Any]],\n",
    "                            section_weights: Dict[str, float]) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Computes the final weighted ATS score from merged section scores.\n",
    "    Returns dict with final score and breakdown.\n",
    "    \"\"\"\n",
    "    total_weight = sum(section_weights.values())\n",
    "    if total_weight == 0:\n",
    "        raise ValueError(\"Total section weights must be greater than zero.\")\n",
    "\n",
    "    weighted_sum = 0.0\n",
    "    breakdown = []\n",
    "\n",
    "    for section, weight in section_weights.items():\n",
    "        score = merged_scores.get(section, {}).get(\"score\", 0.0)\n",
    "        weighted_sum += score * weight\n",
    "        breakdown.append(f\"{section}: {score:.2f} √ó {weight:.2f}\")\n",
    "\n",
    "    final_score = round(weighted_sum / total_weight, 3)\n",
    "    return {\n",
    "        \"final_ats_score\": final_score,\n",
    "        \"explanation\": f\"Weighted average across sections ‚Üí {' | '.join(breakdown)}\"\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "06ffb6c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "section_weights_config = {\n",
    "    \"skills\": 0.15,\n",
    "    \"certifications\": 0.10,\n",
    "    \"education\": 0.10,\n",
    "    \"experience\": 0.20,\n",
    "    \"tools\": 0.10,\n",
    "    \"responsibilities\": 0.15,\n",
    "    \"soft_skills\": 0.05,\n",
    "    \"transferable_skills\": 0.05,\n",
    "    \"leadership\": 0.05,\n",
    "    \"grammar_cleanliness\": 0.05\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "349a56e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "print(\"=== Testing: merge_scores and compute_total_ats_score ===\")\n",
    "\n",
    "# Sample rule-based scores\n",
    "rule_scores = {\n",
    "    \"skills\": {\"score\": 0.6, \"reason\": \"Rule: Matched some required skills.\"},\n",
    "    \"certifications\": {\"score\": 0.4, \"reason\": \"Rule: No direct certification match.\"},\n",
    "    \"education\": {\"score\": 0.9, \"reason\": \"Rule: Degree aligned well.\"},\n",
    "    \"experience\": {\"score\": 1.0, \"reason\": \"Rule: Resume years > JD years.\"},\n",
    "    \"tools\": {\"score\": 0.5, \"reason\": \"Rule: Partial tool match.\"},\n",
    "    \"responsibilities\": {\"score\": 0.3, \"reason\": \"Rule: Low overlap on tasks.\"}\n",
    "}\n",
    "\n",
    "# Sample LLM-based scores\n",
    "llm_scores = {\n",
    "    \"skills\": {\"score\": 0.8, \"reason\": \"LLM: Python and Docker match JD.\"},\n",
    "    \"certifications\": {\"score\": 0.6, \"reason\": \"LLM: AWS match, missing GCP.\"},\n",
    "    \"education\": {\"score\": 0.7, \"reason\": \"LLM: One degree matches preferred list.\"},\n",
    "    \"experience\": {\"score\": 0.7, \"reason\": \"LLM: Related roles, less domain alignment.\"},\n",
    "    \"tools\": {\"score\": 0.4, \"reason\": \"LLM: Excel mentioned, others missing.\"},\n",
    "    \"responsibilities\": {\"score\": 0.2, \"reason\": \"LLM: Few relevant duties matched.\"},\n",
    "    \"soft_skills\": {\"score\": 0.5, \"reason\": \"LLM: Communication and teamwork evident.\"},\n",
    "    \"transferable_skills\": {\"score\": 0.4, \"reason\": \"LLM: PM and cross-functional skills.\"},\n",
    "    \"leadership\": {\"score\": 0.6, \"reason\": \"LLM: Led global teams in resume.\"},\n",
    "    \"grammar_cleanliness\": {\"score\": 0.9, \"reason\": \"LLM: Clean formatting and language.\"}\n",
    "}\n",
    "\n",
    "\n",
    "# Merge section scores\n",
    "merged_scores = merge_scores(rule_scores, llm_scores, merge_weights_config)\n",
    "\n",
    "# Print merged scores\n",
    "print(\"\\n=== Merged Scores ===\")\n",
    "pprint(merged_scores)\n",
    "\n",
    "# Compute total ATS score\n",
    "final_result = compute_total_ats_score(merged_scores, section_weights_config)\n",
    "\n",
    "# Print final ATS score\n",
    "print(\"\\n=== Final ATS Score ===\")\n",
    "pprint(final_result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e97597c9",
   "metadata": {},
   "source": [
    "## Utilities to load semantic matching Resume-JD and find matching pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d4462daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Tuple\n",
    "import os\n",
    "\n",
    "# ‚úÖ Updated: Load and filter relevant resume‚ÄìJD pairs\n",
    "def find_matching_pairs(\n",
    "    relevance_json_path: str,\n",
    "    match_labels: List[str] = [\"strong\", \"medium\", \"weak\"]\n",
    ") -> List[Tuple[int, int]]:\n",
    "    \"\"\"\n",
    "    Load relevance map and return (resume_id, jd_id) tuples for selected match labels.\n",
    "    \"\"\"\n",
    "    data = load_json_file(relevance_json_path)\n",
    "    results = data.get(\"semantic_relevance_scores\", [])\n",
    "\n",
    "    filtered_pairs = [\n",
    "        (item[\"resume_id\"], item[\"jd_id\"])\n",
    "        for item in results\n",
    "        if item.get(\"semantic_match_label\") in match_labels\n",
    "    ]\n",
    "    return filtered_pairs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f62c08a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Found 46775 matching resume‚ÄìJD pairs\n",
      "[(28424982, 3905271776), (20624984, 3904362493), (17252448, 3887474760), (62850928, 3905370105), (15620421, 3905326001)]\n"
     ]
    }
   ],
   "source": [
    "relevance_map_file = os.path.join(Config.JSON_OUTPUT_SCORING_DIR, 'relevant_pairs.json')\n",
    "matching_pairs = find_matching_pairs(relevance_map_file, match_labels=[\"strong\", \"medium\", \"weak\"])\n",
    "\n",
    "print(f\"‚úÖ Found {len(matching_pairs)} matching resume‚ÄìJD pairs\")\n",
    "print(matching_pairs[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "63e7c7da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_match_metadata(resume_id: str, jd_id: str, relevance_map: Dict[str, List[Dict]]) -> Dict:\n",
    "    for entry in relevance_map.get(\"semantic_relevance_scores\", []):\n",
    "        if str(entry[\"resume_id\"]) == str(resume_id) and str(entry[\"jd_id\"]) == str(jd_id):\n",
    "            return {\n",
    "                \"domain\": entry.get(\"resume_domain\", \"\"),\n",
    "                \"resume_jd_similarity\": entry.get(\"resume_jd_similarity\", 0.0),\n",
    "                \"semantic_match_label\": entry.get(\"semantic_match_label\", \"weak\")\n",
    "            }\n",
    "    raise ValueError(f\"No semantic match metadata found for resume_id={resume_id}, jd_id={jd_id}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b7b0994",
   "metadata": {},
   "source": [
    "## Phase 3: Scoring Loop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e1d129a",
   "metadata": {},
   "source": [
    "### Checkpoint Handling (JSON)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ef277819",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timezone\n",
    "\n",
    "def load_resume_checkpoint(path: str) -> int:\n",
    "    if not os.path.exists(path):\n",
    "        return 0\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as file:\n",
    "        return json.load(file).get(\"last_index\", 0)\n",
    "\n",
    "def save_resume_checkpoint(path: str, index: int):\n",
    "    data = {\n",
    "        \"last_index\": index,\n",
    "        \"timestamp\": datetime.now(timezone.utc).isoformat()\n",
    "    }\n",
    "    save_json_output(data, path)\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e5c063c",
   "metadata": {},
   "source": [
    "### Scoring a Single Resume-JD Pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "bb267f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Dict, Optional, Any\n",
    "from pathlib import Path\n",
    "\n",
    "def find_record_by_id(\n",
    "    records: List[Dict[str, Any]],\n",
    "    record_id: str,\n",
    "    id_field: str = \"record_id\"\n",
    ") -> Optional[Dict[str, Any]]:\n",
    "    \"\"\"Finds a record in a list of dicts by a specified record ID field.\"\"\"\n",
    "    return next((r for r in records if str(r.get(id_field)) == str(record_id)), None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1815e470",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "def score_resume_vs_jd(\n",
    "    resume_id: str,\n",
    "    jd_id: str,\n",
    "    resume_json_dir: str,\n",
    "    jd_json_dir: str,\n",
    "    relevance_map: Dict[str, List[Dict]],\n",
    ") -> Dict:\n",
    "    # Load resume + JD parsed JSONs\n",
    "    resume_files = list(Path(resume_json_dir).glob(f\"resumes_{resume_id}_*.json\"))\n",
    "    jd_files = list(Path(jd_json_dir).glob(f\"jds_{jd_id}_*.json\"))\n",
    "\n",
    "    if not resume_files:\n",
    "        raise FileNotFoundError(f\"No resume file found for resume_id: {resume_id}\")\n",
    "    if not jd_files:\n",
    "        raise FileNotFoundError(f\"No JD file found for jd_id: {jd_id}\")\n",
    "\n",
    "    resume_records = load_json_file(str(resume_files[0]))\n",
    "    jd_records = load_json_file(str(jd_files[0]))\n",
    "\n",
    "\n",
    "    resume_record = find_record_by_id(resume_records, resume_id)\n",
    "    jd_record = find_record_by_id(jd_records, jd_id)\n",
    "\n",
    "\n",
    "    if not resume_record:\n",
    "        raise ValueError(f\"Resume record_id {resume_id} not found in file {resume_files[0].name}\")\n",
    "    if not jd_record:\n",
    "        raise ValueError(f\"JD record_id {jd_id} not found in file {jd_files[0].name}\")\n",
    "\n",
    "    resume_data = resume_record.get(\"output_json\", {})\n",
    "    jd_data = jd_record.get(\"output_json\", {})\n",
    "\n",
    "\n",
    "    # Rule-based scores\n",
    "    rule_scores = compute_all_rule_scores(resume_data, jd_data)\n",
    "\n",
    "    # LLM-based scores\n",
    "    llm_scores = score_with_llm(resume_data, jd_data, resume_id=resume_id, jd_id=jd_id)\n",
    "\n",
    "    # Merge section-wise scores\n",
    "    section_scores = merge_scores(rule_scores, llm_scores, merge_weights_config)\n",
    "\n",
    "    # Compute final ATS score\n",
    "    final_score_result = compute_total_ats_score(section_scores, section_weights_config)\n",
    "    final_score = final_score_result[\"final_ats_score\"]\n",
    "\n",
    "    # Derive match quality from final ATS score\n",
    "    if final_score >= 0.75:\n",
    "        match_quality = \"strong\"\n",
    "    elif final_score >= 0.5:\n",
    "        match_quality = \"medium\"\n",
    "    else:\n",
    "        match_quality = \"weak\"\n",
    "\n",
    "    # Enrich with metadata from semantic map\n",
    "    match_meta = get_match_metadata(resume_id, jd_id, relevance_map)\n",
    "\n",
    "    return {\n",
    "        \"resume_id\": resume_id,\n",
    "        \"jd_id\": jd_id,\n",
    "        \"domain\": match_meta[\"domain\"],\n",
    "        \"resume_jd_similarity\": match_meta[\"resume_jd_similarity\"],\n",
    "        \"semantic_match_label\": match_meta[\"semantic_match_label\"],  # Relevance from Phase 1\n",
    "        \"section_scores\": section_scores,\n",
    "        \"match_quality\": match_quality,  # ATS score-based match\n",
    "        \"final_ats_score\": final_score\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0458abd",
   "metadata": {},
   "source": [
    "### Test Single Resume-JD Pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11194bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "import os\n",
    "\n",
    "# === Setup file paths ===\n",
    "relevance_map_file = os.path.join(Config.JSON_OUTPUT_SCORING_DIR, 'semantic_relevance_scores.json')\n",
    "resume_json_dir = Config.JSON_OUTPUT_NORMALIZED_RESUME\n",
    "jd_json_dir = Config.JSON_OUTPUT_NORMALIZED_JD\n",
    "\n",
    "# === Load relevance map ===\n",
    "relevance_map = load_json_file(relevance_map_file)\n",
    "\n",
    "# === Pick a strong match from the top for testing ===\n",
    "sample_pair = None\n",
    "for item in relevance_map[\"semantic_relevance_scores\"]:\n",
    "    if item[\"semantic_match_label\"] == \"strong\":\n",
    "        sample_pair = (item[\"resume_id\"], item[\"jd_id\"])\n",
    "        break\n",
    "\n",
    "if not sample_pair:\n",
    "    raise ValueError(\"No strong match found in relevance map to test.\")\n",
    "\n",
    "resume_id, jd_id = sample_pair\n",
    "print(f\"=== Testing score_resume_vs_jd() for resume_id={resume_id}, jd_id={jd_id} ===\")\n",
    "\n",
    "# === Run scoring ===\n",
    "result = score_resume_vs_jd(\n",
    "    resume_id=resume_id,\n",
    "    jd_id=jd_id,\n",
    "    resume_json_dir=resume_json_dir,\n",
    "    jd_json_dir=jd_json_dir,\n",
    "    relevance_map=relevance_map\n",
    ")\n",
    "\n",
    "# === Show result ===\n",
    "pprint(result)\n",
    "\n",
    "\n",
    "test_file = os.path.join(Config.JSON_OUTPUT_SCORING_DIR, 'test_phase3_scoring.json')\n",
    "\n",
    "save_json_output(result, test_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91d1fabc",
   "metadata": {},
   "source": [
    "### Score pairs in batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "84864189",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import Dict, List\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from pprint import pprint\n",
    "\n",
    "def score_and_save_in_batches(\n",
    "    relevance_path: str,\n",
    "    resume_json_dir: str,\n",
    "    jd_json_dir: str,\n",
    "    output_dir: str,\n",
    "    limit: Optional[int] = None\n",
    "):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    checkpoint_path = os.path.join(output_dir, \"ats_scoring_checkpoint.json\")\n",
    "    error_log_path = os.path.join(output_dir, \"ats_scoring_errors.json\")\n",
    "\n",
    "    # Load checkpoint or start at 0\n",
    "    start_index = load_resume_checkpoint(checkpoint_path)\n",
    "\n",
    "    # Load relevance map\n",
    "    relevance_data = load_json_file(relevance_path)\n",
    "    relevant_pairs: List[Dict] = relevance_data.get(\"semantic_relevance_scores\", [])\n",
    "\n",
    "    if not relevant_pairs:\n",
    "        raise ValueError(\"No valid resume‚ÄìJD pairs found in relevance map.\")\n",
    "\n",
    "    total = len(relevant_pairs)\n",
    "    end_index = total if limit is None else min(start_index + limit, total)\n",
    "    print(f\"üîÅ Scoring {end_index - start_index} pairs starting from index {start_index}\")\n",
    "\n",
    "    processed = 0\n",
    "    error_records = []\n",
    "\n",
    "    for idx in range(start_index, end_index):\n",
    "        pair = relevant_pairs[idx]\n",
    "        resume_id = str(pair[\"resume_id\"])\n",
    "        jd_id = str(pair[\"jd_id\"])\n",
    "\n",
    "        try:\n",
    "            result = score_resume_vs_jd(\n",
    "                resume_id=resume_id,\n",
    "                jd_id=jd_id,\n",
    "                resume_json_dir=resume_json_dir,\n",
    "                jd_json_dir=jd_json_dir,\n",
    "                relevance_map=relevance_data\n",
    "            )\n",
    "            score = result[\"final_ats_score\"]\n",
    "            quality = result[\"match_quality\"]\n",
    "            timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "            output_name = f\"{resume_id}_{jd_id}_{quality}_{timestamp}_{score:.2f}.json\"\n",
    "            output_path = os.path.join(output_dir, output_name)\n",
    "            save_json_output(result, output_path)\n",
    "\n",
    "            processed += 1\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è Skipping pair (resume_id={resume_id}, jd_id={jd_id}): {e}\")\n",
    "            error_records.append({\n",
    "                \"resume_id\": resume_id,\n",
    "                \"jd_id\": jd_id,\n",
    "                \"error\": str(e)\n",
    "            })\n",
    "            \n",
    "    if error_records:\n",
    "        existing_errors = []\n",
    "        if os.path.exists(error_log_path):\n",
    "            with open(error_log_path, \"r\", encoding=\"utf-8\") as f:\n",
    "                existing_errors = json.load(f)\n",
    "        existing_errors.extend(error_records)\n",
    "        save_json_output(existing_errors, error_log_path)\n",
    "\n",
    "    # Save checkpoint\n",
    "    save_resume_checkpoint(checkpoint_path, end_index)\n",
    "    print(f\"‚úÖ Processed {processed} resume‚ÄìJD pairs. New checkpoint index: {end_index}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a4fd7f6",
   "metadata": {},
   "source": [
    "## Execute Scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6965928a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Saved output to json_outputs_all_data/scoring\\91591026_3905375582_strong_20250616_220220_0.77.json\n",
      "‚úÖ Saved output to json_outputs_all_data/scoring\\36861863_3904412334_weak_20250616_220235_0.47.json\n",
      "‚úÖ Saved output to json_outputs_all_data/scoring\\17115815_3905378069_medium_20250616_220249_0.59.json\n",
      "‚úÖ Saved output to json_outputs_all_data/scoring\\28092317_3901963546_weak_20250616_220302_0.32.json\n",
      "‚úÖ Saved output to json_outputs_all_data/scoring\\15746146_3885856804_medium_20250616_220317_0.55.json\n",
      "‚úÖ Saved output to json_outputs_all_data/scoring\\78107631_3904408123_weak_20250616_220330_0.39.json\n",
      "‚úÖ Saved output to json_outputs_all_data/scoring\\98108571_3906093141_weak_20250616_220349_0.22.json\n",
      "‚úÖ Saved output to json_outputs_all_data/scoring\\29149998_3903840743_medium_20250616_220408_0.53.json\n",
      "‚úÖ Saved output to json_outputs_all_data/scoring\\98509238_3904394631_medium_20250616_220426_0.52.json\n",
      "‚úÖ Saved output to json_outputs_all_data/scoring\\10176815_3902808410_weak_20250616_220443_0.41.json\n",
      "‚úÖ Saved output to json_outputs_all_data/scoring\\17276884_3905297922_medium_20250616_220457_0.62.json\n",
      "‚úÖ Saved output to json_outputs_all_data/scoring\\14752209_3904362879_medium_20250616_220511_0.55.json\n",
      "‚úÖ Saved output to json_outputs_all_data/scoring\\12546838_3902843672_medium_20250616_220524_0.58.json\n",
      "‚úÖ Saved output to json_outputs_all_data/scoring\\25749150_3902759328_weak_20250616_220535_0.46.json\n",
      "‚úÖ Saved output to json_outputs_all_data/scoring\\13080868_3905228237_weak_20250616_220553_0.47.json\n",
      "‚úÖ Saved output to json_outputs_all_data/scoring\\13998435_3886884354_weak_20250616_220607_0.47.json\n",
      "‚úÖ Saved output to json_outputs_all_data/scoring\\47603843_3902791028_medium_20250616_220620_0.66.json\n",
      "‚úÖ Saved output to json_outputs_all_data/scoring\\29147100_3905858430_medium_20250616_220633_0.54.json\n",
      "‚úÖ Saved output to json_outputs_all_data/scoring\\16804396_3904704818_weak_20250616_220648_0.30.json\n",
      "‚úÖ Saved output to json_outputs_all_data/scoring\\74512244_3904059851_medium_20250616_220703_0.64.json\n",
      "‚úÖ Saved output to json_outputs_all_data/scoring\\17688766_3902363472_medium_20250616_220723_0.58.json\n",
      "‚úÖ Saved output to json_outputs_all_data/scoring\\90685127_3901681093_medium_20250616_220738_0.53.json\n",
      "‚úÖ Saved output to json_outputs_all_data/scoring\\10030015_3904384407_weak_20250616_220750_0.38.json\n",
      "‚úÖ Saved output to json_outputs_all_data/scoring\\27662298_3904363225_weak_20250616_220804_0.49.json\n",
      "‚úÖ Saved output to json_outputs_all_data/scoring\\15891494_3902926801_medium_20250616_220816_0.64.json\n",
      "‚úÖ Saved output to json_outputs_all_data/scoring\\34797369_3901943854_medium_20250616_220829_0.56.json\n",
      "‚úÖ Saved output to json_outputs_all_data/scoring\\14150896_3905225113_weak_20250616_220841_0.39.json\n",
      "‚úÖ Saved output to json_outputs_all_data/scoring\\72136463_3903474978_weak_20250616_220853_0.36.json\n",
      "‚úÖ Saved output to json_outputs_all_data/scoring\\34046031_3905299905_medium_20250616_220908_0.60.json\n",
      "‚úÖ Saved output to json_outputs_all_data/scoring\\15423153_3902843957_medium_20250616_220923_0.64.json\n",
      "‚úÖ Saved output to json_outputs_all_data/scoring\\29647215_3904363416_medium_20250616_220934_0.59.json\n",
      "‚úÖ Saved output to json_outputs_all_data/scoring\\45987048_3903825698_medium_20250616_220946_0.68.json\n",
      "‚úÖ Saved output to json_outputs_all_data/scoring\\28630325_3904710523_weak_20250616_221002_0.48.json\n",
      "‚úÖ Saved output to json_outputs_all_data/scoring\\29208172_3902753343_medium_20250616_221015_0.67.json\n",
      "‚úÖ Saved output to json_outputs_all_data/scoring\\10984392_3903831350_medium_20250616_221028_0.54.json\n",
      "‚úÖ Saved output to json_outputs_all_data/scoring\\17396388_3905370041_weak_20250616_221040_0.47.json\n",
      "‚úÖ Saved output to json_outputs_all_data/scoring\\91697974_3904001283_medium_20250616_221055_0.60.json\n",
      "‚úÖ Saved output to json_outputs_all_data/scoring\\23841877_3904415557_medium_20250616_221108_0.55.json\n",
      "‚úÖ Saved output to json_outputs_all_data/scoring\\18827609_3884434138_medium_20250616_221125_0.58.json\n",
      "‚úÖ Saved output to json_outputs_all_data/scoring\\26746496_3904725790_weak_20250616_221141_0.47.json\n",
      "‚úÖ Saved output to json_outputs_all_data/scoring\\27004930_3901993765_weak_20250616_221155_0.38.json\n",
      "‚úÖ Saved output to json_outputs_all_data/scoring\\11441764_3902861489_medium_20250616_221206_0.57.json\n",
      "‚úÖ Saved output to json_outputs_all_data/scoring\\17396388_3902344466_weak_20250616_221219_0.45.json\n",
      "‚úÖ Saved output to json_outputs_all_data/scoring\\25330083_3904097310_medium_20250616_221230_0.55.json\n",
      "‚úÖ Saved output to json_outputs_all_data/scoring\\18293620_3904723718_medium_20250616_221242_0.68.json\n",
      "‚úÖ Saved output to json_outputs_all_data/scoring\\90280583_3905662663_medium_20250616_221255_0.62.json\n",
      "‚úÖ Saved output to json_outputs_all_data/scoring\\86828820_3904365524_medium_20250616_221307_0.61.json\n",
      "‚úÖ Saved output to json_outputs_all_data/scoring\\12717345_3905331408_medium_20250616_221319_0.71.json\n",
      "‚úÖ Saved output to json_outputs_all_data/scoring\\24322804_3904988445_medium_20250616_221332_0.53.json\n",
      "‚úÖ Saved output to json_outputs_all_data/scoring\\98379112_3905323577_medium_20250616_221343_0.57.json\n",
      "‚úÖ Saved output to json_outputs_all_data/scoring\\33135102_3905307050_medium_20250616_221353_0.55.json\n",
      "‚úÖ Saved output to json_outputs_all_data/scoring\\24411323_3904367110_weak_20250616_221403_0.41.json\n",
      "‚úÖ Saved output to json_outputs_all_data/scoring\\88859947_3904954839_weak_20250616_221419_0.44.json\n",
      "‚úÖ Saved output to json_outputs_all_data/scoring\\24068423_3904941405_weak_20250616_221433_0.40.json\n",
      "‚úÖ Saved output to json_outputs_all_data/scoring\\35157762_3903842476_medium_20250616_221444_0.60.json\n",
      "‚úÖ Saved output to json_outputs_all_data/scoring\\55595908_3901987526_medium_20250616_221459_0.53.json\n",
      "‚úÖ Saved output to json_outputs_all_data/scoring\\28867567_3902351930_weak_20250616_221511_0.44.json\n",
      "‚úÖ Saved output to json_outputs_all_data/scoring\\27090089_3903477149_weak_20250616_221531_0.48.json\n",
      "‚úÖ Saved output to json_outputs_all_data/scoring\\25930778_3901977332_weak_20250616_221544_0.31.json\n",
      "‚úÖ Saved output to json_outputs_all_data/scoring\\18457785_3905687426_weak_20250616_221554_0.46.json\n",
      "‚úÖ Saved output to json_outputs_all_data/scoring\\44624796_3902831440_medium_20250616_221603_0.57.json\n",
      "‚úÖ Saved output to json_outputs_all_data/scoring\\21549195_3902869062_medium_20250616_221616_0.56.json\n",
      "‚úÖ Saved output to json_outputs_all_data/scoring\\14449423_3885842626_medium_20250616_221628_0.65.json\n",
      "‚úÖ Saved output to json_outputs_all_data/scoring\\25949631_3902757491_weak_20250616_221638_0.38.json\n",
      "‚úÖ Saved output to json_outputs_all_data/scoring\\10464113_3903850202_weak_20250616_221649_0.36.json\n",
      "‚úÖ Saved output to json_outputs_all_data/scoring\\26189601_3905306775_medium_20250616_221702_0.64.json\n",
      "‚úÖ Saved output to json_outputs_all_data/scoring\\37792474_3904382629_weak_20250616_221716_0.49.json\n",
      "‚úÖ Saved output to json_outputs_all_data/scoring\\20880935_3901993777_medium_20250616_221726_0.57.json\n",
      "‚úÖ Saved output to json_outputs_all_data/scoring\\16804396_3906096171_weak_20250616_221735_0.14.json\n",
      "‚úÖ Saved output to json_outputs_all_data/scoring\\19397727_3901985465_medium_20250616_221750_0.54.json\n",
      "‚úÖ Saved output to json_outputs_all_data/scoring\\19446337_3905304252_strong_20250616_221801_0.80.json\n",
      "‚úÖ Saved output to json_outputs_all_data/scoring\\23234047_3887471270_medium_20250616_221815_0.67.json\n",
      "‚úÖ Saved output to json_outputs_all_data/scoring\\23497307_3902359707_weak_20250616_221828_0.46.json\n",
      "‚úÖ Saved output to json_outputs_all_data/scoring\\20748929_3901692357_medium_20250616_221840_0.60.json\n",
      "‚úÖ Saved output to json_outputs_all_data/scoring\\28630325_3905290953_weak_20250616_221849_0.44.json\n",
      "‚úÖ Saved output to json_outputs_all_data/scoring\\20210676_3884992276_medium_20250616_221900_0.51.json\n",
      "‚úÖ Saved output to json_outputs_all_data/scoring\\30361788_3903804869_medium_20250616_221914_0.62.json\n",
      "‚úÖ Saved output to json_outputs_all_data/scoring\\16353584_3901666729_medium_20250616_221927_0.56.json\n",
      "‚úÖ Saved output to json_outputs_all_data/scoring\\19582792_3904504067_weak_20250616_221940_0.50.json\n",
      "‚úÖ Saved output to json_outputs_all_data/scoring\\14049846_3885807498_weak_20250616_221953_0.33.json\n",
      "‚úÖ Saved output to json_outputs_all_data/scoring\\16407619_3903831325_weak_20250616_222004_0.41.json\n",
      "‚úÖ Saved output to json_outputs_all_data/scoring\\14726000_3904369146_medium_20250616_222022_0.64.json\n",
      "‚úÖ Saved output to json_outputs_all_data/scoring\\20253563_3905364625_weak_20250616_222034_0.28.json\n",
      "‚úÖ Saved output to json_outputs_all_data/scoring\\13294301_3903814954_weak_20250616_222048_0.41.json\n",
      "‚úÖ Saved output to json_outputs_all_data/scoring\\23138078_3903835824_medium_20250616_222101_0.72.json\n",
      "‚úÖ Saved output to json_outputs_all_data/scoring\\16223371_3885853861_medium_20250616_222111_0.51.json\n",
      "‚úÖ Saved output to json_outputs_all_data/scoring\\18460045_3902806530_weak_20250616_222124_0.44.json\n",
      "‚úÖ Saved output to json_outputs_all_data/scoring\\41344156_3902371340_medium_20250616_222135_0.54.json\n",
      "‚úÖ Saved output to json_outputs_all_data/scoring\\81508860_3904724495_weak_20250616_222146_0.38.json\n",
      "‚úÖ Saved output to json_outputs_all_data/scoring\\16237710_3905352150_medium_20250616_222158_0.52.json\n",
      "‚úÖ Saved output to json_outputs_all_data/scoring\\18311419_3902867126_weak_20250616_222210_0.46.json\n",
      "‚úÖ Saved output to json_outputs_all_data/scoring\\11169163_3885864930_medium_20250616_222228_0.61.json\n",
      "‚úÖ Saved output to json_outputs_all_data/scoring\\19397727_3905304733_medium_20250616_222241_0.68.json\n",
      "‚úÖ Saved output to json_outputs_all_data/scoring\\21622444_3901978375_weak_20250616_222254_0.46.json\n",
      "‚úÖ Saved output to json_outputs_all_data/scoring\\30646367_3904085727_medium_20250616_222308_0.54.json\n",
      "‚úÖ Saved output to json_outputs_all_data/scoring\\25547145_3904955115_weak_20250616_222320_0.31.json\n",
      "‚úÖ Saved output to json_outputs_all_data/scoring\\11169163_3902861915_medium_20250616_222334_0.75.json\n",
      "‚úÖ Saved output to json_outputs_all_data/scoring\\15699744_3905293743_weak_20250616_222348_0.45.json\n",
      "‚úÖ Saved output to json_outputs_all_data/scoring\\29211359_3905228112_weak_20250616_222404_0.36.json\n",
      "‚úÖ Saved output to json_outputs_all_data/scoring\\14789139_3904986765_medium_20250616_222415_0.56.json\n",
      "‚úÖ Saved output to json_outputs_all_data/scoring\\28522529_3901685082_medium_20250616_222431_0.59.json\n",
      "‚úÖ Saved output to json_outputs_all_data/scoring\\23814777_3901674663_medium_20250616_222448_0.55.json\n",
      "‚úÖ Saved output to json_outputs_all_data/scoring\\25706337_3905287409_weak_20250616_222500_0.46.json\n",
      "‚úÖ Saved output to json_outputs_all_data/scoring\\10674770_3903816226_medium_20250616_222511_0.51.json\n",
      "‚úÖ Saved output to json_outputs_all_data/scoring\\27490876_3905368524_medium_20250616_222523_0.55.json\n",
      "‚úÖ Saved output to json_outputs_all_data/scoring\\15553584_3905246902_medium_20250616_222537_0.63.json\n",
      "‚úÖ Saved output to json_outputs_all_data/scoring\\16237710_3885870146_weak_20250616_222551_0.41.json\n",
      "‚úÖ Saved output to json_outputs_all_data/scoring\\27233183_3904730146_weak_20250616_222606_0.34.json\n",
      "‚úÖ Saved output to json_outputs_all_data/scoring\\17509935_3904068273_medium_20250616_222617_0.57.json\n",
      "‚úÖ Saved output to json_outputs_all_data/scoring\\13812481_3902756235_weak_20250616_222631_0.43.json\n",
      "‚úÖ Saved output to json_outputs_all_data/scoring\\13858219_3905303314_medium_20250616_222643_0.66.json\n",
      "‚úÖ Saved output to json_outputs_all_data/scoring\\94417768_3901643771_weak_20250616_222656_0.49.json\n",
      "‚úÖ Saved output to json_outputs_all_data/scoring\\11877150_3902314302_medium_20250616_222709_0.72.json\n",
      "‚úÖ Saved output to json_outputs_all_data/scoring\\14455622_3904388033_weak_20250616_222722_0.47.json\n",
      "‚úÖ Saved output to json_outputs_all_data/scoring\\43378989_3901953860_weak_20250616_222734_0.43.json\n",
      "‚úÖ Saved output to json_outputs_all_data/scoring\\10395944_3902741560_medium_20250616_222747_0.54.json\n",
      "‚úÖ Saved output to json_outputs_all_data/scoring\\86828820_3905332844_medium_20250616_222801_0.57.json\n",
      "‚úÖ Saved output to json_outputs_all_data/scoring\\23818675_3902914511_medium_20250616_222818_0.58.json\n",
      "‚úÖ Saved output to json_outputs_all_data/scoring\\28614791_3904400125_medium_20250616_222830_0.52.json\n",
      "‚úÖ Saved output to json_outputs_all_data/scoring\\39674178_3905870597_weak_20250616_222846_0.50.json\n",
      "‚úÖ Saved output to json_outputs_all_data/scoring\\11797122_3904966674_medium_20250616_222902_0.68.json\n",
      "‚úÖ Saved output to json_outputs_all_data/scoring\\23782450_3902763185_weak_20250616_222913_0.31.json\n",
      "‚úÖ Saved output to json_outputs_all_data/scoring\\61322296_3901688620_medium_20250616_222924_0.71.json\n",
      "‚úÖ Saved output to json_outputs_all_data/scoring\\18484846_3905204833_weak_20250616_222936_0.46.json\n",
      "‚úÖ Saved output to json_outputs_all_data/scoring\\77576845_3905378069_medium_20250616_222946_0.69.json\n",
      "‚úÖ Saved output to json_outputs_all_data/scoring\\10001727_3904392214_medium_20250616_223001_0.51.json\n",
      "‚úÖ Saved output to json_outputs_all_data/scoring\\14528265_3885856804_weak_20250616_223013_0.46.json\n",
      "‚úÖ Saved output to json_outputs_all_data/scoring\\18586076_3902741180_weak_20250616_223025_0.48.json\n",
      "‚úÖ Saved output to json_outputs_all_data/scoring\\54101961_3905246179_weak_20250616_223038_0.34.json\n",
      "‚úÖ Saved output to json_outputs_all_data/scoring\\23510685_3902357329_medium_20250616_223050_0.70.json\n",
      "‚úÖ Saved output to json_outputs_all_data/scoring\\36074301_3904394631_weak_20250616_223105_0.37.json\n",
      "‚úÖ Saved output to json_outputs_all_data/scoring\\81588968_3902804568_weak_20250616_223118_0.40.json\n",
      "‚úÖ Saved output to json_outputs_all_data/scoring\\39142536_3904383823_medium_20250616_223140_0.63.json\n",
      "‚úÖ Saved output to json_outputs_all_data/scoring\\88907739_3905367830_medium_20250616_223152_0.62.json\n",
      "‚úÖ Saved output to json_outputs_all_data/scoring\\32531824_3902843672_medium_20250616_223204_0.56.json\n",
      "‚úÖ Saved output to json_outputs_all_data/scoring\\21763056_3902758496_weak_20250616_223216_0.46.json\n",
      "‚úÖ Saved output to json_outputs_all_data/scoring\\17509935_3905228237_weak_20250616_223229_0.39.json\n",
      "‚úÖ Saved output to json_outputs_all_data/scoring\\11722421_3901941076_medium_20250616_223241_0.60.json\n",
      "‚úÖ Saved output to json_outputs_all_data/scoring\\21904897_3902791028_medium_20250616_223255_0.66.json\n",
      "‚úÖ Saved output to json_outputs_all_data/scoring\\19195747_3904941771_weak_20250616_223307_0.39.json\n",
      "‚úÖ Saved output to json_outputs_all_data/scoring\\21611637_3885852494_medium_20250616_223323_0.63.json\n",
      "‚úÖ Saved output to json_outputs_all_data/scoring\\18172739_3904059851_medium_20250616_223335_0.66.json\n",
      "‚úÖ Saved output to json_outputs_all_data/scoring\\19850482_3905325920_weak_20250616_223348_0.43.json\n",
      "‚úÖ Saved output to json_outputs_all_data/scoring\\19444529_3902869062_medium_20250616_223400_0.55.json\n",
      "‚úÖ Saved output to json_outputs_all_data/scoring\\22605864_3904384410_medium_20250616_223414_0.55.json\n",
      "‚úÖ Saved output to json_outputs_all_data/scoring\\27909372_3904363224_medium_20250616_223432_0.66.json\n",
      "‚úÖ Saved output to json_outputs_all_data/scoring\\77638654_3901993889_medium_20250616_223445_0.64.json\n",
      "‚úÖ Saved output to json_outputs_all_data/scoring\\29208172_3902788384_medium_20250616_223458_0.52.json\n",
      "‚úÖ Saved output to json_outputs_all_data/scoring\\33344933_3903449189_weak_20250616_223510_0.46.json\n",
      "‚úÖ Saved output to json_outputs_all_data/scoring\\26750846_3841334821_weak_20250616_223520_0.41.json\n",
      "‚úÖ Saved output to json_outputs_all_data/scoring\\14241621_3904391037_medium_20250616_223530_0.54.json\n",
      "‚úÖ Saved output to json_outputs_all_data/scoring\\10464113_3902843957_medium_20250616_223545_0.52.json\n",
      "‚úÖ Saved output to json_outputs_all_data/scoring\\23527321_3904363416_medium_20250616_223556_0.61.json\n",
      "‚úÖ Saved output to json_outputs_all_data/scoring\\22056333_3905372078_weak_20250616_223609_0.45.json\n",
      "‚úÖ Saved output to json_outputs_all_data/scoring\\18979238_3904711446_weak_20250616_223626_0.42.json\n",
      "‚úÖ Saved output to json_outputs_all_data/scoring\\13574264_3902753343_medium_20250616_223638_0.60.json\n",
      "‚úÖ Saved output to json_outputs_all_data/scoring\\20633855_3903831350_weak_20250616_223648_0.46.json\n",
      "‚úÖ Saved output to json_outputs_all_data/scoring\\21794875_3905370041_medium_20250616_223658_0.51.json\n",
      "‚úÖ Saved output to json_outputs_all_data/scoring\\19850482_3904004142_weak_20250616_223712_0.36.json\n",
      "‚úÖ Saved output to json_outputs_all_data/scoring\\23591247_3901669713_weak_20250616_223723_0.43.json\n",
      "‚úÖ Saved output to json_outputs_all_data/scoring\\28419173_3901932974_weak_20250616_223735_0.50.json\n",
      "‚úÖ Saved output to json_outputs_all_data/scoring\\27485716_3902846106_weak_20250616_223751_0.45.json\n",
      "‚úÖ Saved output to json_outputs_all_data/scoring\\11637468_3901993765_medium_20250616_223801_0.52.json\n",
      "‚úÖ Saved output to json_outputs_all_data/scoring\\38441665_3902861489_medium_20250616_223813_0.66.json\n",
      "‚úÖ Saved output to json_outputs_all_data/scoring\\34250007_3902344466_medium_20250616_223828_0.51.json\n",
      "‚úÖ Saved output to json_outputs_all_data/scoring\\17823436_3902944445_weak_20250616_223841_0.34.json\n",
      "‚úÖ Saved output to json_outputs_all_data/scoring\\17095812_3904723718_weak_20250616_223857_0.49.json\n",
      "‚úÖ Saved output to json_outputs_all_data/scoring\\91515108_3886831281_weak_20250616_223912_0.43.json\n",
      "‚úÖ Saved output to json_outputs_all_data/scoring\\19124258_3904085241_medium_20250616_223931_0.64.json\n",
      "‚úÖ Saved output to json_outputs_all_data/scoring\\47729453_3904389587_medium_20250616_223944_0.56.json\n",
      "‚úÖ Saved output to json_outputs_all_data/scoring\\31684925_3905849410_medium_20250616_223958_0.54.json\n",
      "‚úÖ Saved output to json_outputs_all_data/scoring\\65708020_3901948362_medium_20250616_224010_0.63.json\n",
      "‚úÖ Saved output to json_outputs_all_data/scoring\\25330083_3904362397_medium_20250616_224027_0.73.json\n"
     ]
    }
   ],
   "source": [
    "score_and_save_in_batches(\n",
    "    relevance_path=os.path.join(Config.JSON_OUTPUT_SCORING_DIR, \"relevant_pairs.json\"),\n",
    "    resume_json_dir=Config.JSON_OUTPUT_NORMALIZED_RESUME,\n",
    "    jd_json_dir=Config.JSON_OUTPUT_NORMALIZED_JD,\n",
    "    output_dir=Config.JSON_OUTPUT_SCORING_DIR,\n",
    "    limit=None\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.10)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
