{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f630d895",
   "metadata": {},
   "source": [
    "# Global setup and package installation used in most phases"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "969fcea6",
   "metadata": {},
   "source": [
    "## Colab + GPU Detection Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e7cf79fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "def is_running_in_colab():\n",
    "    try:\n",
    "        import google.colab\n",
    "        return True\n",
    "    except ImportError:\n",
    "        return False\n",
    "\n",
    "def get_available_gpu_memory_gb():\n",
    "    try:\n",
    "        output = subprocess.check_output(\n",
    "            [\"nvidia-smi\", \"--query-gpu=memory.free\", \"--format=csv,nounits,noheader\"],\n",
    "            encoding=\"utf-8\"\n",
    "        )\n",
    "        free_mem_mb = int(output.strip().split(\"\\n\")[0])\n",
    "        return free_mem_mb / 1024\n",
    "    except Exception:\n",
    "        return 0.0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66be54d4",
   "metadata": {},
   "source": [
    "## install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "942fba10",
   "metadata": {},
   "outputs": [],
   "source": [
    "if is_running_in_colab():\n",
    "    # Install the required packages\n",
    "    !pip install kagglehub pandas\n",
    "    !pip install -q transformers accelerate bitsandbytes sentencepiece pydantic huggingface_hub xformers\n",
    "else:\n",
    "    %pip install kagglehub pandas\n",
    "    %pip install -q transformers accelerate sentencepiece pydantic huggingface_hub xformers\n",
    "    #%pip install torch==2.2.2 torchvision==0.17.2 torchaudio==2.2.2 --index-url https://download.pytorch.org/whl/cu121\n",
    "    #%pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121\n",
    "    %pip install --pre torch torchvision torchaudio --index-url https://download.pytorch.org/whl/nightly/cu128\n",
    "    %pip install -U bitsandbytes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef4a9f61",
   "metadata": {},
   "source": [
    "## Login to huggingface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1235aef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import login\n",
    "import os\n",
    "\n",
    "# Set your token here securely or prompt for it in Colab\n",
    "# Recommended: store in Colab secrets or environment variable\n",
    "HF_TOKEN = os.getenv(\"HUGGINGFACE_TOKEN\")\n",
    "\n",
    "\n",
    "if not HF_TOKEN:\n",
    "    if is_running_in_colab():\n",
    "        # If running in Colab, use the Colab secrets\n",
    "        try:\n",
    "            from google.colab import userdata\n",
    "            HF_TOKEN = userdata.get('HF_TOKEN')\n",
    "            if not HF_TOKEN:\n",
    "                raise ValueError(\"‚ö†Ô∏è Hugging Face token not found in Colab secrets.\")\n",
    "            print(\"üîë Hugging Face token found in Colab secrets.\")\n",
    "        except ImportError:\n",
    "            print(\"‚ö†Ô∏è Unable to authenticate in Colab. Please set your Hugging Face token manually.\")\n",
    "    else:\n",
    "        # Prompt for token if not set in environment\n",
    "        print(\"üîë Please enter your Hugging Face token:\")\n",
    "        # For Colab or local prompt input\n",
    "        HF_TOKEN = input(\"üîë Enter your Hugging Face token: \").strip()\n",
    "\n",
    "login(token=HF_TOKEN)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b423735e",
   "metadata": {},
   "source": [
    "## Setup Kaggle Credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "409818e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Kaggle credentials already exist at C:\\Users\\rubyj/.kaggle/kaggle.json\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "\n",
    "def setup_kaggle_credentials():\n",
    "    kaggle_path = os.path.expanduser('~/.kaggle/kaggle.json')\n",
    "    if not os.path.exists(kaggle_path):\n",
    "        from google.colab import files\n",
    "        print(\"üìÇ Upload kaggle.json file...\")\n",
    "        uploaded = files.upload()\n",
    "        os.makedirs(os.path.dirname(kaggle_path), exist_ok=True)\n",
    "        for filename in uploaded.keys():\n",
    "            shutil.move(filename, kaggle_path)\n",
    "        os.chmod(kaggle_path, 0o600)\n",
    "        print(f\"‚úÖ Kaggle credentials setup at {kaggle_path}\")\n",
    "    else:\n",
    "        print(f\"‚úÖ Kaggle credentials already exist at {kaggle_path}\")\n",
    "\n",
    "setup_kaggle_credentials()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d384b2f",
   "metadata": {},
   "source": [
    "## Mount Google Drive (Colab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1517ea98",
   "metadata": {},
   "outputs": [],
   "source": [
    "if is_running_in_colab():\n",
    "   from google.colab import drive\n",
    "   drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9964af3",
   "metadata": {},
   "source": [
    "##  Load Nous-Hermes-mistral-Instruct with Fallback to Quantized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3882e7e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig, pipeline\n",
    "import torch\n",
    "\n",
    "def load_model_pipeline(model_name: str, hf_token: str):\n",
    "    has_cuda = torch.cuda.is_available()\n",
    "    free_mem = torch.cuda.get_device_properties(0).total_memory / (1024 ** 3) if has_cuda else 0\n",
    "    print(f\"üíª CUDA: {has_cuda} | GPU Memory: {free_mem:.2f} GB\")\n",
    "\n",
    "    device_map = {\"\": 0} if has_cuda else \"cpu\"\n",
    "    use_4bit = has_cuda and free_mem < 24\n",
    "\n",
    "    # Set quantization config\n",
    "    quant_config = BitsAndBytesConfig(\n",
    "        load_in_4bit=True if use_4bit else False,\n",
    "        bnb_4bit_use_double_quant=True,\n",
    "        bnb_4bit_compute_dtype=torch.float16,\n",
    "        bnb_4bit_quant_type=\"nf4\"\n",
    "    ) if use_4bit else None\n",
    "\n",
    "    # Load tokenizer\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name, token=hf_token, trust_remote_code=True)\n",
    "    tokenizer.pad_token = tokenizer.eos_token  # ‚úÖ Fix warning about pad_token\n",
    "\n",
    "    # Load model\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        model_name,\n",
    "        device_map=device_map,\n",
    "        quantization_config=quant_config,\n",
    "        torch_dtype=torch.float16 if not quant_config else None,\n",
    "        trust_remote_code=True,\n",
    "        token=hf_token\n",
    "    )\n",
    "\n",
    "    print(f\"‚úÖ Model loaded on {next(model.parameters()).device}\")\n",
    "    return pipeline(\"text-generation\", model=model, tokenizer=tokenizer, batch_size=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d505348b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üíª CUDA: True | GPU Memory: 15.92 GB\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16f0c531cae444b3b99ddc2c29fc0c6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Model loaded on cuda:0\n"
     ]
    }
   ],
   "source": [
    "llm_pipeline = load_model_pipeline(\n",
    "    model_name=\"NousResearch/Nous-Hermes-2-Mistral-7B-DPO\",\n",
    "    hf_token=HF_TOKEN\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "739b4783",
   "metadata": {},
   "source": [
    "# Global utilities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10779c22",
   "metadata": {},
   "source": [
    "### Utility to merge normalized json files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "9a472fbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Merged and moved: normalized_jds_20250426_0212_2f0933.json\n",
      "üíæ Saved to: json_outputs_phase1_run3\\normalized\\normalized_jds.json\n",
      "‚úÖ Merged and moved: normalized_resumes_20250426_0208_e5a1bc.json\n",
      "üíæ Saved to: json_outputs_phase1_run3\\normalized\\normalized_resumes.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "def merge_json_files(\n",
    "    source_dir: Path,\n",
    "    output_file: Path,\n",
    "    pattern: str,\n",
    "    merged_dir: Path\n",
    "):\n",
    "    source_dir.mkdir(parents=True, exist_ok=True)\n",
    "    merged_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    merged_data = []\n",
    "\n",
    "    # Load existing output if it exists\n",
    "    if output_file.exists():\n",
    "        with open(output_file, \"r\", encoding=\"utf-8\") as f:\n",
    "            try:\n",
    "                merged_data = json.load(f)\n",
    "            except json.JSONDecodeError:\n",
    "                print(f\"‚ö†Ô∏è Could not decode {output_file}, starting from scratch.\")\n",
    "\n",
    "    # Identify matching files\n",
    "    files_to_merge = sorted(source_dir.glob(pattern))\n",
    "\n",
    "    for file_path in files_to_merge:\n",
    "        with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            try:\n",
    "                data = json.load(f)\n",
    "                if isinstance(data, list):\n",
    "                    merged_data.extend(data)\n",
    "                else:\n",
    "                    print(f\"‚ö†Ô∏è Skipping {file_path.name}: not a list.\")\n",
    "            except Exception as e:\n",
    "                print(f\"‚ö†Ô∏è Failed to parse {file_path.name}: {e}\")\n",
    "                continue\n",
    "\n",
    "        # Move to merged folder\n",
    "        shutil.move(str(file_path), merged_dir / file_path.name)\n",
    "        print(f\"‚úÖ Merged and moved: {file_path.name}\")\n",
    "\n",
    "    # Write combined output\n",
    "    if merged_data:\n",
    "        with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump(merged_data, f, indent=2)\n",
    "        print(f\"üíæ Saved to: {output_file}\")\n",
    "    else:\n",
    "        print(\"üì≠ No valid data to merge.\")\n",
    "\n",
    "# === Usage ===\n",
    "\n",
    "# Paths\n",
    "normalized_dir = Path(\"json_outputs_phase1_run3/normalized\")\n",
    "merged_dir = normalized_dir / \"merged\"\n",
    "\n",
    "merge_json_files(\n",
    "    source_dir=normalized_dir,\n",
    "    output_file=normalized_dir / \"normalized_jds.json\",\n",
    "    pattern=\"normalized_jds_*.json\",\n",
    "    merged_dir=merged_dir\n",
    ")\n",
    "\n",
    "merge_json_files(\n",
    "    source_dir=normalized_dir,\n",
    "    output_file=normalized_dir / \"normalized_resumes.json\",\n",
    "    pattern=\"normalized_resumes_*.json\",\n",
    "    merged_dir=merged_dir\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "504346b6",
   "metadata": {},
   "source": [
    "### Utility to save json to a folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6a69e1bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "# üì¶ Save JSON Output with Safety\n",
    "def save_json_output(data, output_path: str, indent: int = 4, overwrite: bool = True):\n",
    "    output_dir = os.path.dirname(output_path)\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    if os.path.exists(output_path):\n",
    "        if overwrite:\n",
    "            os.remove(output_path)\n",
    "        else:\n",
    "            raise FileExistsError(f\"File {output_path} already exists and overwrite=False.\")\n",
    "\n",
    "    with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(data, f, indent=indent, ensure_ascii=False)\n",
    "\n",
    "    print(f\"‚úÖ Saved output to {output_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcb849be",
   "metadata": {},
   "source": [
    "# Phase 1: First Steps Notebook ‚Äî Data Ingestion + Minimal Parsing\n",
    "1. Load Resume and JD datasets\n",
    "2. Minimal Parsing into JSON Structure\n",
    "3. Save structured JSON for Phase 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb756b8f",
   "metadata": {},
   "source": [
    "## Util Classes and methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43abc8ac",
   "metadata": {},
   "source": [
    "### Configurations  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a1e827a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================\n",
    "# üõ† CONFIGURATION\n",
    "# ==============================\n",
    "\n",
    "class Config:\n",
    "    DATASET_DOWNLOAD_DIR = \"datasets\"\n",
    "    JSON_OUTPUT_DIR = \"json_outputs_phase1_run3\"\n",
    "    JSON_OUTPUT_NORMALIZED_DIR = \"json_outputs_phase1_run3/normalized\"\n",
    "    AUTO_CLEANUP = True\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95a537a5",
   "metadata": {},
   "source": [
    "### Downloader "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "89480102",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================\n",
    "# DOWNLOADER\n",
    "# ==============================\n",
    "import zipfile\n",
    "from pathlib import Path\n",
    "\n",
    "class DatasetDownloader:\n",
    "    @staticmethod\n",
    "    def download_and_extract(dataset_path: str) -> tuple[str, str]:\n",
    "        os.makedirs(Config.DATASET_DOWNLOAD_DIR, exist_ok=True)\n",
    "        dataset_slug = dataset_path.split(\"/\")[-1]\n",
    "        extract_folder_path = os.path.join(Config.DATASET_DOWNLOAD_DIR, dataset_slug)\n",
    "        zip_filename = f\"{dataset_slug}.zip\"\n",
    "        zip_path = os.path.join(Config.DATASET_DOWNLOAD_DIR, zip_filename)\n",
    "\n",
    "        if os.path.exists(extract_folder_path) and any(Path(extract_folder_path).rglob(\"*.csv\")):\n",
    "            print(f\"‚ö° Dataset folder already exists at '{extract_folder_path}', skipping download and extraction.\")\n",
    "            return extract_folder_path, zip_filename\n",
    "\n",
    "        print(f\"‚¨áÔ∏è Downloading dataset: {dataset_path} ...\")\n",
    "        !kaggle datasets download -d {dataset_path} -p {Config.DATASET_DOWNLOAD_DIR}\n",
    "\n",
    "        if not os.path.exists(zip_path):\n",
    "            raise FileNotFoundError(f\"‚ùå Zip file '{zip_filename}' not found after download!\")\n",
    "\n",
    "        os.makedirs(extract_folder_path, exist_ok=True)\n",
    "        with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "            zip_ref.extractall(extract_folder_path)\n",
    "\n",
    "        print(f\"‚úÖ Downloaded and extracted to '{extract_folder_path}'.\")\n",
    "        return extract_folder_path, zip_filename\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1170df00",
   "metadata": {},
   "source": [
    "### Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d2c06119",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================\n",
    "# LOADER\n",
    "# ==============================\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "class DatasetLoader:\n",
    "    @staticmethod\n",
    "    def load_csv(dataset_folder: str, target_csv_name: str) -> pd.DataFrame:\n",
    "        print(f\"üîç Searching for '{target_csv_name}' inside {dataset_folder}...\")\n",
    "        if not os.path.exists(dataset_folder):\n",
    "            raise FileNotFoundError(f\"‚ùå Dataset folder '{dataset_folder}' does not exist!\")\n",
    "\n",
    "        for root, _, files in os.walk(dataset_folder):\n",
    "            for file in files:\n",
    "                if file.lower() == target_csv_name.lower():\n",
    "                    csv_path = os.path.join(root, file)\n",
    "                    df = pd.read_csv(csv_path)\n",
    "                    print(f\"‚úÖ Loaded CSV with shape {df.shape}\")\n",
    "                    return df\n",
    "\n",
    "        raise FileNotFoundError(f\"‚ùå CSV file '{target_csv_name}' not found inside extracted dataset!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96a80a5a",
   "metadata": {},
   "source": [
    "### Data Processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "08247c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================\n",
    "# PROCESSOR\n",
    "# ==============================\n",
    "from typing import List\n",
    "\n",
    "\n",
    "class DatasetProcessor:\n",
    "    @staticmethod\n",
    "    def filter_fields(df: pd.DataFrame, allowed_fields: List[str]) -> pd.DataFrame:\n",
    "        missing_fields = [field for field in allowed_fields if field not in df.columns]\n",
    "        if missing_fields:\n",
    "            raise ValueError(f\"‚ùå Fields {missing_fields} not found in dataset!\")\n",
    "\n",
    "        filtered_df = df[allowed_fields]\n",
    "        print(f\"‚úÖ Filtered columns: {list(filtered_df.columns)}\")\n",
    "        return filtered_df\n",
    "\n",
    "    @staticmethod\n",
    "    def save_to_json(df: pd.DataFrame, output_json_name: str):\n",
    "        os.makedirs(Config.JSON_OUTPUT_DIR, exist_ok=True)\n",
    "        output_path = os.path.join(Config.JSON_OUTPUT_DIR, output_json_name)\n",
    "\n",
    "        if os.path.exists(output_path):\n",
    "            os.remove(output_path)\n",
    "            print(f\"üóëÔ∏è Existing JSON '{output_path}' deleted.\")\n",
    "\n",
    "        df.to_json(output_path, orient='records', lines=True, force_ascii=False)\n",
    "        print(f\"‚úÖ Data saved to JSON at '{output_path}'\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64fc4fb6",
   "metadata": {},
   "source": [
    "### Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f7245255",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================\n",
    "# CLEANER\n",
    "# ==============================\n",
    "class Cleaner:\n",
    "    @staticmethod\n",
    "    def cleanup_dataset_artifacts(extracted_folder_path: str, zip_filename: str):\n",
    "        if os.path.exists(extracted_folder_path):\n",
    "            shutil.rmtree(extracted_folder_path)\n",
    "            print(f\"üßπ Folder '{extracted_folder_path}' has been deleted successfully.\")\n",
    "\n",
    "        zip_path = os.path.join(Config.DATASET_DOWNLOAD_DIR, zip_filename)\n",
    "        if os.path.exists(zip_path):\n",
    "            os.remove(zip_path)\n",
    "            print(f\"üóëÔ∏è Zip file '{zip_path}' has been deleted successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15a2525b",
   "metadata": {},
   "source": [
    "### Hybrid Data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b8d85253",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ==============================\n",
    "# HYBRID LOADER\n",
    "# ==============================\n",
    "try:\n",
    "    import kagglehub\n",
    "    from kagglehub import KaggleDatasetAdapter\n",
    "except ImportError:\n",
    "    kagglehub = None\n",
    "\n",
    "class HybridDatasetLoader:\n",
    "    @staticmethod\n",
    "    def load_dataset(dataset_path: str, file_name: str) -> pd.DataFrame:\n",
    "        if kagglehub:\n",
    "            try:\n",
    "                print(f\"üì• Trying KaggleHub for {dataset_path}...\")\n",
    "                df = kagglehub.dataset_load(KaggleDatasetAdapter.PANDAS, dataset_path, file_name)\n",
    "                print(f\"‚úÖ Loaded using KaggleHub: shape = {df.shape}\")\n",
    "                return df\n",
    "            except Exception as e:\n",
    "                print(f\"‚ö†Ô∏è KaggleHub failed: {e}\\nFalling back to ZIP-based loader.\")\n",
    "\n",
    "        extracted_folder, _ = DatasetDownloader.download_and_extract(dataset_path)\n",
    "        return DatasetLoader.load_csv(extracted_folder, file_name)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bace5dc8",
   "metadata": {},
   "source": [
    "### Infer JD Domains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "97cfe6ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "domain_keywords_dict = {\n",
    "    'advocate': ['advocate'],\n",
    "    'agriculture': ['agriculture'],\n",
    "    'apparel': ['apparel'],\n",
    "    'arts': ['arts'],\n",
    "    'automobile': ['automobile'],\n",
    "    'aviation': ['aviation'],\n",
    "    'banking': ['banking'],\n",
    "    'bpo': ['bpo'],\n",
    "    'business development': ['business', 'development', 'business development', 'business-development'],\n",
    "    'chef': ['chef'],\n",
    "    'construction': ['construction'],\n",
    "    'consultant': ['consultant'],\n",
    "    'data scientist': ['data', 'data analyst', 'data scientist', 'scientist'],\n",
    "    'designing': ['designing', 'designer'],\n",
    "    'digital media': ['digital', 'digital marketing executive', 'media', 'digital media', 'digital-media'],\n",
    "    'engineering': ['engineering'],\n",
    "    'finance': ['finance', 'financial analyst'],\n",
    "    'healthcare': ['healthcare'],\n",
    "    'hr': ['hr'],\n",
    "    'information technology': ['information', 'technology', 'information technology', 'information-technology'],\n",
    "    'public relations': ['public', 'relations', 'public relations', 'public-relations'],\n",
    "    'marketing': ['marketing'],\n",
    "    'sales': ['sales', 'sales executive'],\n",
    "    'teacher': ['teacher'],\n",
    "    'technician': ['technician'],\n",
    "    'training': ['training'],\n",
    "    'web designing': ['web', 'designing'],\n",
    "    'fitness': ['fitness'],\n",
    "    'accountant': ['accountant', 'accounting']\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c5f1837f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer_domain_from_title(title):\n",
    "    title_lower = title.lower()\n",
    "    for domain, keywords in domain_keywords_dict.items():\n",
    "        if any(kw in title_lower for kw in keywords):\n",
    "            return domain\n",
    "    return \"unknown\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "de7419f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================\n",
    "# Efficient LLM Inference in Batches for JD Domains\n",
    "# ==============================\n",
    "from tqdm import tqdm\n",
    "\n",
    "def infer_domains_in_batches(texts, batch_size=8):\n",
    "    results = []\n",
    "    for i in tqdm(range(0, len(texts), batch_size), desc=\"üß† Inferring JD domains\"):\n",
    "        batch = texts[i:i+batch_size]\n",
    "        prompts = [\n",
    "            f\"Given this job description:\\n\\n{desc}\\n\\nWhat is the most likely job function or domain?\" for desc in batch\n",
    "        ]\n",
    "        try:\n",
    "            responses = llm_pipeline(prompts)\n",
    "            for r in responses:\n",
    "                results.append(r[0]['generated_text'].strip().split(\"\\n\")[-1])\n",
    "        except Exception:\n",
    "            results.extend([\"unknown\"] * len(batch))\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a18dbb61",
   "metadata": {},
   "source": [
    "### Filter and Rank JDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "12e07d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================\n",
    "# JD Filtering and Ranking (with batched domain inference)\n",
    "# ==============================\n",
    "def filter_and_rank_jds(jd_df, resume_domains, max_total=50, top_n_per_domain=2):\n",
    "    # Ensure necessary columns exist\n",
    "    for col in ['title', 'description']:\n",
    "        if col not in jd_df.columns:\n",
    "            raise ValueError(f\"‚ùå Column '{col}' not found in JD dataset\")\n",
    "        jd_df[col] = jd_df[col].fillna('').astype(str)\n",
    "\n",
    "    # Infer domains \n",
    "    print(\"üß† Inferring JD domains from title using keyword matcing...\")\n",
    "    #jd_df['inferred_domain'] = infer_domains_in_batches(jd_df['description'].tolist())\n",
    "    jd_df['inferred_domain'] = jd_df['title'].fillna(\"\").apply(infer_domain_from_title)\n",
    "\n",
    "\n",
    "    all_ranked = []\n",
    "\n",
    "    for domain in resume_domains:\n",
    "        matches = jd_df[\n",
    "            jd_df['title'].str.contains(domain, na=False, case=False) |\n",
    "            jd_df['inferred_domain'].str.contains(domain, na=False, case=False)\n",
    "        ].copy()\n",
    "\n",
    "        if matches.empty:\n",
    "            print(f\"‚ö†Ô∏è No JDs matched domain: '{domain}'\")\n",
    "            continue\n",
    "\n",
    "        matches['richness_score'] = matches['description'].str.len()\n",
    "        top = matches.sort_values(by='richness_score', ascending=False).head(top_n_per_domain)\n",
    "        all_ranked.append(top)\n",
    "\n",
    "    if not all_ranked:\n",
    "        raise ValueError(\"‚ùå No job descriptions matched any resume domains.\")\n",
    "\n",
    "    final_jds_df = pd.concat(all_ranked, ignore_index=True)\n",
    "    final_jds_df = final_jds_df.drop_duplicates().sort_values(by='richness_score', ascending=False).head(max_total)\n",
    "\n",
    "    print(f\"‚úÖ Filtered and ranked {len(final_jds_df)} job descriptions across {len(resume_domains)} domains.\")\n",
    "    return final_jds_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc4ed1ea",
   "metadata": {},
   "source": [
    "### Load Resume and JD datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7bc2aa51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================\n",
    "# Resume Dataset Loader (with caching)\n",
    "# ==============================\n",
    "def load_resume_dataset(dataset_path: str = \"snehaanbhawal/resume-dataset\", target_csv_name: str = \"Resume.csv\") -> pd.DataFrame:\n",
    "    if not hasattr(load_resume_dataset, \"_cache\"):\n",
    "        print(\"üì• Loading resume dataset for the first time...\")\n",
    "        load_resume_dataset._cache = HybridDatasetLoader.load_dataset(dataset_path, target_csv_name)\n",
    "    else:\n",
    "        print(\"‚úÖ Using cached resume dataset.\")\n",
    "    \n",
    "    return load_resume_dataset._cache\n",
    "\n",
    "# ==============================\n",
    "# Job Description Dataset Loader (with caching)\n",
    "# ==============================\n",
    "def load_job_description_dataset(dataset_path: str = \"arshkon/linkedin-job-postings\", target_csv_name: str = \"postings.csv\") -> pd.DataFrame:\n",
    "    if not hasattr(load_job_description_dataset, \"_cache\"):\n",
    "        print(\"üì• Loading job description dataset for the first time...\")\n",
    "        load_job_description_dataset._cache = HybridDatasetLoader.load_dataset(dataset_path, target_csv_name)\n",
    "    else:\n",
    "        print(\"‚úÖ Using cached job description dataset.\")\n",
    "    \n",
    "    return load_job_description_dataset._cache\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ff68a05",
   "metadata": {},
   "source": [
    "### JD Dataset Processing Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "212dbc74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================\n",
    "# JD Processing Function\n",
    "# ==============================\n",
    "def process_dataset_jd(dataset_path: str, target_csv_name: str, allowed_fields: List[str], output_json_name: str):\n",
    "    jd_df = load_job_description_dataset(dataset_path, target_csv_name)\n",
    "    resume_df = load_resume_dataset()\n",
    "    resume_domains = resume_df['Category'].dropna().str.lower().unique().tolist()\n",
    "    ranked_jds_df = filter_and_rank_jds(jd_df, resume_domains)\n",
    "    filtered_df = DatasetProcessor.filter_fields(ranked_jds_df, allowed_fields)\n",
    "    DatasetProcessor.save_to_json(filtered_df, output_json_name)\n",
    "    \n",
    "    # cleanup dataset\n",
    "    dataset_slug = dataset_path.split(\"/\")[-1]\n",
    "    extracted_folder = os.path.join(Config.DATASET_DOWNLOAD_DIR, dataset_slug)\n",
    "    zip_filename = f\"{dataset_slug}.zip\"\n",
    "    if Config.AUTO_CLEANUP:\n",
    "        Cleaner.cleanup_dataset_artifacts(extracted_folder, zip_filename)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e917e9d6",
   "metadata": {},
   "source": [
    "### Resume Dataset Processing Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "23ea4be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================\n",
    "# Resume Filtering (5 per category)\n",
    "# ==============================\n",
    "def filter_resumes_by_category(resume_df: pd.DataFrame, top_n: int = 1) -> pd.DataFrame:\n",
    "    if 'Category' not in resume_df.columns:\n",
    "        raise ValueError(\"‚ùå Resume dataset does not contain 'Category' column.\")\n",
    "\n",
    "    filtered_resumes = (\n",
    "        resume_df\n",
    "        .dropna(subset=['Category'])\n",
    "        .groupby('Category', group_keys=False)\n",
    "        .apply(lambda group: group.head(top_n))\n",
    "        .reset_index(drop=True)\n",
    "    )\n",
    "\n",
    "    print(f\"‚úÖ Filtered {len(filtered_resumes)} resumes (top {top_n} from each category).\")\n",
    "    return filtered_resumes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "766a42bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ==============================\n",
    "# MAIN FLOW\n",
    "# ==============================\n",
    "\n",
    "def process_dataset_resume(dataset_path: str, target_csv_name: str, allowed_fields: List[str], output_json_name: str):\n",
    "    df = load_resume_dataset(dataset_path, target_csv_name)\n",
    "    filtered_df = DatasetProcessor.filter_fields(df, allowed_fields)\n",
    "    DatasetProcessor.save_to_json(filtered_df, output_json_name)\n",
    "\n",
    "    dataset_slug = dataset_path.split(\"/\")[-1]\n",
    "    extracted_folder = os.path.join(Config.DATASET_DOWNLOAD_DIR, dataset_slug)\n",
    "    zip_filename = f\"{dataset_slug}.zip\"\n",
    "    if Config.AUTO_CLEANUP:\n",
    "        Cleaner.cleanup_dataset_artifacts(extracted_folder, zip_filename)\n",
    "\n",
    "\n",
    "# ==============================\n",
    "# Save Filtered Resumes\n",
    "# ==============================\n",
    "def process_and_save_filtered_resumes(dataset_path: str, target_csv_name: str, allowed_fields: List[str], output_json_name: str):\n",
    "    resume_df = load_resume_dataset(dataset_path, target_csv_name)\n",
    "    df = filter_resumes_by_category(resume_df)\n",
    "    filtered_df = DatasetProcessor.filter_fields(df, allowed_fields)\n",
    "    DatasetProcessor.save_to_json(filtered_df, output_json_name)\n",
    "    \n",
    "    dataset_slug = dataset_path.split(\"/\")[-1]\n",
    "    extracted_folder = os.path.join(Config.DATASET_DOWNLOAD_DIR, dataset_slug)\n",
    "    zip_filename = f\"{dataset_slug}.zip\"\n",
    "    if Config.AUTO_CLEANUP:\n",
    "        Cleaner.cleanup_dataset_artifacts(extracted_folder, zip_filename)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60577088",
   "metadata": {},
   "source": [
    "## Login and do the processing of Resume and JD dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "491107cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "process_and_save_filtered_resumes(\n",
    "    dataset_path=\"snehaanbhawal/resume-dataset\",\n",
    "    target_csv_name=\"Resume.csv\",\n",
    "    allowed_fields=[\"Category\", \"Resume_str\"],\n",
    "    output_json_name=\"parsed_resumes.json\"\n",
    ")\n",
    "\n",
    "process_dataset_jd(\n",
    "    dataset_path=\"arshkon/linkedin-job-postings\",\n",
    "    target_csv_name=\"postings.csv\",\n",
    "    allowed_fields=[\"title\", \"company_name\", \"location\",  \"skills_desc\", \"job_id\" , \"formatted_experience_level\", \"formatted_work_type\", \"description\"], #\"description\",\n",
    "    output_json_name=\"parsed_jds.json\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3bb5022",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Process Resume Dataset\n",
    "process_dataset_resume(\n",
    "    dataset_path=\"snehaanbhawal/resume-dataset\",\n",
    "    target_csv_name=\"Resume.csv\",\n",
    "    allowed_fields=[\"Category\", \"Resume_str\"],\n",
    "    output_json_name=\"parsed_resumes.json\"\n",
    ")\n",
    "\n",
    "\n",
    "# Process Job Postings Dataset\n",
    "process_dataset_jd(\n",
    "    dataset_path=\"arshkon/linkedin-job-postings\",\n",
    "    target_csv_name=\"postings.csv\",\n",
    "    allowed_fields=[\"title\", \"company_name\", \"location\",  \"skills_desc\", \"job_id\" , \"formatted_experience_level\", \"formatted_work_type\", \"description\"], #\"description\",\n",
    "    output_json_name=\"parsed_jds.json\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7a1b769",
   "metadata": {},
   "source": [
    "# Phase 2 -\tParse resume/JD into JSON structured scheme"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f7917da",
   "metadata": {},
   "source": [
    "## Define Pydantic Schemas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "42d92205",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "from pydantic import BaseModel\n",
    "\n",
    "class Education(BaseModel):\n",
    "    degree: str\n",
    "    field: str\n",
    "    institution: str\n",
    "    year: str\n",
    "    gpa: Optional[str] = None\n",
    "\n",
    "class Experience(BaseModel):\n",
    "    job_title: str\n",
    "    company: str\n",
    "    start_date: Optional[str] = None\n",
    "    end_date: Optional[str] = None\n",
    "    duration_in_months: Optional[int] = None\n",
    "    description: str\n",
    "\n",
    "class Basics(BaseModel):\n",
    "    name: str\n",
    "    email: str\n",
    "    phone: str\n",
    "    location: str\n",
    "    current_title: str\n",
    "    linkedin_url: Optional[str] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "10276bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Optional\n",
    "from pydantic import BaseModel\n",
    "import re\n",
    "\n",
    "\n",
    "class ResumeSchema(BaseModel):\n",
    "    basics: Basics\n",
    "    education: List[Education]\n",
    "    experience: List[Experience]\n",
    "    skills: List[str]\n",
    "    certifications: List[str]\n",
    "    projects: List[str]\n",
    "    languages: Optional[List[str]] = []\n",
    "    total_experience_years: Optional[float] = 0.0  # ‚úÖ New field added\n",
    "\n",
    "    @classmethod\n",
    "    def normalize(cls, resume_dict: dict) -> dict:\n",
    "        resume_dict = dict(resume_dict)\n",
    "\n",
    "        # Basics\n",
    "        basics = resume_dict.get(\"basics\", {})\n",
    "        resume_dict[\"basics\"] = {\n",
    "            \"name\": basics.get(\"name\", \"\"),\n",
    "            \"email\": basics.get(\"email\", \"\"),\n",
    "            \"phone\": basics.get(\"phone\", \"\"),\n",
    "            \"location\": basics.get(\"location\", \"\"),\n",
    "            \"current_title\": basics.get(\"current_title\", basics.get(\"title\", \"\")),\n",
    "            \"linkedin_url\": basics.get(\"linkedin_url\", \"\")\n",
    "        }\n",
    "\n",
    "        # Normalize sections\n",
    "        for key in [\"skills\", \"certifications\", \"projects\", \"languages\"]:\n",
    "            if not isinstance(resume_dict.get(key), list):\n",
    "                resume_dict[key] = []\n",
    "\n",
    "        # Normalize Experience\n",
    "        normalized_exp = []\n",
    "        for item in resume_dict.get(\"experience\", []):\n",
    "            if not isinstance(item, dict):\n",
    "                continue\n",
    "            normalized_exp.append({\n",
    "                \"job_title\": item.get(\"job_title\", item.get(\"title\", \"\")),\n",
    "                \"company\": item.get(\"company\", \"\"),\n",
    "                \"start_date\": item.get(\"start_date\", \"\"),\n",
    "                \"end_date\": item.get(\"end_date\", \"\"),\n",
    "                \"duration_in_months\": item.get(\"duration_in_months\", None),\n",
    "                \"description\": item.get(\"description\", \"\")\n",
    "            })\n",
    "        resume_dict[\"experience\"] = normalized_exp\n",
    "\n",
    "        # Normalize Education\n",
    "        normalized_edu = []\n",
    "        for item in resume_dict.get(\"education\", []):\n",
    "            if not isinstance(item, dict):\n",
    "                continue\n",
    "            degree = item.get(\"degree\", \"\")\n",
    "            field = item.get(\"field\", \"\")\n",
    "            if not field:\n",
    "                match = re.search(r\"in\\\\s+(.+)\", degree, flags=re.IGNORECASE)\n",
    "                field = match.group(1).strip() if match else \"\"\n",
    "            year = str(item.get(\"year\", \"\")) if item.get(\"year\") else \"\"\n",
    "            gpa = item.get(\"gpa\", None)\n",
    "            normalized_edu.append({\n",
    "                \"degree\": degree,\n",
    "                \"field\": field,\n",
    "                \"institution\": item.get(\"institution\", \"\"),\n",
    "                \"year\": year,\n",
    "                \"gpa\": gpa\n",
    "            })\n",
    "        resume_dict[\"education\"] = normalized_edu\n",
    "\n",
    "        # Total Experience fallback\n",
    "        if \"total_experience_years\" not in resume_dict:\n",
    "            resume_dict[\"total_experience_years\"] = 0.0\n",
    "\n",
    "        return resume_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "7d198213",
   "metadata": {},
   "outputs": [],
   "source": [
    "class JobDescriptionSchema(BaseModel):\n",
    "    title: str\n",
    "    summary: str\n",
    "    required_experience_years: float\n",
    "    preferred_degrees: List[str]\n",
    "    required_skills: List[str]\n",
    "    optional_skills: List[str]\n",
    "    certifications: List[str]\n",
    "    soft_skills: List[str]\n",
    "    job_location: str\n",
    "    remote_option: Optional[bool] = False\n",
    "    employment_type: Optional[str] = None\n",
    "\n",
    "    @classmethod\n",
    "    def normalize(cls, jd_dict: dict) -> dict:\n",
    "        jd_dict = dict(jd_dict)\n",
    "\n",
    "        aliases = {\n",
    "            \"years_required\": \"required_experience_years\",\n",
    "            \"requirements\": \"required_skills\",\n",
    "            \"degree_preferences\": \"preferred_degrees\",\n",
    "            \"certs\": \"certifications\",\n",
    "            \"skills_soft\": \"soft_skills\",\n",
    "            \"job_summary\": \"summary\"\n",
    "        }\n",
    "        for old, new in aliases.items():\n",
    "            if old in jd_dict and new not in jd_dict:\n",
    "                jd_dict[new] = jd_dict.pop(old)\n",
    "\n",
    "        # Required Experience Extraction\n",
    "        def extract_experience_years(text: str) -> float:\n",
    "            if not isinstance(text, str):\n",
    "                return 0.0\n",
    "            match = re.search(r'(\\\\d+(\\\\.\\\\d+)?)\\\\s*\\\\+?\\\\s*(years?|yrs?)', text.lower())\n",
    "            return float(match.group(1)) if match else 0.0\n",
    "\n",
    "        try:\n",
    "            val = jd_dict.get(\"required_experience_years\")\n",
    "            if val is None:\n",
    "                jd_dict[\"required_experience_years\"] = extract_experience_years(jd_dict.get(\"summary\", \"\"))\n",
    "            elif isinstance(val, str):\n",
    "                jd_dict[\"required_experience_years\"] = float(val.split()[0])\n",
    "            else:\n",
    "                jd_dict[\"required_experience_years\"] = float(val)\n",
    "        except Exception:\n",
    "            jd_dict[\"required_experience_years\"] = 0.0\n",
    "\n",
    "        # Normalize fields\n",
    "        for field in [\"preferred_degrees\", \"required_skills\", \"optional_skills\", \"certifications\", \"soft_skills\"]:\n",
    "            if not isinstance(jd_dict.get(field), list):\n",
    "                jd_dict[field] = []\n",
    "\n",
    "        for field in [\"title\", \"summary\", \"job_location\", \"employment_type\"]:\n",
    "            jd_dict[field] = jd_dict.get(field, \"\") or \"\"\n",
    "\n",
    "        # Remote Option\n",
    "        remote_flag = jd_dict.get(\"remote_option\", None)\n",
    "        if remote_flag is None:\n",
    "            remote_flag = \"remote\" in jd_dict.get(\"summary\", \"\").lower()\n",
    "        jd_dict[\"remote_option\"] = bool(remote_flag)\n",
    "\n",
    "        return jd_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "4da01bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_example_structure(model_class) -> dict:\n",
    "    \"\"\"Generate a JSON structure from a Pydantic model using placeholder values, handling Optional fields better.\"\"\"\n",
    "    from typing import get_origin, get_args, Union\n",
    "    from pydantic import BaseModel\n",
    "\n",
    "    def default_for_type(field_type):\n",
    "        origin = get_origin(field_type)\n",
    "        args = get_args(field_type)\n",
    "\n",
    "        if origin is list:\n",
    "            return []\n",
    "        elif origin is Union and type(None) in args:\n",
    "            # Optional[...] detected\n",
    "            non_none_types = [arg for arg in args if arg is not type(None)]\n",
    "            return default_for_type(non_none_types[0]) if non_none_types else \"\"\n",
    "        elif field_type is str:\n",
    "            return \"\"\n",
    "        elif field_type in [float, int]:\n",
    "            return 0.0\n",
    "        elif isinstance(field_type, type) and issubclass(field_type, BaseModel):\n",
    "            return generate_example_structure(field_type)\n",
    "        else:\n",
    "            return \"\"\n",
    "\n",
    "    structure = {}\n",
    "    for field_name, field in model_class.model_fields.items():\n",
    "        try:\n",
    "            structure[field_name] = default_for_type(field.annotation)\n",
    "        except Exception:\n",
    "            structure[field_name] = \"\"\n",
    "    return structure\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "274f774b",
   "metadata": {},
   "source": [
    "##  Prompt Templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "944c074c",
   "metadata": {},
   "outputs": [],
   "source": [
    "RESUME_PROMPT_TEMPLATE = \"\"\"\n",
    "You are a JSON resume parser and experience calculator.\n",
    "\n",
    "Given the following resume text, extract a structured JSON following this schema:\n",
    "\n",
    "{schema}\n",
    "\n",
    "Instructions:\n",
    "- Parse education, experience, skills, certifications, and other fields exactly as described.\n",
    "- In the \"experience\" list, if start_date and end_date are missing, try to infer them if mentioned anywhere.\n",
    "- Accept various date formats such as \"March 2007\", \"Mar 07\", \"03/2007\", \"Current\", \"Present\" etc.\n",
    "- Interpret \"Current\", \"Present\", \"Today\" as the current month and year.\n",
    "- Calculate \"total_experience_years\" as the cumulative duration of professional work experience from all roles.\n",
    "    - Overlapping durations should not be double-counted.\n",
    "    - If start and end dates are missing or ambiguous, skip them for total experience calculation.\n",
    "- If a field is missing in the resume, leave it empty (\"\") or an empty list [] depending on the field type.\n",
    "- Return ONLY a valid JSON object. No extra text, no explanations, no markdown formatting.\n",
    "- Your output MUST start with a {{.\n",
    "\n",
    "Resume Text:\n",
    "--------------------\n",
    "{text}\n",
    "--------------------\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "39910f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "JD_PROMPT_TEMPLATE = \"\"\"\n",
    "You are a JSON job description parser and experience extractor.\n",
    "\n",
    "Given the following job description text, extract a structured JSON following this schema:\n",
    "\n",
    "{schema}\n",
    "\n",
    "Instructions:\n",
    "- Parse title, summary, skills, certifications, and other fields exactly as shown.\n",
    "- Pay special attention to \"required_experience_years\":\n",
    "    - If experience years are explicitly listed, extract that number.\n",
    "    - Accept formats like \"5+ years\", \"3-5 years\", \"8 years required\", etc.\n",
    "    - If multiple ranges are mentioned (e.g., \"3-5 years\"), use the lower value (3 years).\n",
    "    - If no years are mentioned explicitly, infer from job title level:\n",
    "        - \"Senior\", \"Lead\" ‚Üí Assume 5+ years\n",
    "        - \"Mid-level\", \"Experienced\" ‚Üí Assume 3 years\n",
    "        - \"Entry level\", \"Junior\" ‚Üí Assume 0-1 years\n",
    "    - If still ambiguous, default to 0 years.\n",
    "- Handle remote/hybrid jobs:\n",
    "    - Set \"remote_option\" = true if remote keywords are present (remote, work from home, hybrid, WFH).\n",
    "- If a field is missing, leave it empty (\"\") or as an empty list [] depending on the field type.\n",
    "- Return ONLY a valid JSON object. No extra text, no explanations, no markdown formatting.\n",
    "- Your output MUST start with a {{.\n",
    "\n",
    "Job Description Text:\n",
    "--------------------\n",
    "{text}\n",
    "--------------------\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebeb4f67",
   "metadata": {},
   "source": [
    "##  Inference + Validation Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d521772",
   "metadata": {},
   "source": [
    "### Generate Raw LLM Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "5d179a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_llm_output(prompt: str, max_new_tokens: int = 1024) -> str:\n",
    "    \"\"\"Run LLM and return the generated text.\"\"\"\n",
    "    try:\n",
    "        return llm_pipeline(prompt, max_new_tokens=max_new_tokens,  do_sample=False)[0][\"generated_text\"]\n",
    "    except Exception as e:\n",
    "        raise RuntimeError(f\"LLM generation failed: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94efd107",
   "metadata": {},
   "source": [
    "### Sanitize Output: Strip Prompt, Fix Cutoffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "efa85362",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sanitize_llm_output(response: str, prompt: str) -> str:\n",
    "    raw = response.replace(prompt, \"\").strip()\n",
    "\n",
    "    # Truncate garbage after the last closing brace\n",
    "    raw = re.sub(r'}[^}]*$', '}', raw)\n",
    "\n",
    "    # Remove markdown bullets or --- headers at end\n",
    "    raw = re.sub(r'(---|‚Ä¢|‚Äì|-)\\s*$', '', raw, flags=re.MULTILINE)\n",
    "\n",
    "    return raw\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa8d3f67",
   "metadata": {},
   "source": [
    "### Regex-based JSON Block Extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "619d88b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def extract_json_block(text: str) -> dict:\n",
    "    \"\"\"\n",
    "    Regex-free fallback JSON block extractor using brace balance.\n",
    "    Finds first balanced {} block.\n",
    "    \"\"\"\n",
    "    stack = []\n",
    "    start = None\n",
    "    for i, char in enumerate(text):\n",
    "        if char == '{':\n",
    "            if not stack:\n",
    "                start = i\n",
    "            stack.append(char)\n",
    "        elif char == '}':\n",
    "            if stack:\n",
    "                stack.pop()\n",
    "                if not stack:\n",
    "                    try:\n",
    "                        return json.loads(text[start:i+1])\n",
    "                    except json.JSONDecodeError:\n",
    "                        continue\n",
    "    raise ValueError(\"No valid JSON object found in fallback.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0de79d7",
   "metadata": {},
   "source": [
    "### Final Orchestrator: Fault-Tolerant Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "c8971393",
   "metadata": {},
   "outputs": [],
   "source": [
    "def truncate_text(text: str, max_chars=1500) -> str:\n",
    "    \"\"\"Trims long resumes/JDs to prevent LLM overload.\"\"\"\n",
    "    return text.strip()[:max_chars]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "dc83f2c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Union\n",
    "\n",
    "def extract_structured_json(\n",
    "    text: str,\n",
    "    prompt_template: str,\n",
    "    schema_model: Union[None, type] = None,\n",
    "    max_new_tokens: int = 1024,\n",
    "    retries: int = 0,\n",
    "    validate: bool = True,\n",
    ") -> dict:\n",
    "    \"\"\"\n",
    "    Runs LLM to extract structured JSON and validates against schema.\n",
    "    Includes: prompt sanitization, retry, echo detection, brace parser fallback, schema validation.\n",
    "    \"\"\"\n",
    "    example_schema = generate_example_structure(schema_model)\n",
    "    schema_str = json.dumps(example_schema, indent=2)\n",
    "    prompt = prompt_template.format(text=truncate_text(text), schema=schema_str)\n",
    "    raw_output = \"\"\n",
    "    attempt = 0\n",
    "\n",
    "    while attempt <= retries:\n",
    "        try:\n",
    "            # Step 1: Get LLM output\n",
    "            response = generate_llm_output(prompt, max_new_tokens)\n",
    "            raw_output = sanitize_llm_output(response, prompt)\n",
    "\n",
    "            # Step 2: Detect schema echo or instruction echo\n",
    "            if \"$schema\" in raw_output or \"Ensure these rules\" in raw_output:\n",
    "                raise ValueError(\"LLM echoed schema or instruction block instead of generating JSON.\")\n",
    "\n",
    "            # Step 3: Try JSON load directly\n",
    "            json_start = raw_output.find(\"{\")\n",
    "            if json_start == -1:\n",
    "                raise ValueError(\"No opening '{' found in LLM output.\")\n",
    "\n",
    "            parsed = json.loads(raw_output[json_start:])\n",
    "\n",
    "            # Step 4: Optional schema validation\n",
    "            if validate and schema_model:\n",
    "                if hasattr(schema_model, \"normalize\"):\n",
    "                    parsed = schema_model.normalize(parsed)\n",
    "                schema_model.model_validate(parsed)\n",
    "\n",
    "            return parsed\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è Attempt {attempt + 1} failed: {e}\")\n",
    "            print(\"üß™ Raw output was:\\n\", raw_output[:300])  # Preview first 300 chars\n",
    "            attempt += 1\n",
    "\n",
    "    # Step 5: Fallback using brace matching\n",
    "    try:\n",
    "        parsed = extract_json_block(raw_output)\n",
    "        if validate and schema_model:\n",
    "            if hasattr(schema_model, \"normalize\"):\n",
    "                parsed = schema_model.normalize(parsed)\n",
    "            schema_model.model_validate(parsed)\n",
    "        return parsed\n",
    "    except Exception as e:\n",
    "        return {\n",
    "            \"raw_output\": raw_output.strip(),\n",
    "            \"error\": f\"Regex fallback failed: {e}\"\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "33f8e0bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import ValidationError\n",
    "\n",
    "def pydantic_validate(model_class, data):\n",
    "    \"\"\"\n",
    "    Version-safe validator that supports both Pydantic v1 and v2.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Pydantic v2\n",
    "        return model_class.model_validate(data)\n",
    "    except AttributeError:\n",
    "        # Fallback to Pydantic v1\n",
    "        return model_class.parse_obj(data)\n",
    "\n",
    "\n",
    "def validate_entry(entry, is_resume):\n",
    "    try:\n",
    "        model = ResumeSchema if is_resume else JobDescriptionSchema\n",
    "        if hasattr(model, \"normalize\"):\n",
    "            normalized = model.normalize(entry)\n",
    "        else:\n",
    "            normalized = entry\n",
    "        pydantic_validate(model, normalized)\n",
    "        return True, None\n",
    "    except ValidationError as ve:\n",
    "        return False, str(ve)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "143847db",
   "metadata": {},
   "source": [
    "##  Normalize in Batches with Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "997f0224",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import uuid\n",
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "\n",
    "def normalize_and_save(\n",
    "    input_filename,\n",
    "    output_filename_prefix,\n",
    "    is_resume=True,\n",
    "    input_dir=Path(\"json_outputs\"),\n",
    "    output_dir=Path(\"json_outputs/normalized\"),\n",
    "    limit: int = None,\n",
    "    resume: bool = True,\n",
    "    save_every: int = 5,\n",
    "    checkpointing: bool = True,\n",
    "    STRICT: bool = True\n",
    "):\n",
    "    # Ensure output directory exists\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    checkpoint_file = output_dir / f\"checkpoint_{output_filename_prefix}.json\"\n",
    "\n",
    "    # Generate output filenames\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M\")\n",
    "    batch_id = uuid.uuid4().hex[:6]\n",
    "    valid_file = f\"{output_filename_prefix}_{timestamp}_{batch_id}.json\"\n",
    "    invalid_file = f\"invalid_{output_filename_prefix}_{timestamp}_{batch_id}.json\"\n",
    "    metadata_file = f\"meta_{output_filename_prefix}_{timestamp}_{batch_id}.json\"\n",
    "\n",
    "    # Load raw input\n",
    "    input_path = input_dir / input_filename\n",
    "    with open(input_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        raw_data = [json.loads(line) for line in f.readlines() if line.strip()]\n",
    "\n",
    "    start_index = 0\n",
    "    results, invalids = [], []\n",
    "\n",
    "    if resume and checkpointing and checkpoint_file.exists():\n",
    "        with open(checkpoint_file, \"r\") as ckpt:\n",
    "            checkpoint = json.load(ckpt)\n",
    "            start_index = checkpoint.get(\"last_index\", 0)\n",
    "            print(f\"üîÅ Resuming from record {start_index}\")\n",
    "\n",
    "    raw_data = raw_data[start_index:]\n",
    "    if limit:\n",
    "        raw_data = raw_data[:limit]\n",
    "\n",
    "    prompt_template = RESUME_PROMPT_TEMPLATE if is_resume else JD_PROMPT_TEMPLATE\n",
    "    schema_model = ResumeSchema if is_resume else JobDescriptionSchema\n",
    "\n",
    "    for idx, record in enumerate(tqdm(raw_data), start=start_index):\n",
    "        text = record.get(\"Resume_str\" if is_resume else \"description\", \"\")\n",
    "        parsed = extract_structured_json(\n",
    "            text=text,\n",
    "            prompt_template=prompt_template,\n",
    "            schema_model=schema_model,\n",
    "            validate=STRICT\n",
    "        )\n",
    "\n",
    "        if \"raw_output\" in parsed or \"error\" in parsed:\n",
    "            invalids.append({\n",
    "                \"input\": text,\n",
    "                \"output\": parsed,\n",
    "                \"error\": parsed.get(\"error\", \"Malformed or unstructured output\")\n",
    "            })\n",
    "            continue\n",
    "\n",
    "        if STRICT:\n",
    "            is_valid, error_msg = validate_entry(parsed, is_resume)\n",
    "            if is_valid:\n",
    "                results.append(parsed)\n",
    "            else:\n",
    "                invalids.append({\n",
    "                    \"input\": text,\n",
    "                    \"output\": parsed,\n",
    "                    \"error\": error_msg\n",
    "                })\n",
    "        else:\n",
    "            results.append(parsed)\n",
    "\n",
    "        # Save periodically\n",
    "        if save_every and ((idx + 1 - start_index) % save_every == 0):\n",
    "            if results:\n",
    "                with open(output_dir / valid_file, \"w\") as f:\n",
    "                    json.dump(results, f, indent=2)\n",
    "            if invalids:\n",
    "                with open(output_dir / invalid_file, \"w\") as f:\n",
    "                    json.dump(invalids, f, indent=2)\n",
    "            if checkpointing:\n",
    "                with open(checkpoint_file, \"w\") as f:\n",
    "                    json.dump({\"last_index\": idx + 1}, f)\n",
    "\n",
    "    # Final save\n",
    "    if results:\n",
    "        with open(output_dir / valid_file, \"w\") as f:\n",
    "            json.dump(results, f, indent=2)\n",
    "    if invalids:\n",
    "        with open(output_dir / invalid_file, \"w\") as f:\n",
    "            json.dump(invalids, f, indent=2)\n",
    "    if checkpointing:\n",
    "        with open(checkpoint_file, \"w\") as f:\n",
    "            json.dump({\"last_index\": start_index + len(raw_data)}, f)\n",
    "\n",
    "    # Metadata summary\n",
    "    meta = {\n",
    "        \"batch_id\": batch_id,\n",
    "        \"timestamp\": timestamp,\n",
    "        \"input_file\": input_filename,\n",
    "        \"valid_output_file\": valid_file if results else None,\n",
    "        \"invalid_output_file\": invalid_file if invalids else None,\n",
    "        \"count_total\": len(raw_data),\n",
    "        \"count_valid\": len(results),\n",
    "        \"count_invalid\": len(invalids),\n",
    "        \"strict_validation\": STRICT,\n",
    "        \"model\": llm_pipeline.model.config.name_or_path,\n",
    "        \"device\": str(next(llm_pipeline.model.parameters()).device)\n",
    "    }\n",
    "    with open(output_dir / metadata_file, \"w\") as f:\n",
    "        json.dump(meta, f, indent=2)\n",
    "\n",
    "    print(f\"‚úÖ Done. Valid: {len(results)} | Invalid: {len(invalids)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34057ff1",
   "metadata": {},
   "source": [
    "## Run Phase 2 End-to-End"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d26b70c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "def run_phase2_structured_normalization():\n",
    "    \n",
    "    normalize_and_save(\n",
    "    input_filename=\"parsed_resumes.json\",\n",
    "    output_filename_prefix=\"normalized_resumes\",\n",
    "    is_resume=True,\n",
    "    limit=50,\n",
    "    resume=True,\n",
    "    STRICT=False,  # or set to False for schema-tolerant mode\n",
    "    input_dir=Path(Config.JSON_OUTPUT_DIR),\n",
    "    output_dir=Path(Config.JSON_OUTPUT_NORMALIZED_DIR)\n",
    "    )\n",
    "    \n",
    "    normalize_and_save(\n",
    "    input_filename=\"parsed_jds.json\",\n",
    "    output_filename_prefix=\"normalized_jds\",\n",
    "    is_resume=False,\n",
    "    limit=50,\n",
    "    resume=True,\n",
    "    STRICT=False,  # or set to False for schema-tolerant mode\n",
    "    input_dir=Path(Config.JSON_OUTPUT_DIR),\n",
    "    output_dir=Path(Config.JSON_OUTPUT_NORMALIZED_DIR)\n",
    "    )\n",
    "    \n",
    "run_phase2_structured_normalization()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48ca168b",
   "metadata": {},
   "source": [
    "# Phase 3 Rubric-Based Scoring Engine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83dbca64",
   "metadata": {},
   "source": [
    "### Imports & Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a18efba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üì• Imports\n",
    "#import json\n",
    "#import pandas as pd\n",
    "#import random\n",
    "#from tqdm import tqdm\n",
    "#import matplotlib.pyplot as plt\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa84e9f4",
   "metadata": {},
   "source": [
    "## Load Normalized Resumes and JDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "74e53aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any\n",
    "import json\n",
    "\n",
    "# üìÇ Load normalized JSON data\n",
    "def load_json_file(file_path: str) -> Any:\n",
    "    if not os.path.isfile(file_path):\n",
    "        raise FileNotFoundError(f\"File not found: {file_path}\")\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        return json.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfe8432c",
   "metadata": {},
   "source": [
    "### Load Resumes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "337dc63b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "resumes_path = os.path.join(Config.JSON_OUTPUT_NORMALIZED_DIR, 'normalized_resumes.json')\n",
    "resumes = load_json_file(resumes_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04a0b647",
   "metadata": {},
   "source": [
    "### Load JDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7b478b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "jds_path = os.path.join(Config.JSON_OUTPUT_NORMALIZED_DIR, 'normalized_jds.json')\n",
    "jds = load_json_file(jds_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47209d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Loaded {len(resumes)} resumes and {len(jds)} job descriptions.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55ede883",
   "metadata": {},
   "source": [
    "## Rule-Based Scoring Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "48c996a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚öôÔ∏è Rule-Based Scoring\n",
    "\n",
    "def skills_match(resume, jd):\n",
    "    resume_skills = set(resume.get(\"skills\", []))\n",
    "    jd_skills = set(jd.get(\"required_skills\", []))\n",
    "    \n",
    "    if not jd_skills:\n",
    "        return {\"score\": 1.0, \"details\": \"JD has no skill requirement.\"}\n",
    "    \n",
    "    matched = resume_skills.intersection(jd_skills)\n",
    "    score = len(matched) / len(jd_skills)\n",
    "    details = f\"Matched skills: {list(matched)}\"\n",
    "    return {\"score\": round(score, 2), \"details\": details}\n",
    "\n",
    "def experience_match(resume, jd):\n",
    "    resume_exp = resume.get(\"total_experience_years\", 0.0)\n",
    "    required_exp = jd.get(\"required_experience_years\", 0.0)\n",
    "    \n",
    "    if required_exp == 0:\n",
    "        return {\"score\": 1.0, \"details\": \"JD has no experience requirement.\"}\n",
    "    \n",
    "    ratio = min(resume_exp / required_exp, 1.0)\n",
    "    details = f\"Resume experience: {resume_exp} yrs vs JD requirement: {required_exp} yrs\"\n",
    "    return {\"score\": round(ratio, 2), \"details\": details}\n",
    "\n",
    "def education_match(resume, jd):\n",
    "    resume_edu = [edu[\"degree\"].lower() for edu in resume.get(\"education\", [])]\n",
    "    preferred_degrees = [deg.lower() for deg in jd.get(\"preferred_degrees\", [])]\n",
    "\n",
    "    if not preferred_degrees:\n",
    "        return {\"score\": 1.0, \"details\": \"No preferred degrees in JD.\"}\n",
    "\n",
    "    matched = set()\n",
    "    for deg in preferred_degrees:\n",
    "        for edu in resume_edu:\n",
    "            if deg in edu:\n",
    "                matched.add(deg)\n",
    "\n",
    "    score = len(matched) / len(preferred_degrees)\n",
    "    details = f\"Matched degrees: {list(matched)}\"\n",
    "    return {\"score\": round(score, 2), \"details\": details}\n",
    "\n",
    "def certifications_match(resume, jd):\n",
    "    resume_certs = set(resume.get(\"certifications\", []))\n",
    "    required_certs = set(jd.get(\"certifications\", []))\n",
    "    \n",
    "    if not required_certs:\n",
    "        return {\"score\": 1.0, \"details\": \"JD has no certification requirement.\"}\n",
    "    \n",
    "    matched = resume_certs.intersection(required_certs)\n",
    "    score = len(matched) / len(required_certs)\n",
    "    details = f\"Matched certifications: {list(matched)}\"\n",
    "    return {\"score\": round(score, 2), \"details\": details}\n",
    "\n",
    "def rule_based_scoring(resume, jd):\n",
    "    return {\n",
    "        \"skills_match\": skills_match(resume, jd),\n",
    "        \"experience_alignment\": experience_match(resume, jd),\n",
    "        \"education_alignment\": education_match(resume, jd),\n",
    "        \"certifications_alignment\": certifications_match(resume, jd)\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb6c9f86",
   "metadata": {},
   "source": [
    "## LLM-Based Scoring Functions (Structured Prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c59346a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_structured_prompt(resume, jd):\n",
    "    prompt = f\"\"\"\n",
    "You are an ATS Resume-JD Matcher Assistant.\n",
    "\n",
    "Given these parsed fields:\n",
    "\n",
    "Resume:\n",
    "Title: {resume.get('basics', {}).get('current_title', '')}\n",
    "Skills: {', '.join(resume.get('skills', []))}\n",
    "Certifications: {', '.join(resume.get('certifications', []))}\n",
    "Experience Years: {resume.get('total_experience_years', 0.0)}\n",
    "\n",
    "Job Description:\n",
    "Title: {jd.get('title', '')}\n",
    "Required Skills: {', '.join(jd.get('required_skills', []))}\n",
    "Required Experience: {jd.get('required_experience_years', 0.0)}\n",
    "Required Certifications: {', '.join(jd.get('certifications', []))}\n",
    "\n",
    "Evaluate and respond ONLY as JSON:\n",
    "{{\n",
    "    \"soft_skills\": {{\"score\": float, \"details\": \"string\"}},\n",
    "    \"transferable_skills\": {{\"score\": float, \"details\": \"string\"}}\n",
    "}}\n",
    "\"\"\"\n",
    "    return prompt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "967fcf70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ü§ñ LLM-Based Scoring\n",
    "import json\n",
    "\n",
    "\n",
    "def llm_based_scoring(resume, jd):\n",
    "    prompt = create_structured_prompt(resume, jd)\n",
    "    try:\n",
    "        response = llm_pipeline(prompt, max_new_tokens=300)[0]['generated_text']\n",
    "        parsed_response = json.loads(response.split('{', 1)[1].rsplit('}', 1)[0].join(['{', '}']))\n",
    "    except Exception as e:\n",
    "        print(f\"LLM Scoring Error: {e}\")\n",
    "        parsed_response = {\n",
    "            \"soft_skills\": {\"score\": 0.5, \"details\": \"LLM fallback\"},\n",
    "            \"transferable_skills\": {\"score\": 0.5, \"details\": \"LLM fallback\"}\n",
    "        }\n",
    "    return parsed_response\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f18a5f9",
   "metadata": {},
   "source": [
    "## Combine Section Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b7f5629d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üîó Combine all section scores\n",
    "\n",
    "def combine_sections(rule_sections, llm_sections):\n",
    "    all_sections = {**rule_sections, **llm_sections}\n",
    "    \n",
    "    total_weight = 0\n",
    "    weighted_score_sum = 0\n",
    "    \n",
    "    section_weights = {\n",
    "        \"skills_match\": 4.0,\n",
    "        \"experience_alignment\": 2.0,\n",
    "        \"education_alignment\": 1.0,\n",
    "        \"certifications_alignment\": 1.0,\n",
    "        \"soft_skills\": 1.0,\n",
    "        \"transferable_skills\": 1.0\n",
    "    }\n",
    "    \n",
    "    for section, content in all_sections.items():\n",
    "        weight = section_weights.get(section, 1.0)\n",
    "        weighted_score_sum += content['score'] * weight\n",
    "        total_weight += weight\n",
    "    \n",
    "    overall_score = weighted_score_sum / total_weight if total_weight else 0.0\n",
    "    return round(overall_score, 4), all_sections\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6036dabf",
   "metadata": {},
   "source": [
    "## Main Scoring Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40fde565",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üîÅ Main Scoring Loop (Corrected)\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "final_scores = []\n",
    "\n",
    "for resume_idx, resume in tqdm(enumerate(resumes), desc=\"Scoring Resumes\", total=len(resumes)):\n",
    "    resume_id = f\"resume_{resume_idx}\"\n",
    "\n",
    "    for jd_idx, jd in enumerate(jds):\n",
    "        jd_id = f\"jd_{jd_idx}\"\n",
    "\n",
    "        rule_sections = rule_based_scoring(resume, jd)\n",
    "        llm_sections = llm_based_scoring(resume, jd)\n",
    "\n",
    "        overall_score, merged_sections = combine_sections(rule_sections, llm_sections)\n",
    "\n",
    "        final_scores.append({\n",
    "            \"resume_id\": resume_id,\n",
    "            \"job_id\": jd_id,\n",
    "            \"overall_score\": overall_score,\n",
    "            \"sections\": merged_sections,\n",
    "            \"scoring_timestamp\": datetime.now().isoformat(),\n",
    "            \"model_used\": \"Nous-Hermes-2-Mistral-7B-DPO\"\n",
    "        })\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80a65449",
   "metadata": {},
   "source": [
    "## Save Final Rich JSON Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71339d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üíæ Save Final ATS Scores\n",
    "save_json_output(final_scores, output_path =\"results/final_ats_scores_rich.json\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a80cc19",
   "metadata": {},
   "source": [
    "## Visualize Score Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8315b23f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìä Score Distribution Plot\n",
    "import matplotlib.pyplot as plt\n",
    "scores = [item['overall_score'] for item in final_scores]\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.hist(scores, bins=20, edgecolor='black')\n",
    "plt.title('Distribution of Final ATS Scores')\n",
    "plt.xlabel('Overall ATS Score')\n",
    "plt.ylabel('Number of Resume-JD Pairs')\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acf63754",
   "metadata": {},
   "source": [
    "## Test phase 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18754f78",
   "metadata": {},
   "source": [
    "#### Load Test Resumes and JDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "19fadabb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìÇ Mini Test Resumes\n",
    "test_resumes = [\n",
    "    {\n",
    "        \"basics\": {\n",
    "            \"name\": \"Alice Smith\",\n",
    "            \"email\": \"alice@example.com\",\n",
    "            \"phone\": \"123-456-7890\",\n",
    "            \"location\": \"New York, NY\",\n",
    "            \"current_title\": \"Software Engineer\",\n",
    "            \"linkedin_url\": \"\"\n",
    "        },\n",
    "        \"education\": [\n",
    "            {\"degree\": \"B.Sc. Computer Science\", \"field\": \"Computer Science\", \"institution\": \"NYU\", \"year\": \"2018\", \"gpa\": \"3.7\"}\n",
    "        ],\n",
    "        \"experience\": [\n",
    "            {\"job_title\": \"Software Developer\", \"company\": \"ABC Corp\", \"start_date\": \"06/2018\", \"end_date\": \"08/2021\", \"duration_in_months\": 38, \"description\": \"Developed web applications.\"}\n",
    "        ],\n",
    "        \"skills\": [\"Python\", \"Django\", \"SQL\"],\n",
    "        \"certifications\": [\"AWS Certified Developer\"],\n",
    "        \"projects\": [\"E-commerce platform\"],\n",
    "        \"languages\": [\"English\"],\n",
    "        \"total_experience_years\": 3.2\n",
    "    },\n",
    "    {\n",
    "        \"basics\": {\n",
    "            \"name\": \"Bob Johnson\",\n",
    "            \"email\": \"bob@example.com\",\n",
    "            \"phone\": \"987-654-3210\",\n",
    "            \"location\": \"San Francisco, CA\",\n",
    "            \"current_title\": \"Data Analyst\",\n",
    "            \"linkedin_url\": \"\"\n",
    "        },\n",
    "        \"education\": [\n",
    "            {\"degree\": \"B.A. Statistics\", \"field\": \"Statistics\", \"institution\": \"UCLA\", \"year\": \"2017\", \"gpa\": \"3.5\"}\n",
    "        ],\n",
    "        \"experience\": [\n",
    "            {\"job_title\": \"Data Analyst\", \"company\": \"XYZ Inc\", \"start_date\": \"01/2018\", \"end_date\": \"12/2020\", \"duration_in_months\": 36, \"description\": \"Analyzed data trends.\"}\n",
    "        ],\n",
    "        \"skills\": [\"SQL\", \"Tableau\", \"Python\"],\n",
    "        \"certifications\": [],\n",
    "        \"projects\": [\"Sales analytics dashboard\"],\n",
    "        \"languages\": [\"English\"],\n",
    "        \"total_experience_years\": 3.0\n",
    "    }\n",
    "]\n",
    "\n",
    "# üìÇ Mini Test JDs\n",
    "test_jds = [\n",
    "    {\n",
    "        \"title\": \"Backend Engineer\",\n",
    "        \"summary\": \"Looking for a backend engineer with 3+ years experience in Python and SQL. AWS certification preferred.\",\n",
    "        \"required_experience_years\": 3.0,\n",
    "        \"preferred_degrees\": [\"B.Sc. Computer Science\"],\n",
    "        \"required_skills\": [\"Python\", \"SQL\"],\n",
    "        \"optional_skills\": [\"Django\"],\n",
    "        \"certifications\": [\"AWS Certified Developer\"],\n",
    "        \"soft_skills\": [\"Teamwork\", \"Communication\"],\n",
    "        \"job_location\": \"New York, NY\",\n",
    "        \"remote_option\": True,\n",
    "        \"employment_type\": \"Full-time\"\n",
    "    },\n",
    "    {\n",
    "        \"title\": \"Business Data Analyst\",\n",
    "        \"summary\": \"Seeking a Data Analyst with 2+ years experience in SQL, Excel, and data visualization tools.\",\n",
    "        \"required_experience_years\": 2.0,\n",
    "        \"preferred_degrees\": [\"B.A. Statistics\"],\n",
    "        \"required_skills\": [\"SQL\", \"Excel\"],\n",
    "        \"optional_skills\": [\"Tableau\"],\n",
    "        \"certifications\": [],\n",
    "        \"soft_skills\": [\"Analytical thinking\", \"Attention to detail\"],\n",
    "        \"job_location\": \"San Francisco, CA\",\n",
    "        \"remote_option\": False,\n",
    "        \"employment_type\": \"Full-time\"\n",
    "    }\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03fc91f6",
   "metadata": {},
   "source": [
    "#### Scoring Loop (Test Batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fd959656",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring Test Resumes:   0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM Scoring Error: Expecting value: line 2 column 30 (char 31)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring Test Resumes:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:12<00:12, 12.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM Scoring Error: Expecting value: line 2 column 30 (char 31)\n",
      "LLM Scoring Error: Expecting value: line 2 column 30 (char 31)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring Test Resumes: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:21<00:00, 10.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM Scoring Error: Expecting value: line 2 column 30 (char 31)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# üîÅ Mini Scoring Loop (2x2 = 4 combinations)\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "\n",
    "test_final_scores = []\n",
    "\n",
    "for resume_idx, resume in tqdm(enumerate(test_resumes), desc=\"Scoring Test Resumes\", total=len(test_resumes)):\n",
    "    resume_id = f\"resume_{resume_idx}\"\n",
    "\n",
    "    for jd_idx, jd in enumerate(test_jds):\n",
    "        jd_id = f\"jd_{jd_idx}\"\n",
    "\n",
    "        rule_sections = rule_based_scoring(resume, jd)\n",
    "        llm_sections = llm_based_scoring(resume, jd)\n",
    "\n",
    "        overall_score, merged_sections = combine_sections(rule_sections, llm_sections)\n",
    "\n",
    "        test_final_scores.append({\n",
    "            \"resume_id\": resume_id,\n",
    "            \"job_id\": jd_id,\n",
    "            \"overall_score\": overall_score,\n",
    "            \"sections\": merged_sections,\n",
    "            \"scoring_timestamp\": datetime.now().isoformat(),\n",
    "            \"model_used\": \"Nous-Hermes-2-Mistral-7B-DPO\"\n",
    "        })\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba92e4e5",
   "metadata": {},
   "source": [
    "#### Save Mini Test Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a6eab9b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Saved output to results/test_final_ats_scores_rich.json\n"
     ]
    }
   ],
   "source": [
    "# üíæ Save Mini Test Output\n",
    "\n",
    "save_json_output(test_final_scores, \"results/test_final_ats_scores_rich.json\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae54c58f",
   "metadata": {},
   "source": [
    "#### View Sample Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4fc2c169",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"resume_id\": \"resume_0\",\n",
      "  \"job_id\": \"jd_0\",\n",
      "  \"overall_score\": 0.9,\n",
      "  \"sections\": {\n",
      "    \"skills_match\": {\n",
      "      \"score\": 1.0,\n",
      "      \"details\": \"Matched skills: ['Python', 'SQL']\"\n",
      "    },\n",
      "    \"experience_alignment\": {\n",
      "      \"score\": 1.0,\n",
      "      \"details\": \"Resume experience: 3.2 yrs vs JD requirement: 3.0 yrs\"\n",
      "    },\n",
      "    \"education_alignment\": {\n",
      "      \"score\": 1.0,\n",
      "      \"details\": \"Matched degrees: ['b.sc. computer science']\"\n",
      "    },\n",
      "    \"certifications_alignment\": {\n",
      "      \"score\": 1.0,\n",
      "      \"details\": \"Matched certifications: ['AWS Certified Developer']\"\n",
      "    },\n",
      "    \"soft_skills\": {\n",
      "      \"score\": 0.5,\n",
      "      \"details\": \"LLM fallback\"\n",
      "    },\n",
      "    \"transferable_skills\": {\n",
      "      \"score\": 0.5,\n",
      "      \"details\": \"LLM fallback\"\n",
      "    }\n",
      "  },\n",
      "  \"scoring_timestamp\": \"2025-04-26T03:01:13.826513\",\n",
      "  \"model_used\": \"Nous-Hermes-2-Mistral-7B-DPO\"\n",
      "}\n",
      "--------------------------------------------------------------------------------\n",
      "{\n",
      "  \"resume_id\": \"resume_0\",\n",
      "  \"job_id\": \"jd_1\",\n",
      "  \"overall_score\": 0.6,\n",
      "  \"sections\": {\n",
      "    \"skills_match\": {\n",
      "      \"score\": 0.5,\n",
      "      \"details\": \"Matched skills: ['SQL']\"\n",
      "    },\n",
      "    \"experience_alignment\": {\n",
      "      \"score\": 1.0,\n",
      "      \"details\": \"Resume experience: 3.2 yrs vs JD requirement: 2.0 yrs\"\n",
      "    },\n",
      "    \"education_alignment\": {\n",
      "      \"score\": 0.0,\n",
      "      \"details\": \"Matched degrees: []\"\n",
      "    },\n",
      "    \"certifications_alignment\": {\n",
      "      \"score\": 1.0,\n",
      "      \"details\": \"JD has no certification requirement.\"\n",
      "    },\n",
      "    \"soft_skills\": {\n",
      "      \"score\": 0.5,\n",
      "      \"details\": \"LLM fallback\"\n",
      "    },\n",
      "    \"transferable_skills\": {\n",
      "      \"score\": 0.5,\n",
      "      \"details\": \"LLM fallback\"\n",
      "    }\n",
      "  },\n",
      "  \"scoring_timestamp\": \"2025-04-26T03:01:19.126942\",\n",
      "  \"model_used\": \"Nous-Hermes-2-Mistral-7B-DPO\"\n",
      "}\n",
      "--------------------------------------------------------------------------------\n",
      "{\n",
      "  \"resume_id\": \"resume_1\",\n",
      "  \"job_id\": \"jd_0\",\n",
      "  \"overall_score\": 0.7,\n",
      "  \"sections\": {\n",
      "    \"skills_match\": {\n",
      "      \"score\": 1.0,\n",
      "      \"details\": \"Matched skills: ['Python', 'SQL']\"\n",
      "    },\n",
      "    \"experience_alignment\": {\n",
      "      \"score\": 1.0,\n",
      "      \"details\": \"Resume experience: 3.0 yrs vs JD requirement: 3.0 yrs\"\n",
      "    },\n",
      "    \"education_alignment\": {\n",
      "      \"score\": 0.0,\n",
      "      \"details\": \"Matched degrees: []\"\n",
      "    },\n",
      "    \"certifications_alignment\": {\n",
      "      \"score\": 0.0,\n",
      "      \"details\": \"Matched certifications: []\"\n",
      "    },\n",
      "    \"soft_skills\": {\n",
      "      \"score\": 0.5,\n",
      "      \"details\": \"LLM fallback\"\n",
      "    },\n",
      "    \"transferable_skills\": {\n",
      "      \"score\": 0.5,\n",
      "      \"details\": \"LLM fallback\"\n",
      "    }\n",
      "  },\n",
      "  \"scoring_timestamp\": \"2025-04-26T03:01:21.389245\",\n",
      "  \"model_used\": \"Nous-Hermes-2-Mistral-7B-DPO\"\n",
      "}\n",
      "--------------------------------------------------------------------------------\n",
      "{\n",
      "  \"resume_id\": \"resume_1\",\n",
      "  \"job_id\": \"jd_1\",\n",
      "  \"overall_score\": 0.7,\n",
      "  \"sections\": {\n",
      "    \"skills_match\": {\n",
      "      \"score\": 0.5,\n",
      "      \"details\": \"Matched skills: ['SQL']\"\n",
      "    },\n",
      "    \"experience_alignment\": {\n",
      "      \"score\": 1.0,\n",
      "      \"details\": \"Resume experience: 3.0 yrs vs JD requirement: 2.0 yrs\"\n",
      "    },\n",
      "    \"education_alignment\": {\n",
      "      \"score\": 1.0,\n",
      "      \"details\": \"Matched degrees: ['b.a. statistics']\"\n",
      "    },\n",
      "    \"certifications_alignment\": {\n",
      "      \"score\": 1.0,\n",
      "      \"details\": \"JD has no certification requirement.\"\n",
      "    },\n",
      "    \"soft_skills\": {\n",
      "      \"score\": 0.5,\n",
      "      \"details\": \"LLM fallback\"\n",
      "    },\n",
      "    \"transferable_skills\": {\n",
      "      \"score\": 0.5,\n",
      "      \"details\": \"LLM fallback\"\n",
      "    }\n",
      "  },\n",
      "  \"scoring_timestamp\": \"2025-04-26T03:01:28.143553\",\n",
      "  \"model_used\": \"Nous-Hermes-2-Mistral-7B-DPO\"\n",
      "}\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# üìú View first few records\n",
    "\n",
    "for record in test_final_scores:\n",
    "    print(json.dumps(record, indent=2))\n",
    "    print(\"-\" * 80)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.10)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
