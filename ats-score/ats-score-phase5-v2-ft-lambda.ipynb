{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a62a7e73",
   "metadata": {},
   "source": [
    "## Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "80839423",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: kagglehub in /home/ubuntu/AI-resume-agent/myenv/lib/python3.10/site-packages (0.3.12)\n",
      "Requirement already satisfied: pandas in /home/ubuntu/AI-resume-agent/myenv/lib/python3.10/site-packages (2.3.0)\n",
      "Requirement already satisfied: tqdm in /home/ubuntu/AI-resume-agent/myenv/lib/python3.10/site-packages (from kagglehub) (4.67.1)\n",
      "Requirement already satisfied: pyyaml in /home/ubuntu/AI-resume-agent/myenv/lib/python3.10/site-packages (from kagglehub) (6.0.2)\n",
      "Requirement already satisfied: packaging in /home/ubuntu/AI-resume-agent/myenv/lib/python3.10/site-packages (from kagglehub) (25.0)\n",
      "Requirement already satisfied: requests in /home/ubuntu/AI-resume-agent/myenv/lib/python3.10/site-packages (from kagglehub) (2.32.4)\n",
      "Requirement already satisfied: numpy>=1.22.4 in /home/ubuntu/AI-resume-agent/myenv/lib/python3.10/site-packages (from pandas) (2.2.6)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/ubuntu/AI-resume-agent/myenv/lib/python3.10/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/ubuntu/AI-resume-agent/myenv/lib/python3.10/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/ubuntu/AI-resume-agent/myenv/lib/python3.10/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in /home/ubuntu/AI-resume-agent/myenv/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ubuntu/AI-resume-agent/myenv/lib/python3.10/site-packages (from requests->kagglehub) (2.5.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/ubuntu/AI-resume-agent/myenv/lib/python3.10/site-packages (from requests->kagglehub) (3.4.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ubuntu/AI-resume-agent/myenv/lib/python3.10/site-packages (from requests->kagglehub) (2025.6.15)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ubuntu/AI-resume-agent/myenv/lib/python3.10/site-packages (from requests->kagglehub) (3.10)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "torchvision 0.20.1+cu121 requires torch==2.5.1, but you have torch 2.7.0 which is incompatible.\n",
      "torchaudio 2.5.1+cu121 requires torch==2.5.1, but you have torch 2.7.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n",
      "Collecting optuna\n",
      "  Downloading optuna-4.4.0-py3-none-any.whl (395 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m395.9/395.9 KB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: PyYAML in /home/ubuntu/AI-resume-agent/myenv/lib/python3.10/site-packages (from optuna) (6.0.2)\n",
      "Collecting alembic>=1.5.0\n",
      "  Downloading alembic-1.16.2-py3-none-any.whl (242 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m242.7/242.7 KB\u001b[0m \u001b[31m43.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting sqlalchemy>=1.4.2\n",
      "  Downloading sqlalchemy-2.0.41-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m55.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /home/ubuntu/AI-resume-agent/myenv/lib/python3.10/site-packages (from optuna) (25.0)\n",
      "Requirement already satisfied: tqdm in /home/ubuntu/AI-resume-agent/myenv/lib/python3.10/site-packages (from optuna) (4.67.1)\n",
      "Collecting colorlog\n",
      "  Downloading colorlog-6.9.0-py3-none-any.whl (11 kB)\n",
      "Requirement already satisfied: numpy in /home/ubuntu/AI-resume-agent/myenv/lib/python3.10/site-packages (from optuna) (2.2.6)\n",
      "Collecting tomli\n",
      "  Downloading tomli-2.2.1-py3-none-any.whl (14 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.12 in /home/ubuntu/AI-resume-agent/myenv/lib/python3.10/site-packages (from alembic>=1.5.0->optuna) (4.14.0)\n",
      "Collecting Mako\n",
      "  Downloading mako-1.3.10-py3-none-any.whl (78 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.5/78.5 KB\u001b[0m \u001b[31m20.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting greenlet>=1\n",
      "  Downloading greenlet-3.2.3-cp310-cp310-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (582 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m582.2/582.2 KB\u001b[0m \u001b[31m68.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: MarkupSafe>=0.9.2 in /home/ubuntu/AI-resume-agent/myenv/lib/python3.10/site-packages (from Mako->alembic>=1.5.0->optuna) (3.0.2)\n",
      "Installing collected packages: tomli, Mako, greenlet, colorlog, sqlalchemy, alembic, optuna\n",
      "Successfully installed Mako-1.3.10 alembic-1.16.2 colorlog-6.9.0 greenlet-3.2.3 optuna-4.4.0 sqlalchemy-2.0.41 tomli-2.2.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Looking in indexes: https://download.pytorch.org/whl/cu121\n",
      "Requirement already satisfied: torch in /home/ubuntu/AI-resume-agent/myenv/lib/python3.10/site-packages (2.7.0)\n",
      "Requirement already satisfied: torchvision in /home/ubuntu/AI-resume-agent/myenv/lib/python3.10/site-packages (0.20.1+cu121)\n",
      "Requirement already satisfied: torchaudio in /home/ubuntu/AI-resume-agent/myenv/lib/python3.10/site-packages (2.5.1+cu121)\n",
      "Requirement already satisfied: fsspec in /home/ubuntu/AI-resume-agent/myenv/lib/python3.10/site-packages (from torch) (2025.3.0)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /home/ubuntu/AI-resume-agent/myenv/lib/python3.10/site-packages (from torch) (11.3.0.4)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /home/ubuntu/AI-resume-agent/myenv/lib/python3.10/site-packages (from torch) (12.5.4.2)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /home/ubuntu/AI-resume-agent/myenv/lib/python3.10/site-packages (from torch) (4.14.0)\n",
      "Requirement already satisfied: networkx in /home/ubuntu/AI-resume-agent/myenv/lib/python3.10/site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /home/ubuntu/AI-resume-agent/myenv/lib/python3.10/site-packages (from torch) (12.6.4.1)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.3 in /home/ubuntu/AI-resume-agent/myenv/lib/python3.10/site-packages (from torch) (0.6.3)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /home/ubuntu/AI-resume-agent/myenv/lib/python3.10/site-packages (from torch) (12.6.85)\n",
      "Requirement already satisfied: jinja2 in /home/ubuntu/AI-resume-agent/myenv/lib/python3.10/site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /home/ubuntu/AI-resume-agent/myenv/lib/python3.10/site-packages (from torch) (12.6.77)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /home/ubuntu/AI-resume-agent/myenv/lib/python3.10/site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /home/ubuntu/AI-resume-agent/myenv/lib/python3.10/site-packages (from torch) (10.3.7.77)\n",
      "Requirement already satisfied: triton==3.3.0 in /home/ubuntu/AI-resume-agent/myenv/lib/python3.10/site-packages (from torch) (3.3.0)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /home/ubuntu/AI-resume-agent/myenv/lib/python3.10/site-packages (from torch) (12.6.80)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /home/ubuntu/AI-resume-agent/myenv/lib/python3.10/site-packages (from torch) (1.11.1.6)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /home/ubuntu/AI-resume-agent/myenv/lib/python3.10/site-packages (from torch) (11.7.1.2)\n",
      "Requirement already satisfied: filelock in /home/ubuntu/AI-resume-agent/myenv/lib/python3.10/site-packages (from torch) (3.18.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /home/ubuntu/AI-resume-agent/myenv/lib/python3.10/site-packages (from torch) (12.6.77)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /home/ubuntu/AI-resume-agent/myenv/lib/python3.10/site-packages (from torch) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.5.1.17 in /home/ubuntu/AI-resume-agent/myenv/lib/python3.10/site-packages (from torch) (9.5.1.17)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.26.2 in /home/ubuntu/AI-resume-agent/myenv/lib/python3.10/site-packages (from torch) (2.26.2)\n",
      "Requirement already satisfied: setuptools>=40.8.0 in /home/ubuntu/AI-resume-agent/myenv/lib/python3.10/site-packages (from triton==3.3.0->torch) (59.6.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /home/ubuntu/AI-resume-agent/myenv/lib/python3.10/site-packages (from torchvision) (11.0.0)\n",
      "Collecting torch\n",
      "  Using cached https://download.pytorch.org/whl/cu121/torch-2.5.1%2Bcu121-cp310-cp310-linux_x86_64.whl (780.4 MB)\n",
      "Requirement already satisfied: numpy in /home/ubuntu/AI-resume-agent/myenv/lib/python3.10/site-packages (from torchvision) (2.2.6)\n",
      "INFO: pip is looking at multiple versions of torchvision to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting torchvision\n",
      "  Using cached https://download.pytorch.org/whl/cu121/torchvision-0.20.1%2Bcu121-cp310-cp310-linux_x86_64.whl (7.3 MB)\n",
      "INFO: pip is looking at multiple versions of <Python from Requires-Python> to determine which version is compatible with other requirements. This could take a while.\n",
      "  Using cached https://download.pytorch.org/whl/cu121/torchvision-0.20.0%2Bcu121-cp310-cp310-linux_x86_64.whl (7.3 MB)\n",
      "Collecting torch\n",
      "  Using cached https://download.pytorch.org/whl/cu121/torch-2.5.0%2Bcu121-cp310-cp310-linux_x86_64.whl (780.4 MB)\n",
      "Collecting torchvision\n",
      "  Using cached https://download.pytorch.org/whl/cu121/torchvision-0.19.1%2Bcu121-cp310-cp310-linux_x86_64.whl (7.1 MB)\n",
      "Collecting torch\n",
      "  Using cached https://download.pytorch.org/whl/cu121/torch-2.4.1%2Bcu121-cp310-cp310-linux_x86_64.whl (798.9 MB)\n",
      "Collecting torchvision\n",
      "  Using cached https://download.pytorch.org/whl/cu121/torchvision-0.19.0%2Bcu121-cp310-cp310-linux_x86_64.whl (7.1 MB)\n",
      "Collecting torch\n",
      "  Using cached https://download.pytorch.org/whl/cu121/torch-2.4.0%2Bcu121-cp310-cp310-linux_x86_64.whl (799.1 MB)\n",
      "Collecting torchvision\n",
      "  Using cached https://download.pytorch.org/whl/cu121/torchvision-0.18.1%2Bcu121-cp310-cp310-linux_x86_64.whl (7.0 MB)\n",
      "Collecting torch\n",
      "  Using cached https://download.pytorch.org/whl/cu121/torch-2.3.1%2Bcu121-cp310-cp310-linux_x86_64.whl (781.0 MB)\n",
      "Collecting torchvision\n",
      "  Using cached https://download.pytorch.org/whl/cu121/torchvision-0.18.0%2Bcu121-cp310-cp310-linux_x86_64.whl (7.0 MB)\n",
      "Collecting torch\n",
      "  Using cached https://download.pytorch.org/whl/cu121/torch-2.3.0%2Bcu121-cp310-cp310-linux_x86_64.whl (781.0 MB)\n",
      "Collecting torchvision\n",
      "  Using cached https://download.pytorch.org/whl/cu121/torchvision-0.17.2%2Bcu121-cp310-cp310-linux_x86_64.whl (7.0 MB)\n",
      "Collecting torch\n",
      "  Using cached https://download.pytorch.org/whl/cu121/torch-2.2.2%2Bcu121-cp310-cp310-linux_x86_64.whl (757.3 MB)\n",
      "INFO: pip is looking at multiple versions of torchvision to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting torchvision\n",
      "  Using cached https://download.pytorch.org/whl/cu121/torchvision-0.17.1%2Bcu121-cp310-cp310-linux_x86_64.whl (7.0 MB)\n",
      "Collecting torch\n",
      "  Using cached https://download.pytorch.org/whl/cu121/torch-2.2.1%2Bcu121-cp310-cp310-linux_x86_64.whl (757.3 MB)\n",
      "INFO: pip is looking at multiple versions of <Python from Requires-Python> to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting torchvision\n",
      "  Using cached https://download.pytorch.org/whl/cu121/torchvision-0.17.0%2Bcu121-cp310-cp310-linux_x86_64.whl (7.0 MB)\n",
      "Collecting torch\n",
      "  Using cached https://download.pytorch.org/whl/cu121/torch-2.2.0%2Bcu121-cp310-cp310-linux_x86_64.whl (757.3 MB)\n",
      "Requirement already satisfied: requests in /home/ubuntu/AI-resume-agent/myenv/lib/python3.10/site-packages (from torchvision) (2.32.4)\n",
      "Collecting torchvision\n",
      "  Using cached https://download.pytorch.org/whl/cu121/torchvision-0.16.2%2Bcu121-cp310-cp310-linux_x86_64.whl (6.8 MB)\n",
      "Collecting torch\n",
      "  Using cached https://download.pytorch.org/whl/cu121/torch-2.1.2%2Bcu121-cp310-cp310-linux_x86_64.whl (2200.7 MB)\n",
      "Collecting torchvision\n",
      "  Using cached https://download.pytorch.org/whl/cu121/torchvision-0.16.1%2Bcu121-cp310-cp310-linux_x86_64.whl (6.8 MB)\n",
      "Collecting torch\n",
      "  Using cached https://download.pytorch.org/whl/cu121/torch-2.1.1%2Bcu121-cp310-cp310-linux_x86_64.whl (2200.7 MB)\n",
      "Collecting torchvision\n",
      "  Using cached https://download.pytorch.org/whl/cu121/torchvision-0.16.0%2Bcu121-cp310-cp310-linux_x86_64.whl (7.0 MB)\n",
      "Collecting torch\n",
      "  Using cached https://download.pytorch.org/whl/cu121/torch-2.1.0%2Bcu121-cp310-cp310-linux_x86_64.whl (2200.6 MB)\n",
      "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
      "Collecting torchvision\n",
      "  Using cached https://download.pytorch.org/whl/torchvision-0.2.0-py2.py3-none-any.whl (48 kB)\n",
      "Requirement already satisfied: six in /home/ubuntu/AI-resume-agent/myenv/lib/python3.10/site-packages (from torchvision) (1.17.0)\n",
      "INFO: pip is looking at multiple versions of torchaudio to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting torchaudio\n",
      "  Using cached https://download.pytorch.org/whl/cu121/torchaudio-2.5.1%2Bcu121-cp310-cp310-linux_x86_64.whl (3.4 MB)\n",
      "  Using cached https://download.pytorch.org/whl/cu121/torchaudio-2.5.0%2Bcu121-cp310-cp310-linux_x86_64.whl (3.4 MB)\n",
      "  Using cached https://download.pytorch.org/whl/cu121/torchaudio-2.4.1%2Bcu121-cp310-cp310-linux_x86_64.whl (3.4 MB)\n",
      "  Using cached https://download.pytorch.org/whl/cu121/torchaudio-2.4.0%2Bcu121-cp310-cp310-linux_x86_64.whl (3.4 MB)\n",
      "  Using cached https://download.pytorch.org/whl/cu121/torchaudio-2.3.1%2Bcu121-cp310-cp310-linux_x86_64.whl (3.4 MB)\n",
      "  Using cached https://download.pytorch.org/whl/cu121/torchaudio-2.3.0%2Bcu121-cp310-cp310-linux_x86_64.whl (3.4 MB)\n",
      "  Using cached https://download.pytorch.org/whl/cu121/torchaudio-2.2.2%2Bcu121-cp310-cp310-linux_x86_64.whl (3.4 MB)\n",
      "INFO: pip is looking at multiple versions of torchaudio to determine which version is compatible with other requirements. This could take a while.\n",
      "  Using cached https://download.pytorch.org/whl/cu121/torchaudio-2.2.1%2Bcu121-cp310-cp310-linux_x86_64.whl (3.4 MB)\n",
      "  Using cached https://download.pytorch.org/whl/cu121/torchaudio-2.2.0%2Bcu121-cp310-cp310-linux_x86_64.whl (3.4 MB)\n",
      "  Using cached https://download.pytorch.org/whl/cu121/torchaudio-2.1.2%2Bcu121-cp310-cp310-linux_x86_64.whl (3.3 MB)\n",
      "  Using cached https://download.pytorch.org/whl/cu121/torchaudio-2.1.1%2Bcu121-cp310-cp310-linux_x86_64.whl (3.3 MB)\n",
      "  Using cached https://download.pytorch.org/whl/cu121/torchaudio-2.1.0%2Bcu121-cp310-cp310-linux_x86_64.whl (3.3 MB)\n",
      "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
      "Collecting torchvision\n",
      "  Using cached https://download.pytorch.org/whl/torchvision-0.1.6-py3-none-any.whl (16 kB)\n",
      "INFO: pip is looking at multiple versions of triton to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting triton==3.3.0\n",
      "  Using cached https://download.pytorch.org/whl/triton-3.3.0-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (156.4 MB)\n",
      "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
      "INFO: pip is looking at multiple versions of nvidia-nvtx-cu12 to determine which version is compatible with other requirements. This could take a while.\n",
      "INFO: pip is looking at multiple versions of nvidia-nvjitlink-cu12 to determine which version is compatible with other requirements. This could take a while.\n",
      "INFO: pip is looking at multiple versions of nvidia-nccl-cu12 to determine which version is compatible with other requirements. This could take a while.\n",
      "INFO: pip is looking at multiple versions of nvidia-cusparselt-cu12 to determine which version is compatible with other requirements. This could take a while.\n",
      "INFO: pip is looking at multiple versions of nvidia-cusparse-cu12 to determine which version is compatible with other requirements. This could take a while.\n",
      "INFO: pip is looking at multiple versions of nvidia-cusolver-cu12 to determine which version is compatible with other requirements. This could take a while.\n",
      "INFO: pip is looking at multiple versions of nvidia-curand-cu12 to determine which version is compatible with other requirements. This could take a while.\n",
      "INFO: pip is looking at multiple versions of nvidia-cufile-cu12 to determine which version is compatible with other requirements. This could take a while.\n",
      "INFO: pip is looking at multiple versions of nvidia-cufft-cu12 to determine which version is compatible with other requirements. This could take a while.\n",
      "INFO: pip is looking at multiple versions of nvidia-cudnn-cu12 to determine which version is compatible with other requirements. This could take a while.\n",
      "INFO: pip is looking at multiple versions of nvidia-cuda-runtime-cu12 to determine which version is compatible with other requirements. This could take a while.\n",
      "INFO: pip is looking at multiple versions of nvidia-cuda-nvrtc-cu12 to determine which version is compatible with other requirements. This could take a while.\n",
      "INFO: pip is looking at multiple versions of nvidia-cuda-cupti-cu12 to determine which version is compatible with other requirements. This could take a while.\n",
      "INFO: pip is looking at multiple versions of nvidia-cublas-cu12 to determine which version is compatible with other requirements. This could take a while.\n",
      "INFO: pip is looking at multiple versions of torch to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting nvidia-cufft-cu12==11.0.2.54\n",
      "  Using cached https://download.pytorch.org/whl/cu121/nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
      "Collecting nvidia-cublas-cu12==12.1.3.1\n",
      "  Using cached https://download.pytorch.org/whl/cu121/nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
      "Collecting nvidia-nvtx-cu12==12.1.105\n",
      "  Using cached https://download.pytorch.org/whl/cu121/nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.1.105\n",
      "  Using cached https://download.pytorch.org/whl/cu121/nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
      "Collecting sympy==1.13.1\n",
      "  Using cached https://download.pytorch.org/whl/sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
      "Collecting nvidia-cusparse-cu12==12.1.0.106\n",
      "  Using cached https://download.pytorch.org/whl/cu121/nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
      "Collecting nvidia-cusolver-cu12==11.4.5.107\n",
      "  Using cached https://download.pytorch.org/whl/cu121/nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
      "Collecting nvidia-cudnn-cu12==9.1.0.70\n",
      "  Using cached https://download.pytorch.org/whl/cu121/nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.1.105\n",
      "  Using cached https://download.pytorch.org/whl/cu121/nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
      "Collecting triton==3.1.0\n",
      "  Using cached https://download.pytorch.org/whl/triton-3.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (209.5 MB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.1.105\n",
      "  Using cached https://download.pytorch.org/whl/cu121/nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.2.106\n",
      "  Using cached https://download.pytorch.org/whl/cu121/nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
      "Collecting nvidia-nccl-cu12==2.21.5\n",
      "  Using cached https://download.pytorch.org/whl/nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl (188.7 MB)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/ubuntu/AI-resume-agent/myenv/lib/python3.10/site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/ubuntu/AI-resume-agent/myenv/lib/python3.10/site-packages (from jinja2->torch) (3.0.2)\n",
      "Installing collected packages: triton, sympy, nvidia-nvtx-cu12, nvidia-nccl-cu12, nvidia-cusparse-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusolver-cu12, nvidia-cudnn-cu12, torch\n",
      "  Attempting uninstall: triton\n",
      "    Found existing installation: triton 3.3.0\n",
      "    Uninstalling triton-3.3.0:\n",
      "      Successfully uninstalled triton-3.3.0\n",
      "  Attempting uninstall: sympy\n",
      "    Found existing installation: sympy 1.14.0\n",
      "    Uninstalling sympy-1.14.0:\n",
      "      Successfully uninstalled sympy-1.14.0\n",
      "  Attempting uninstall: nvidia-nvtx-cu12\n",
      "    Found existing installation: nvidia-nvtx-cu12 12.6.77\n",
      "    Uninstalling nvidia-nvtx-cu12-12.6.77:\n",
      "      Successfully uninstalled nvidia-nvtx-cu12-12.6.77\n",
      "  Attempting uninstall: nvidia-nccl-cu12\n",
      "    Found existing installation: nvidia-nccl-cu12 2.26.2\n",
      "    Uninstalling nvidia-nccl-cu12-2.26.2:\n",
      "      Successfully uninstalled nvidia-nccl-cu12-2.26.2\n",
      "  Attempting uninstall: nvidia-cusparse-cu12\n",
      "    Found existing installation: nvidia-cusparse-cu12 12.5.4.2\n",
      "    Uninstalling nvidia-cusparse-cu12-12.5.4.2:\n",
      "      Successfully uninstalled nvidia-cusparse-cu12-12.5.4.2\n",
      "  Attempting uninstall: nvidia-curand-cu12\n",
      "    Found existing installation: nvidia-curand-cu12 10.3.7.77\n",
      "    Uninstalling nvidia-curand-cu12-10.3.7.77:\n",
      "      Successfully uninstalled nvidia-curand-cu12-10.3.7.77\n",
      "  Attempting uninstall: nvidia-cufft-cu12\n",
      "    Found existing installation: nvidia-cufft-cu12 11.3.0.4\n",
      "    Uninstalling nvidia-cufft-cu12-11.3.0.4:\n",
      "      Successfully uninstalled nvidia-cufft-cu12-11.3.0.4\n",
      "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
      "    Found existing installation: nvidia-cuda-runtime-cu12 12.6.77\n",
      "    Uninstalling nvidia-cuda-runtime-cu12-12.6.77:\n",
      "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.6.77\n",
      "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
      "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.6.77\n",
      "    Uninstalling nvidia-cuda-nvrtc-cu12-12.6.77:\n",
      "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.6.77\n",
      "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
      "    Found existing installation: nvidia-cuda-cupti-cu12 12.6.80\n",
      "    Uninstalling nvidia-cuda-cupti-cu12-12.6.80:\n",
      "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.6.80\n",
      "  Attempting uninstall: nvidia-cublas-cu12\n",
      "    Found existing installation: nvidia-cublas-cu12 12.6.4.1\n",
      "    Uninstalling nvidia-cublas-cu12-12.6.4.1:\n",
      "      Successfully uninstalled nvidia-cublas-cu12-12.6.4.1\n",
      "  Attempting uninstall: nvidia-cusolver-cu12\n",
      "    Found existing installation: nvidia-cusolver-cu12 11.7.1.2\n",
      "    Uninstalling nvidia-cusolver-cu12-11.7.1.2:\n",
      "      Successfully uninstalled nvidia-cusolver-cu12-11.7.1.2\n",
      "  Attempting uninstall: nvidia-cudnn-cu12\n",
      "    Found existing installation: nvidia-cudnn-cu12 9.5.1.17\n",
      "    Uninstalling nvidia-cudnn-cu12-9.5.1.17:\n",
      "      Successfully uninstalled nvidia-cudnn-cu12-9.5.1.17\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 2.7.0\n",
      "    Uninstalling torch-2.7.0:\n",
      "      Successfully uninstalled torch-2.7.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "xformers 0.0.30 requires torch==2.7.0, but you have torch 2.5.1+cu121 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.21.5 nvidia-nvtx-cu12-12.1.105 sympy-1.13.1 torch-2.5.1+cu121 triton-3.1.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install kagglehub pandas\n",
    "%pip install -q transformers peft datasets accelerate bitsandbytes sentencepiece pydantic huggingface_hub xformers\n",
    "%pip install optuna\n",
    "\n",
    "#%pip install torch==2.2.2 torchvision==0.17.2 torchaudio==2.2.2 --index-url https://download.pytorch.org/whl/cu121\n",
    "%pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121\n",
    "#%pip install --pre torch torchvision torchaudio --index-url https://download.pytorch.org/whl/nightly/cu128\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e991874",
   "metadata": {},
   "source": [
    "## Configurations  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ec2f4fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================\n",
    "# 🛠 CONFIGURATION\n",
    "# ==============================\n",
    "\n",
    "class Config:\n",
    "    JSON_OUTPUT_DIR = \"json_outputs_all_data\"\n",
    "    JSON_OUTPUT_NORMALIZED_DIR = \"json_outputs_all_data/normalized\"\n",
    "    JSON_OUTPUT_NORMALIZED_JD = \"json_outputs_all_data/normalized/jd\"\n",
    "    JSON_OUTPUT_NORMALIZED_RESUME = \"json_outputs_all_data/normalized/resume\"\n",
    "    JSON_OUTPUT_SCORING_DIR = \"json_outputs_all_data/scoring\"\n",
    "    JSON_OUTPUT_SCORING_SPLIT_DIR = \"json_outputs_all_data/scoring/split\"\n",
    "    JSON_OUTPUT_SCORING_FT_DATA = \"json_outputs_all_data/scoring/FT_data\"\n",
    "    JSON_OUTPUT_FINE_TUNE_SCORE = \"json_outputs_all_data/fine-tune/scored\"\n",
    "    JSON_OUTPUT_FINE_TUNE_RECORD = \"json_outputs_all_data/fine-tune/record\"\n",
    "    JSON_OUTPUT_FINE_TUNE_TEST_DATA = \"json_outputs_all_data/fine-tune/test-data\"\n",
    "    JSON_OUTPUT_FINE_TUNE_OUTPUT = \"json_outputs_all_data/fine-tune/optuna_output\"\n",
    "    JSON_OUTPUT_FINE_TUNE_MODEL = \"json_outputs_all_data/fine-tune/model\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecca7f7f",
   "metadata": {},
   "source": [
    "## Login to huggingface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f223e97",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/AI-resume-agent/myenv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import login\n",
    "import os\n",
    "\n",
    "# Set your token here securely or prompt for it in Colab\n",
    "# Recommended: store in Colab secrets or environment variable\n",
    "HF_TOKEN = os.getenv(\"HUGGINGFACE_TOKEN\")\n",
    "\n",
    "\n",
    "if not HF_TOKEN:\n",
    "    # Prompt for token if not set in environment\n",
    "    print(\"🔑 Please enter your Hugging Face token:\")\n",
    "    # For Colab or local prompt input\n",
    "    HF_TOKEN = input(\"🔑 Enter your Hugging Face token: \").strip()\n",
    "\n",
    "login(token=HF_TOKEN)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97cd1793",
   "metadata": {},
   "source": [
    "# Full Fine-Tuning on Lambda with Optuna, LR Scheduler, Early Stopping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7002494a",
   "metadata": {},
   "source": [
    "### Imports & Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "22f8df89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "import os\n",
    "from transformers import TrainingArguments, Trainer, EarlyStoppingCallback\n",
    "from datasets import load_dataset, DatasetDict\n",
    "from peft import LoraConfig, get_peft_model, TaskType\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, DataCollatorForLanguageModeling\n",
    "import torch\n",
    "from transformers import BitsAndBytesConfig\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fb6a859",
   "metadata": {},
   "source": [
    "### Paths & Basic Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4fab610c",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"Qwen/Qwen2-7B-Instruct\"\n",
    "\n",
    "\n",
    "# ✅ Paths\n",
    "train_path =os.path.join(Config.JSON_OUTPUT_FINE_TUNE_TEST_DATA, \"train.jsonl\") \n",
    "eval_path = os.path.join(Config.JSON_OUTPUT_FINE_TUNE_TEST_DATA, \"eval.jsonl\") \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e66d88d8",
   "metadata": {},
   "source": [
    "### Load Tokenizer & Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b9f92ab8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 23995 examples [00:00, 40014.30 examples/s]\n",
      "Generating validation split: 5999 examples [00:00, 39194.83 examples/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, trust_remote_code=True)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "\n",
    "data = load_dataset(\"json\", data_files={\"train\": train_path, \"validation\": eval_path})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b4d9e07",
   "metadata": {},
   "source": [
    "### Tokenization Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cba89c42",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 23995/23995 [02:58<00:00, 134.23 examples/s]\n",
      "Map: 100%|██████████| 5999/5999 [00:43<00:00, 138.10 examples/s]\n"
     ]
    }
   ],
   "source": [
    "def tokenize(example):\n",
    "    prompt = f\"<|im_start|>user\\n{example['input']}<|im_end|>\\n<|im_start|>assistant\\n{example['output']}<|im_end|>\"\n",
    "    tokens = tokenizer(prompt, padding=\"max_length\", truncation=True, max_length=1024)\n",
    "    tokens[\"labels\"] = tokens[\"input_ids\"].copy()\n",
    "    return tokens\n",
    "\n",
    "\n",
    "tokenized_data = data.map(tokenize, remove_columns=data[\"train\"].column_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "591ca392",
   "metadata": {},
   "source": [
    "### Define Optuna Objective Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e0088158",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    from peft import prepare_model_for_kbit_training\n",
    "\n",
    "    # Hyperparameter suggestions\n",
    "    learning_rate = trial.suggest_float(\"learning_rate\", 5e-5, 5e-4, log=True)\n",
    "    num_train_epochs = trial.suggest_int(\"num_train_epochs\", 2, 4)\n",
    "    lora_r = trial.suggest_categorical(\"lora_r\", [4, 8, 16])\n",
    "    lora_alpha = trial.suggest_categorical(\"lora_alpha\", [16, 32, 64])\n",
    "\n",
    "    # Load base model with bitsandbytes quantization (no meta tensor error)\n",
    "    bnb_config = BitsAndBytesConfig(\n",
    "        load_in_4bit=True,\n",
    "        bnb_4bit_use_double_quant=True,\n",
    "        bnb_4bit_quant_type=\"nf4\",\n",
    "        bnb_4bit_compute_dtype=torch.bfloat16,\n",
    "    )\n",
    "\n",
    "    base_model = AutoModelForCausalLM.from_pretrained(\n",
    "        MODEL_NAME,\n",
    "        quantization_config=bnb_config,\n",
    "        device_map=\"auto\",\n",
    "        trust_remote_code=True,\n",
    "    )\n",
    "\n",
    "    base_model = prepare_model_for_kbit_training(base_model)\n",
    "\n",
    "    # Apply LoRA\n",
    "    lora_config = LoraConfig(\n",
    "        r=lora_r,\n",
    "        lora_alpha=lora_alpha,\n",
    "        target_modules=[\"q_proj\", \"v_proj\"],\n",
    "        lora_dropout=0.05,\n",
    "        bias=\"none\",\n",
    "        task_type=TaskType.CAUSAL_LM\n",
    "    )\n",
    "    model = get_peft_model(base_model, lora_config)\n",
    "\n",
    "    # Output directories for current trial\n",
    "    output_dir = os.path.join(Config.JSON_OUTPUT_FINE_TUNE_OUTPUT, f\"optuna_trial_{trial.number}\")\n",
    "    logging_dir = os.path.join(output_dir, \"logs\")\n",
    "\n",
    "    # Training arguments\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=output_dir,\n",
    "        per_device_train_batch_size=2,\n",
    "        per_device_eval_batch_size=2,\n",
    "        gradient_accumulation_steps=8,\n",
    "        eval_strategy=\"epoch\",\n",
    "        save_strategy=\"epoch\",\n",
    "        learning_rate=learning_rate,\n",
    "        num_train_epochs=num_train_epochs,\n",
    "        bf16=True,\n",
    "        load_best_model_at_end=True,\n",
    "        report_to=\"none\",\n",
    "        save_total_limit=1,\n",
    "        logging_dir=logging_dir,\n",
    "        logging_steps=10,\n",
    "    )\n",
    "\n",
    "    # Prepare trainer\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=tokenized_data[\"train\"],\n",
    "        eval_dataset=tokenized_data[\"validation\"],\n",
    "        tokenizer=tokenizer,\n",
    "        data_collator=DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False),\n",
    "        callbacks=[EarlyStoppingCallback(early_stopping_patience=2)],\n",
    "    )\n",
    "\n",
    "    # Training and evaluation\n",
    "    trainer.train()\n",
    "    trial.set_user_attr(\"best_model_path\", trainer.state.best_model_checkpoint or output_dir)\n",
    "    eval_metrics = trainer.evaluate()\n",
    "    return eval_metrics[\"eval_loss\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e97fb436",
   "metadata": {},
   "source": [
    "### Launch Optuna Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc53aec5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-24 00:34:42,238] A new study created in memory with name: no-name-335da27f-3fb5-4e1a-91d8-b549ede1f15b\n",
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:12<00:00,  3.18s/it]\n",
      "/tmp/ipykernel_6185/3243740175.py:61: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n",
      "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.\n",
      "/home/ubuntu/AI-resume-agent/myenv/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:632: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='143' max='3000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 143/3000 17:45 < 5:59:57, 0.13 it/s, Epoch 0.09/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=10)\n",
    "\n",
    "print(\"✅ Best hyperparameters:\")\n",
    "print(study.best_params)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1b1a394",
   "metadata": {},
   "source": [
    "###  Save Final Best Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30c7c071",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_trial_number = study.best_trial.number\n",
    "#best_model_path = f\"optuna_output/{best_trial_number}\"\n",
    "best_model_path = study.best_trial.user_attrs.get(\"best_model_path\")\n",
    "print(\"✅ Best model path:\", best_model_path)\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(best_model_path)\n",
    "model.save_pretrained(Config.JSON_OUTPUT_FINE_TUNE_MODEL)\n",
    "tokenizer.save_pretrained(Config.JSON_OUTPUT_FINE_TUNE_MODEL)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cb93d0c",
   "metadata": {},
   "source": [
    "## Save to hugging face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c45f5474",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import HfApi, HfFolder\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "# ✅ Optional: Login (only needed once per environment)\n",
    "# from huggingface_hub import login\n",
    "# login(\"hf_your_access_token\")\n",
    "\n",
    "# Set model path and repo name\n",
    "model_path = Config.JSON_OUTPUT_FINE_TUNE_MODEL\n",
    "repo_name = \"rubsj/Qwen2-Resume-ATS\"  # customize this\n",
    "\n",
    "# Push model and tokenizer to HF hub\n",
    "model.push_to_hub(repo_name, , private=True)\n",
    "tokenizer.push_to_hub(repo_name, , private=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b961a3ae",
   "metadata": {},
   "source": [
    "## Create ZIP for Lambda Download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fba74aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "zip_path = f\"{Config.JSON_OUTPUT_FINE_TUNE_MODEL}.zip\"\n",
    "shutil.make_archive(base_name=Config.JSON_OUTPUT_FINE_TUNE_MODEL, format='zip', root_dir=Config.JSON_OUTPUT_FINE_TUNE_MODEL)\n",
    "print(f\"✅ Model zipped at: {zip_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38f4c0ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"✅ Hugging Face Model URL: https://huggingface.co/{repo_name}\")\n",
    "print(f\"✅ Local zip ready for download: {zip_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
