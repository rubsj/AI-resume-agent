{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0e558f9c",
   "metadata": {},
   "source": [
    "# Global setup and package installation used in most phases"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4582433",
   "metadata": {},
   "source": [
    "## Colab + GPU Detection Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "909ac010",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "def is_running_in_colab():\n",
    "    try:\n",
    "        import google.colab\n",
    "        return True\n",
    "    except ImportError:\n",
    "        return False\n",
    "\n",
    "def get_available_gpu_memory_gb():\n",
    "    try:\n",
    "        output = subprocess.check_output(\n",
    "            [\"nvidia-smi\", \"--query-gpu=memory.free\", \"--format=csv,nounits,noheader\"],\n",
    "            encoding=\"utf-8\"\n",
    "        )\n",
    "        free_mem_mb = int(output.strip().split(\"\\n\")[0])\n",
    "        return free_mem_mb / 1024\n",
    "    except Exception:\n",
    "        return 0.0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "746cd125",
   "metadata": {},
   "source": [
    "## install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "989d573e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if is_running_in_colab():\n",
    "    # Install the required packages\n",
    "    !pip install kagglehub pandas\n",
    "    !pip install -q transformers accelerate bitsandbytes sentencepiece pydantic huggingface_hub xformers\n",
    "    !pip install regex json5\n",
    "    !pip install dspy  sentence-transformers transformers accelerate scikit-learn -q\n",
    "\n",
    "else:\n",
    "    %pip install kagglehub pandas\n",
    "    %pip install -q transformers accelerate sentencepiece pydantic huggingface_hub xformers\n",
    "    #%pip install torch==2.2.2 torchvision==0.17.2 torchaudio==2.2.2 --index-url https://download.pytorch.org/whl/cu121\n",
    "    #%pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121\n",
    "    %pip install --pre torch torchvision torchaudio --index-url https://download.pytorch.org/whl/nightly/cu128\n",
    "    %pip install -U bitsandbytes\n",
    "    %pip install regex json5\n",
    "    # üì¶ INSTALL REQUIREMENTS\n",
    "    %pip install dspy  sentence-transformers transformers accelerate scikit-learn -q\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02d7833b",
   "metadata": {},
   "source": [
    "## Login to huggingface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0faca7c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import login\n",
    "import os\n",
    "\n",
    "# Set your token here securely or prompt for it in Colab\n",
    "# Recommended: store in Colab secrets or environment variable\n",
    "HF_TOKEN = os.getenv(\"HUGGINGFACE_TOKEN\")\n",
    "\n",
    "\n",
    "if not HF_TOKEN:\n",
    "    if is_running_in_colab():\n",
    "        # If running in Colab, use the Colab secrets\n",
    "        try:\n",
    "            from google.colab import userdata\n",
    "            HF_TOKEN = userdata.get('HF_TOKEN')\n",
    "            if not HF_TOKEN:\n",
    "                raise ValueError(\"‚ö†Ô∏è Hugging Face token not found in Colab secrets.\")\n",
    "            print(\"üîë Hugging Face token found in Colab secrets.\")\n",
    "        except ImportError:\n",
    "            print(\"‚ö†Ô∏è Unable to authenticate in Colab. Please set your Hugging Face token manually.\")\n",
    "    else:\n",
    "        # Prompt for token if not set in environment\n",
    "        print(\"üîë Please enter your Hugging Face token:\")\n",
    "        # For Colab or local prompt input\n",
    "        HF_TOKEN = input(\"üîë Enter your Hugging Face token: \").strip()\n",
    "\n",
    "login(token=HF_TOKEN)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "639e756d",
   "metadata": {},
   "source": [
    "## Setup Kaggle Credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d427d355",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Kaggle credentials already exist at C:\\Users\\rubyj/.kaggle/kaggle.json\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "\n",
    "def setup_kaggle_credentials():\n",
    "    kaggle_path = os.path.expanduser('~/.kaggle/kaggle.json')\n",
    "    if not os.path.exists(kaggle_path):\n",
    "        from google.colab import files\n",
    "        print(\"üìÇ Upload kaggle.json file...\")\n",
    "        uploaded = files.upload()\n",
    "        os.makedirs(os.path.dirname(kaggle_path), exist_ok=True)\n",
    "        for filename in uploaded.keys():\n",
    "            shutil.move(filename, kaggle_path)\n",
    "        os.chmod(kaggle_path, 0o600)\n",
    "        print(f\"‚úÖ Kaggle credentials setup at {kaggle_path}\")\n",
    "    else:\n",
    "        print(f\"‚úÖ Kaggle credentials already exist at {kaggle_path}\")\n",
    "\n",
    "setup_kaggle_credentials()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f301c89",
   "metadata": {},
   "source": [
    "##  Load mistral-Instruct with Fallback to Quantized"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d8df421",
   "metadata": {},
   "source": [
    "### SimpleLM-Like Class for DSPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9c8166b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dspy import BaseLM\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "import torch\n",
    "\n",
    "class SimpleLM(BaseLM):\n",
    "    def __init__(self, model_name, tokenizer, model, max_new_tokens=2048):\n",
    "        super().__init__(model=model_name)\n",
    "        self.tokenizer = tokenizer\n",
    "        self._model = model         # internal model\n",
    "        self.model = model_name     # string for DSPy to parse with .split()\n",
    "        self.max_new_tokens = max_new_tokens\n",
    "        self.kwargs = {}\n",
    "\n",
    "    def __call__(self, messages, **kwargs):\n",
    "        # DSPy passes `messages=[{\"role\": \"user\", \"content\": \"...\"}]`\n",
    "        if isinstance(messages, list):\n",
    "            prompt = \"\\n\".join([m[\"content\"] for m in messages])\n",
    "        else:\n",
    "            raise ValueError(\"Expected messages as a list of dicts with 'content'.\")\n",
    "\n",
    "        inputs = self.tokenizer(prompt, return_tensors=\"pt\").to(self._model.device)\n",
    "        outputs = self._model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=self.max_new_tokens,\n",
    "            do_sample=False,\n",
    "            pad_token_id=self.tokenizer.pad_token_id,\n",
    "            eos_token_id=self.tokenizer.eos_token_id\n",
    "        )\n",
    "        output_text = self.tokenizer.decode(outputs[0], skip_special_tokens=True).strip()\n",
    "        return output_text\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc01fa07",
   "metadata": {},
   "source": [
    "### Use It in Your DSPy Project (with Quantized Mistral)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4fc325a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üíª CUDA: True | GPU Memory: 15.92 GB\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a88fb112f4214fc5aa3b46a64eb242ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "from dspy import configure\n",
    "\n",
    "# üîß Load quantized or full model manually\n",
    "model_name = \"mistralai/Mistral-7B-Instruct-v0.1\"\n",
    "hf_token = HF_TOKEN\n",
    "\n",
    "has_cuda = torch.cuda.is_available()\n",
    "free_mem = torch.cuda.get_device_properties(0).total_memory / (1024 ** 3) if has_cuda else 0\n",
    "print(f\"üíª CUDA: {has_cuda} | GPU Memory: {free_mem:.2f} GB\")\n",
    "\n",
    "device_map = {\"\": 0} if has_cuda else \"cpu\"\n",
    "use_4bit = has_cuda and free_mem < 24\n",
    "\n",
    "# Set quantization config\n",
    "quant_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True if use_4bit else False,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_compute_dtype=torch.float16,\n",
    "    bnb_4bit_quant_type=\"nf4\"\n",
    ") if use_4bit else None\n",
    "\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, token=hf_token, trust_remote_code=True)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    device_map=device_map,\n",
    "    quantization_config=quant_config,\n",
    "    torch_dtype=torch.float16 if not quant_config else None,\n",
    "    token=hf_token,\n",
    "    trust_remote_code=True\n",
    ").eval()\n",
    "\n",
    "# ‚úÖ Plug into DSPy\n",
    "lm = SimpleLM(model_name=model_name, tokenizer=tokenizer, model=model, max_new_tokens=2048)\n",
    "configure(lm=lm)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d1bb74a",
   "metadata": {},
   "source": [
    "## Utilities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41aa3b5f",
   "metadata": {},
   "source": [
    "### Configurations  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "faa14e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================\n",
    "# üõ† CONFIGURATION\n",
    "# ==============================\n",
    "\n",
    "class Config:\n",
    "    DATASET_DOWNLOAD_DIR = \"datasets\"\n",
    "    JSON_OUTPUT_DIR = \"json_outputs_run3\"\n",
    "    JSON_OUTPUT_NORMALIZED_DIR = \"json_outputs_run3/normalized\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1248c8e3",
   "metadata": {},
   "source": [
    "## Utility to save json to a folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "808269cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "# üì¶ Save JSON Output with Safety\n",
    "def save_json_output(data, output_path: str, indent: int = 4, overwrite: bool = True):\n",
    "    output_dir = os.path.dirname(output_path)\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    if os.path.exists(output_path):\n",
    "        if overwrite:\n",
    "            os.remove(output_path)\n",
    "        else:\n",
    "            raise FileExistsError(f\"File {output_path} already exists and overwrite=False.\")\n",
    "\n",
    "    with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(data, f, indent=indent, ensure_ascii=False)\n",
    "\n",
    "    print(f\"‚úÖ Saved output to {output_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62b305bf",
   "metadata": {},
   "source": [
    "## Utility to load file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04cf51ab",
   "metadata": {},
   "source": [
    "### load_ndjson_file() (for resume/jd input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "82200a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from typing import List\n",
    "\n",
    "\n",
    "def load_ndjson_file(file_path: Path) -> List[dict]:\n",
    "    if not os.path.isfile(file_path):\n",
    "        raise FileNotFoundError(f\"File not found: {file_path}\")\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        return [json.loads(line) for line in file if line.strip()]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0034749",
   "metadata": {},
   "source": [
    "### load_json_file() (for checkpoint & metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "72b1aa37",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "\n",
    "def load_json_file(file_path: Path) -> dict:\n",
    "    if not os.path.isfile(file_path):\n",
    "        raise FileNotFoundError(f\"File not found: {file_path}\")\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        return json.load(file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "715c141c",
   "metadata": {},
   "source": [
    "# Phase 2 -\tParse resume/JD into JSON structured scheme"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c74cd976",
   "metadata": {},
   "source": [
    "## DSPy Signature and Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "413b4237",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'Callback' from 'dspy.utils.callback' (c:\\Ruby\\projects\\AI-resume-agent\\.venv\\Lib\\site-packages\\dspy\\utils\\callback.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[23]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdspy\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcallback\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Callback\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdspy\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# ‚úÖ Define a custom callback that works in DSPy 2.6.24\u001b[39;00m\n",
      "\u001b[31mImportError\u001b[39m: cannot import name 'Callback' from 'dspy.utils.callback' (c:\\Ruby\\projects\\AI-resume-agent\\.venv\\Lib\\site-packages\\dspy\\utils\\callback.py)"
     ]
    }
   ],
   "source": [
    "from dspy.utils.callback import Callback\n",
    "import dspy\n",
    "\n",
    "# ‚úÖ Define a custom callback that works in DSPy 2.6.24\n",
    "class PromptLogger(Callback):\n",
    "    def on_start(self, caller, **kwargs):\n",
    "        input_data = kwargs.get(\"input\", None)\n",
    "        if input_data:\n",
    "            print(\"\\nüì§ Prompt Sent to LLM:\\n\", input_data)\n",
    "\n",
    "    def on_end(self, caller, **kwargs):\n",
    "        output_data = kwargs.get(\"output\", None)\n",
    "        if output_data:\n",
    "            print(\"\\nüì• Raw Output from LLM:\\n\", output_data)\n",
    "\n",
    "# ‚úÖ Register the callback\n",
    "dspy.settings.configure(callbacks=[PromptLogger()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "061d7c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Updated parser function: full resume ‚Üí JSON in one shot using DSPy + Mistral\n",
    "from typing import Dict\n",
    "from dspy import Predict, InputField, OutputField, Signature\n",
    "    \n",
    "class ResumeJsonSignature(Signature):\n",
    "    resume_text = InputField(desc=\"Full resume as plain text\")\n",
    "    extracted_json = OutputField(desc=\"Parsed JSON output for the resume\")\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f4dcefe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dspy import InputField, OutputField, Signature, ChainOfThought, configure, BaseLM\n",
    "# ‚úÖ Prompt Template for Instruct Format\n",
    "class ResumeParser(ChainOfThought):\n",
    "    def __init__(self):\n",
    "        super().__init__(ResumeJsonSignature)\n",
    "\n",
    "    def format(self, inputs):\n",
    "        return {\n",
    "            \"resume_text\": f\"\"\"[INST] Convert the following resume into structured JSON with this format:\n",
    "\n",
    "{{\n",
    "  \"summary\": string,\n",
    "  \"skills\": [string],\n",
    "  \"education\": [{{\"degree\": string, \"field\": string, \"institution\": string, \"year\": string}}],\n",
    "  \"experience\": [{{\"job_title\": string, \"company\": string, \"start_date\": string, \"end_date\": string, \"description\": string}}]\n",
    "}}\n",
    "\n",
    "Resume:\n",
    "{inputs['resume_text']}\n",
    "\n",
    "Return your output as: {{ \"extracted_json\": {{ ... }} }} [/INST]\n",
    "\"\"\"\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3b976b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_resume_to_json(resume_text: str):\n",
    "    parser = ResumeParser()\n",
    "    result = parser(resume_text=resume_text)\n",
    "    print(\"üì§ Prompt Sent to Model:\\n\", result.inputs['resume_text'])\n",
    "    print(\"\\nüì• LLM Output:\\n\", result.extracted_json)\n",
    "    \n",
    "    try:\n",
    "        return json.loads(result.extracted_json)\n",
    "    except Exception as e:\n",
    "        print(\"‚ùå Failed to parse JSON:\", e)\n",
    "        return {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5726ffea",
   "metadata": {},
   "source": [
    "## Test with Sample Resume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a42a2874",
   "metadata": {},
   "outputs": [
    {
     "ename": "AdapterParseError",
     "evalue": "LM response cannot be serialized to a JSON object.\n\nAdapter JSONAdapter failed to parse the LM response. \n\nLM Response: Y \n\nExpected to find output fields in the LM response: [reasoning, extracted_json] \n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAdapterParseError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Ruby\\projects\\AI-resume-agent\\.venv\\Lib\\site-packages\\dspy\\adapters\\chat_adapter.py:42\u001b[39m, in \u001b[36mChatAdapter.__call__\u001b[39m\u001b[34m(self, lm, lm_kwargs, signature, demos, inputs)\u001b[39m\n\u001b[32m     41\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m42\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mlm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlm_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msignature\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdemos\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     43\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m     44\u001b[39m     \u001b[38;5;66;03m# fallback to JSONAdapter\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Ruby\\projects\\AI-resume-agent\\.venv\\Lib\\site-packages\\dspy\\adapters\\base.py:52\u001b[39m, in \u001b[36mAdapter.__call__\u001b[39m\u001b[34m(self, lm, lm_kwargs, signature, demos, inputs)\u001b[39m\n\u001b[32m     51\u001b[39m outputs = lm(messages=inputs, **lm_kwargs)\n\u001b[32m---> \u001b[39m\u001b[32m52\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_post_process\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msignature\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Ruby\\projects\\AI-resume-agent\\.venv\\Lib\\site-packages\\dspy\\adapters\\base.py:32\u001b[39m, in \u001b[36mAdapter._call_post_process\u001b[39m\u001b[34m(self, outputs, signature)\u001b[39m\n\u001b[32m     30\u001b[39m     output, output_logprobs = output[\u001b[33m\"\u001b[39m\u001b[33mtext\u001b[39m\u001b[33m\"\u001b[39m], output[\u001b[33m\"\u001b[39m\u001b[33mlogprobs\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m---> \u001b[39m\u001b[32m32\u001b[39m value = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mparse\u001b[49m\u001b[43m(\u001b[49m\u001b[43msignature\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     34\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m output_logprobs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Ruby\\projects\\AI-resume-agent\\.venv\\Lib\\site-packages\\dspy\\utils\\callback.py:326\u001b[39m, in \u001b[36mwith_callbacks.<locals>.sync_wrapper\u001b[39m\u001b[34m(instance, *args, **kwargs)\u001b[39m\n\u001b[32m    325\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m callbacks:\n\u001b[32m--> \u001b[39m\u001b[32m326\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43minstance\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    328\u001b[39m call_id = uuid.uuid4().hex\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Ruby\\projects\\AI-resume-agent\\.venv\\Lib\\site-packages\\dspy\\adapters\\chat_adapter.py:179\u001b[39m, in \u001b[36mChatAdapter.parse\u001b[39m\u001b[34m(self, signature, completion)\u001b[39m\n\u001b[32m    178\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m fields.keys() != signature.output_fields.keys():\n\u001b[32m--> \u001b[39m\u001b[32m179\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m AdapterParseError(\n\u001b[32m    180\u001b[39m         adapter_name=\u001b[33m\"\u001b[39m\u001b[33mChatAdapter\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    181\u001b[39m         signature=signature,\n\u001b[32m    182\u001b[39m         lm_response=completion,\n\u001b[32m    183\u001b[39m         parsed_result=fields,\n\u001b[32m    184\u001b[39m     )\n\u001b[32m    186\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m fields\n",
      "\u001b[31mAdapterParseError\u001b[39m: Adapter ChatAdapter failed to parse the LM response. \n\nLM Response: Y \n\nExpected to find output fields in the LM response: [reasoning, extracted_json] \n\nActual output fields parsed from the LM response: [] \n\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mAdapterParseError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[21]\u001b[39m\u001b[32m, line 19\u001b[39m\n\u001b[32m      1\u001b[39m sample_resume = \u001b[33m\"\"\"\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[33mJohn Doe\u001b[39m\n\u001b[32m      3\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m     15\u001b[39m \u001b[33mJava, React, Spring Boot, SQL, Docker\u001b[39m\n\u001b[32m     16\u001b[39m \u001b[33m\"\"\"\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m json_output = \u001b[43mparse_resume_to_json\u001b[49m\u001b[43m(\u001b[49m\u001b[43msample_resume\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     20\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m‚úÖ Parsed JSON:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m, json.dumps(json_output, indent=\u001b[32m2\u001b[39m))\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[20]\u001b[39m\u001b[32m, line 3\u001b[39m, in \u001b[36mparse_resume_to_json\u001b[39m\u001b[34m(resume_text)\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mparse_resume_to_json\u001b[39m(resume_text: \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m      2\u001b[39m     parser = ResumeParser()\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m     result = \u001b[43mparser\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresume_text\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresume_text\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      4\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33müì§ Prompt Sent to Model:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m, result.inputs[\u001b[33m'\u001b[39m\u001b[33mresume_text\u001b[39m\u001b[33m'\u001b[39m])\n\u001b[32m      5\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33müì• LLM Output:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m, result.extracted_json)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Ruby\\projects\\AI-resume-agent\\.venv\\Lib\\site-packages\\dspy\\utils\\callback.py:326\u001b[39m, in \u001b[36mwith_callbacks.<locals>.sync_wrapper\u001b[39m\u001b[34m(instance, *args, **kwargs)\u001b[39m\n\u001b[32m    324\u001b[39m callbacks = _get_active_callbacks(instance)\n\u001b[32m    325\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m callbacks:\n\u001b[32m--> \u001b[39m\u001b[32m326\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43minstance\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    328\u001b[39m call_id = uuid.uuid4().hex\n\u001b[32m    330\u001b[39m _execute_start_callbacks(instance, fn, call_id, callbacks, args, kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Ruby\\projects\\AI-resume-agent\\.venv\\Lib\\site-packages\\dspy\\primitives\\program.py:32\u001b[39m, in \u001b[36mModule.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     29\u001b[39m         output.set_lm_usage(usage_tracker.get_total_tokens())\n\u001b[32m     30\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m output\n\u001b[32m---> \u001b[39m\u001b[32m32\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Ruby\\projects\\AI-resume-agent\\.venv\\Lib\\site-packages\\dspy\\predict\\chain_of_thought.py:38\u001b[39m, in \u001b[36mChainOfThought.forward\u001b[39m\u001b[34m(self, **kwargs)\u001b[39m\n\u001b[32m     37\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, **kwargs):\n\u001b[32m---> \u001b[39m\u001b[32m38\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Ruby\\projects\\AI-resume-agent\\.venv\\Lib\\site-packages\\dspy\\predict\\predict.py:85\u001b[39m, in \u001b[36mPredict.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     82\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m args:\n\u001b[32m     83\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;28mself\u001b[39m._get_positional_args_error_message())\n\u001b[32m---> \u001b[39m\u001b[32m85\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Ruby\\projects\\AI-resume-agent\\.venv\\Lib\\site-packages\\dspy\\utils\\callback.py:326\u001b[39m, in \u001b[36mwith_callbacks.<locals>.sync_wrapper\u001b[39m\u001b[34m(instance, *args, **kwargs)\u001b[39m\n\u001b[32m    324\u001b[39m callbacks = _get_active_callbacks(instance)\n\u001b[32m    325\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m callbacks:\n\u001b[32m--> \u001b[39m\u001b[32m326\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43minstance\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    328\u001b[39m call_id = uuid.uuid4().hex\n\u001b[32m    330\u001b[39m _execute_start_callbacks(instance, fn, call_id, callbacks, args, kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Ruby\\projects\\AI-resume-agent\\.venv\\Lib\\site-packages\\dspy\\primitives\\program.py:32\u001b[39m, in \u001b[36mModule.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     29\u001b[39m         output.set_lm_usage(usage_tracker.get_total_tokens())\n\u001b[32m     30\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m output\n\u001b[32m---> \u001b[39m\u001b[32m32\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Ruby\\projects\\AI-resume-agent\\.venv\\Lib\\site-packages\\dspy\\predict\\predict.py:146\u001b[39m, in \u001b[36mPredict.forward\u001b[39m\u001b[34m(self, **kwargs)\u001b[39m\n\u001b[32m    144\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    145\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m settings.context(send_stream=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m--> \u001b[39m\u001b[32m146\u001b[39m         completions = \u001b[43madapter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlm_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msignature\u001b[49m\u001b[43m=\u001b[49m\u001b[43msignature\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdemos\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdemos\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    148\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_postprocess(completions, signature, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Ruby\\projects\\AI-resume-agent\\.venv\\Lib\\site-packages\\dspy\\adapters\\chat_adapter.py:51\u001b[39m, in \u001b[36mChatAdapter.__call__\u001b[39m\u001b[34m(self, lm, lm_kwargs, signature, demos, inputs)\u001b[39m\n\u001b[32m     47\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e, ContextWindowExceededError) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, JSONAdapter):\n\u001b[32m     48\u001b[39m     \u001b[38;5;66;03m# On context window exceeded error or already using JSONAdapter, we don't want to retry with a different\u001b[39;00m\n\u001b[32m     49\u001b[39m     \u001b[38;5;66;03m# adapter.\u001b[39;00m\n\u001b[32m     50\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[32m---> \u001b[39m\u001b[32m51\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mJSONAdapter\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlm_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msignature\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdemos\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Ruby\\projects\\AI-resume-agent\\.venv\\Lib\\site-packages\\dspy\\adapters\\json_adapter.py:53\u001b[39m, in \u001b[36mJSONAdapter.__call__\u001b[39m\u001b[34m(self, lm, lm_kwargs, signature, demos, inputs)\u001b[39m\n\u001b[32m     51\u001b[39m \u001b[38;5;66;03m# If response_format is not supported, use basic call\u001b[39;00m\n\u001b[32m     52\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m params \u001b[38;5;129;01mor\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mresponse_format\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m params:\n\u001b[32m---> \u001b[39m\u001b[32m53\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mlm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlm_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msignature\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdemos\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     55\u001b[39m \u001b[38;5;66;03m# Check early for open-ended mapping types before trying structured outputs.\u001b[39;00m\n\u001b[32m     56\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m _has_open_ended_mapping(signature):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Ruby\\projects\\AI-resume-agent\\.venv\\Lib\\site-packages\\dspy\\adapters\\chat_adapter.py:50\u001b[39m, in \u001b[36mChatAdapter.__call__\u001b[39m\u001b[34m(self, lm, lm_kwargs, signature, demos, inputs)\u001b[39m\n\u001b[32m     45\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdspy\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01madapters\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mjson_adapter\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m JSONAdapter\n\u001b[32m     47\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e, ContextWindowExceededError) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, JSONAdapter):\n\u001b[32m     48\u001b[39m     \u001b[38;5;66;03m# On context window exceeded error or already using JSONAdapter, we don't want to retry with a different\u001b[39;00m\n\u001b[32m     49\u001b[39m     \u001b[38;5;66;03m# adapter.\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m50\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[32m     51\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m JSONAdapter()(lm, lm_kwargs, signature, demos, inputs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Ruby\\projects\\AI-resume-agent\\.venv\\Lib\\site-packages\\dspy\\adapters\\chat_adapter.py:42\u001b[39m, in \u001b[36mChatAdapter.__call__\u001b[39m\u001b[34m(self, lm, lm_kwargs, signature, demos, inputs)\u001b[39m\n\u001b[32m     33\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\n\u001b[32m     34\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m     35\u001b[39m     lm: LM,\n\u001b[32m   (...)\u001b[39m\u001b[32m     39\u001b[39m     inputs: \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any],\n\u001b[32m     40\u001b[39m ) -> \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any]]:\n\u001b[32m     41\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m42\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mlm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlm_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msignature\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdemos\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     43\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m     44\u001b[39m         \u001b[38;5;66;03m# fallback to JSONAdapter\u001b[39;00m\n\u001b[32m     45\u001b[39m         \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdspy\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01madapters\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mjson_adapter\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m JSONAdapter\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Ruby\\projects\\AI-resume-agent\\.venv\\Lib\\site-packages\\dspy\\adapters\\base.py:52\u001b[39m, in \u001b[36mAdapter.__call__\u001b[39m\u001b[34m(self, lm, lm_kwargs, signature, demos, inputs)\u001b[39m\n\u001b[32m     49\u001b[39m inputs = \u001b[38;5;28mself\u001b[39m.format(signature, demos, inputs)\n\u001b[32m     51\u001b[39m outputs = lm(messages=inputs, **lm_kwargs)\n\u001b[32m---> \u001b[39m\u001b[32m52\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_post_process\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msignature\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Ruby\\projects\\AI-resume-agent\\.venv\\Lib\\site-packages\\dspy\\adapters\\base.py:32\u001b[39m, in \u001b[36mAdapter._call_post_process\u001b[39m\u001b[34m(self, outputs, signature)\u001b[39m\n\u001b[32m     29\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(output, \u001b[38;5;28mdict\u001b[39m):\n\u001b[32m     30\u001b[39m     output, output_logprobs = output[\u001b[33m\"\u001b[39m\u001b[33mtext\u001b[39m\u001b[33m\"\u001b[39m], output[\u001b[33m\"\u001b[39m\u001b[33mlogprobs\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m---> \u001b[39m\u001b[32m32\u001b[39m value = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mparse\u001b[49m\u001b[43m(\u001b[49m\u001b[43msignature\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     34\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m output_logprobs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     35\u001b[39m     value[\u001b[33m\"\u001b[39m\u001b[33mlogprobs\u001b[39m\u001b[33m\"\u001b[39m] = output_logprobs\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Ruby\\projects\\AI-resume-agent\\.venv\\Lib\\site-packages\\dspy\\utils\\callback.py:326\u001b[39m, in \u001b[36mwith_callbacks.<locals>.sync_wrapper\u001b[39m\u001b[34m(instance, *args, **kwargs)\u001b[39m\n\u001b[32m    324\u001b[39m callbacks = _get_active_callbacks(instance)\n\u001b[32m    325\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m callbacks:\n\u001b[32m--> \u001b[39m\u001b[32m326\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43minstance\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    328\u001b[39m call_id = uuid.uuid4().hex\n\u001b[32m    330\u001b[39m _execute_start_callbacks(instance, fn, call_id, callbacks, args, kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Ruby\\projects\\AI-resume-agent\\.venv\\Lib\\site-packages\\dspy\\adapters\\json_adapter.py:132\u001b[39m, in \u001b[36mJSONAdapter.parse\u001b[39m\u001b[34m(self, signature, completion)\u001b[39m\n\u001b[32m    129\u001b[39m fields = json_repair.loads(completion)\n\u001b[32m    131\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(fields, \u001b[38;5;28mdict\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m132\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m AdapterParseError(\n\u001b[32m    133\u001b[39m         adapter_name=\u001b[33m\"\u001b[39m\u001b[33mJSONAdapter\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    134\u001b[39m         signature=signature,\n\u001b[32m    135\u001b[39m         lm_response=completion,\n\u001b[32m    136\u001b[39m         message=\u001b[33m\"\u001b[39m\u001b[33mLM response cannot be serialized to a JSON object.\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    137\u001b[39m     )\n\u001b[32m    139\u001b[39m fields = {k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m fields.items() \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m signature.output_fields}\n\u001b[32m    141\u001b[39m \u001b[38;5;66;03m# Attempt to cast each value to type signature.output_fields[k].annotation.\u001b[39;00m\n",
      "\u001b[31mAdapterParseError\u001b[39m: LM response cannot be serialized to a JSON object.\n\nAdapter JSONAdapter failed to parse the LM response. \n\nLM Response: Y \n\nExpected to find output fields in the LM response: [reasoning, extracted_json] \n\n"
     ]
    }
   ],
   "source": [
    "sample_resume = \"\"\"\n",
    "John Doe\n",
    "\n",
    "SUMMARY\n",
    "Experienced software engineer with 10+ years...\n",
    "\n",
    "PROFESSIONAL EXPERIENCE\n",
    "Senior Software Engineer, ABC Corp\n",
    "Built microservices in Java and deployed on Kubernetes.\n",
    "\n",
    "EDUCATION\n",
    "MS in Computer Science, XYZ University\n",
    "\n",
    "SKILLS\n",
    "Java, React, Spring Boot, SQL, Docker\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "json_output = parse_resume_to_json(sample_resume)\n",
    "print(\"\\n‚úÖ Parsed JSON:\\n\", json.dumps(json_output, indent=2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.10)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
